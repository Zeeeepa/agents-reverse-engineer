---
generated_at: 2026-02-09T16:09:56.581Z
content_hash: 232da2af981eb6c44ab5f5e8908ea14d6ee97fe4295f950b83f42ee45e40a95a
purpose: AIService orchestrates AI CLI subprocess invocations with retry logic, timeout enforcement, telemetry recording, and ...
---
**AIService orchestrates AI CLI subprocess invocations with retry logic, timeout enforcement, telemetry recording, and trace emission for concurrent file analysis workflows.**

## Exported API

**AIService** class coordinates AI backend interactions through:
- `constructor(backend: AIBackend, options: AIServiceOptions)` — Initializes service with resolved backend adapter and config (timeoutMs, maxRetries, telemetry.keepRuns)
- `call(options: AICallOptions): Promise<AIResponse>` — Executes AI invocation with retry wrapper, records TelemetryEntry, returns normalized AIResponse
- `finalize(projectRoot: string): Promise<{ logPath: string; summary: RunLog['summary'] }>` — Writes RunLog to `.agents-reverse-engineer/logs/run-<timestamp>.json`, prunes old logs via cleanupOldLogs()
- `setTracer(tracer: ITraceWriter): void` — Attaches trace writer for subprocess:spawn/exit/retry events
- `setDebug(enabled: boolean): void` — Enables verbose subprocess logging with heap/RSS metrics to stderr
- `setSubprocessLogDir(dir: string): void` — Configures directory for writing per-subprocess `.log` files (stdout+stderr+metadata)
- `addFilesReadToLastEntry(filesRead: FileRead[]): void` — Attaches file context metadata to most recent telemetry entry
- `getSummary(): RunLog['summary']` — Returns current run statistics (totalInputTokens, totalCacheReadTokens, errorCount, etc.) without finalizing

**AIServiceOptions** interface specifies:
- `timeoutMs: number` — Default subprocess timeout (from config.ai.timeoutMs, typically 120000)
- `maxRetries: number` — Retry attempt limit for transient errors (from config.ai.maxRetries, typically 3)
- `model?: string` — Default model identifier applied to all calls unless overridden per AICallOptions.model
- `telemetry.keepRuns: number` — Retention count for historical run logs (from config.ai.telemetry.keepRuns, typically 50)

**AIServiceError** type (re-exported from `./types.js`) with discriminated codes: `'TIMEOUT' | 'RATE_LIMIT' | 'SUBPROCESS_ERROR' | 'PARSE_ERROR'`

## Retry Strategy

**withRetry()** invoked from `./retry.js` with custom configuration:
- `maxRetries: options.maxRetries` (typically 3)
- `isRetryable: (error) => error.code === 'RATE_LIMIT'` — ONLY retries rate limits; timeouts are permanent failures to avoid resource exhaustion
- `onRetry: (attempt, error) => ...` — Emits `retry` trace event and stderr warning with `[warn] Retrying "${taskLabel}" (attempt ${attempt}/${maxRetries}, reason: ${errorCode})`

**isRateLimitStderr(stderr: string): boolean** detects transient errors via pattern matching:
- Patterns: `['rate limit', '429', 'too many requests', 'overloaded']` (case-insensitive substring search)
- Maps subprocess stderr to `AIServiceError('RATE_LIMIT', ...)` for retry eligibility

## Subprocess Lifecycle

**call()** execution flow:
1. Merges `options.model ?? this.options.model` into effectiveOptions
2. Calls `backend.buildArgs(effectiveOptions)` to construct CLI argv
3. Increments `activeSubprocesses` counter before spawn
4. Invokes `runSubprocess(backend.cliCommand, args, { timeoutMs, input: prompt, onSpawn: (pid) => tracer.emit('subprocess:spawn', ...) })`
5. Decrements `activeSubprocesses` after completion
6. Emits `subprocess:exit` trace event with childPid, exitCode, signal, durationMs, timedOut
7. Enqueues subprocess log write via `enqueueSubprocessLog()` (fire-and-forget, non-critical)
8. Checks `result.timedOut` → throws `AIServiceError('TIMEOUT', ...)` with stderr warning showing PID and duration
9. Checks `exitCode !== 0` → applies `isRateLimitStderr()` detection → throws RATE_LIMIT or SUBPROCESS_ERROR
10. Calls `backend.parseResponse(stdout, durationMs, exitCode)` with try/catch wrapping parse errors as `AIServiceError('PARSE_ERROR', ...)`
11. Records TelemetryEntry via `logger.addEntry()` with model, tokens, latencyMs, retryCount, filesRead (empty array initially)

## Telemetry Recording

**TelemetryLogger** (from `./telemetry/logger.js`) accumulates entries in-memory:
- Each `call()` invocation adds entry with timestamp, prompt, systemPrompt, response, model, inputTokens, outputTokens, cacheReadTokens, cacheCreationTokens, latencyMs, exitCode, retryCount, thinking='not supported', filesRead=[]
- Failed calls record empty response, 0 tokens, error message string, exitCode=1
- `addFilesReadToLastEntry(filesRead)` mutates most recent entry to attach FileRead[] metadata (path + sizeBytes)
- `toRunLog()` converts entries to RunLog with aggregated summary: totalInputTokens, totalOutputTokens, totalCacheReadTokens, totalCacheCreationTokens, totalLatencyMs, callCount, errorCount, uniqueFilesRead

**writeRunLog(projectRoot, runLog)** (from `./telemetry/run-log.js`) serializes to `.agents-reverse-engineer/logs/run-<timestamp>.json`

**cleanupOldLogs(projectRoot, keepRuns)** (from `./telemetry/cleanup.js`) enforces retention policy by deleting oldest logs beyond keepRuns limit

## Debug Logging

**setDebug(true)** enables stderr output:
- Before spawn: `[debug] Spawning subprocess for "${taskLabel}" (active: ${activeSubprocesses}, heapUsed: ${formatBytes(mem.heapUsed)}, rss: ${formatBytes(mem.rss)}, timeout: ${timeoutMs/1000}s)`
- After exit: `[debug] Subprocess exited for "${taskLabel}" (PID ${childPid}, exitCode: ${exitCode}, duration: ${durationMs/1000}s, active: ${activeSubprocesses})`
- Uses `formatBytes(bytes): string` helper producing `"123B"` / `"4.5KB"` / `"67.8MB"` strings

**setSubprocessLogDir(dir)** writes `.log` files asynchronously:
- Filename pattern: `${taskLabel.replace(/\//g, '--').replace(/[^a-zA-Z0-9._-]/g, '_')}_pid${childPid}.log`
- Content format: metadata header (`task:`, `pid:`, `command:`, `exit:`, `signal:`, `duration:`, `timed_out:`) followed by `--- stdout ---` and `--- stderr ---` sections
- Serialized via promise chain (`logWriteQueue`) to prevent concurrent mkdir races from worker pool
- Failures silently swallowed (non-critical operation)

## Trace Event Emission

**setTracer(tracer)** enables ITraceWriter event emission:
- `subprocess:spawn` — Emitted synchronously in `onSpawn` callback with childPid, command, taskLabel
- `subprocess:exit` — Emitted after subprocess completion with childPid, exitCode, signal, durationMs, timedOut
- `retry` — Emitted in retry handler with attempt number, taskLabel, errorCode

## Backend Integration

**AIBackend** interface (from `./types.js`) requires:
- `name: string` — Backend identifier (e.g., "Claude", "Gemini", "OpenCode")
- `cliCommand: string` — Executable name (e.g., "claude", "gemini", "opencode")
- `buildArgs(options: AICallOptions): string[]` — Constructs argv from options (model, prompt, systemPrompt)
- `parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse` — Extracts text, model, tokens, cacheReadTokens, cacheCreationTokens

**Backend adapter examples:**
- `./backends/claude.ts` — Parses JSON with `usage.input_tokens`, `usage.output_tokens`, `usage.cache_read_input_tokens`, `usage.cache_creation_input_tokens`
- `./backends/gemini.ts` — Stub implementation throwing SUBPROCESS_ERROR
- `./backends/opencode.ts` — Stub implementation throwing SUBPROCESS_ERROR

## Dependencies

- `runSubprocess()` from `./subprocess.js` — Spawns child processes with timeout, process group killing, SIGTERM/SIGKILL escalation
- `withRetry()` from `./retry.js` — Exponential backoff wrapper with isRetryable predicate and onRetry callback
- `TelemetryLogger` from `./telemetry/logger.js` — In-memory entry accumulation with summary aggregation
- `writeRunLog()` from `./telemetry/run-log.js` — Persists RunLog JSON to disk
- `cleanupOldLogs()` from `./telemetry/cleanup.js` — Prunes old logs via readdir + stat + unlink
- `ITraceWriter` from `../orchestration/trace.js` — Trace event emission interface (NullTraceWriter or TraceWriter with NDJSON output)

## Design Patterns

**Template Method pattern** — `call()` defines subprocess invocation skeleton, delegates backend-specific logic to `backend.buildArgs()` and `backend.parseResponse()`

**Strategy pattern** — Backend adapters (Claude, Gemini, OpenCode) implement AIBackend interface for pluggable CLI invocation

**Promise chaining for serialization** — `logWriteQueue` ensures sequential execution of async mkdir+writeFile to avoid race conditions from concurrent workers

**Resource tracking** — `activeSubprocesses` counter enables debug logging of subprocess concurrency for diagnosing resource exhaustion (see CLAUDE.md subprocess management section)