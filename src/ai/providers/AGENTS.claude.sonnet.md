<!-- Generated by agents-reverse-engineer v1.0.1 -->

# src/ai/providers

`src/ai/providers` implements AI provider abstraction layers that bridge the core `AIProvider` interface with subprocess-based CLI invocations, enabling configurable backend routing, timeout enforcement, rate-limit detection, and structured tracing for all AI service calls.

## Contents

- **[subprocess.ts](./subprocess.ts)**: `SubprocessProvider` implements `AIProvider` by spawning CLI subprocesses via `AIBackend.buildArgs()`, enforcing `timeoutMs` via `runSubprocess()`, parsing responses with `backend.parseResponse()`, detecting rate limits using `RATE_LIMIT_PATTERNS`, emitting `subprocess:spawn` and `subprocess:exit` trace events via `ITraceWriter`, and logging subprocess stdout/stderr to `subprocessLogDir` with serialized `logWriteQueue` to prevent mkdir races.

## Architecture

`SubprocessProvider` acts as an adapter: accepts `AIBackend` in constructor, delegates argument construction and response parsing to backend, enforces cross-cutting concerns (timeout, tracing, logging), and throws `AIServiceError` with typed codes (`TIMEOUT`, `RATE_LIMIT`, `SUBPROCESS_ERROR`, `PARSE_ERROR`). `setTracer()` enables late binding of trace writer post-construction. `setSubprocessLogDir()` configures optional persistent logging of subprocess output streams.

## Error Handling

`isRateLimitStderr()` detects rate-limit errors via pattern matching against `['rate limit', '429', 'too many requests', 'overloaded']`. `call()` throws `AIServiceError('TIMEOUT')` when subprocess exceeds `timeoutMs`, `AIServiceError('RATE_LIMIT')` when `isRateLimitStderr()` returns true, `AIServiceError('SUBPROCESS_ERROR')` on non-zero exit codes, `AIServiceError('PARSE_ERROR')` when `backend.parseResponse()` fails. All errors preserve original messages and stack traces.

## Tracing & Logging

Emits `subprocess:spawn` trace events with `type`, `childPid`, `command`, `taskLabel` on process start. Emits `subprocess:exit` events with additional `exitCode`, `signal`, `durationMs`, `timedOut` fields on completion. Tracks `activeCount` for debugging concurrent subprocess limits. Logs debug messages with memory usage formatted by `formatBytes()`. Writes subprocess logs to `${taskLabel}_pid${childPid}.log` within `subprocessLogDir`, serializing writes via promise chain to prevent concurrent mkdir/write races.

## Integration

Wraps `AIBackend` interface from `../types.js`, invoking `backend.buildArgs(options)` to construct subprocess arguments, optional `backend.composeStdinInput(options)` for stdin (defaults to `options.prompt`), and `backend.parseResponse(stdout, durationMs, exitCode)` to extract `AIResponse`. Calls `runSubprocess()` from `../subprocess.js` with constructed command, args, stdin input, timeout, and spawn callback. Returns structured `AIResponse` with `text`, `durationMs`, `model`.

## Behavioral Contracts

- **Rate Limit Detection**: `isRateLimitStderr()` matches case-insensitive patterns: `'rate limit'`, `'429'`, `'too many requests'`, `'overloaded'`
- **Subprocess Timeout**: Throws `AIServiceError('TIMEOUT', 'Subprocess timed out')` when `runSubprocess()` exceeds `timeoutMs`
- **Trace Event Schema**: `subprocess:spawn` emits `{type, childPid, command, taskLabel}`, `subprocess:exit` adds `{exitCode, signal, durationMs, timedOut}`
- **Log Filename Format**: `${taskLabel}_pid${childPid}.log` within `subprocessLogDir`