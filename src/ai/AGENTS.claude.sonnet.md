<!-- Generated by agents-reverse-engineer v1.0.1 -->

# src/ai

The `src/ai` directory provides the AI service layer abstraction for invoking AI coding assistants (Claude Code, Gemini, Codex, OpenCode) via CLI subprocesses, handling backend auto-detection, retry logic with exponential backoff, structured telemetry logging, and subprocess lifecycle management with timeout enforcement.

## Contents

- [`index.ts`](./index.ts): Barrel export consolidating `AIProvider`, `AIBackend`, `AIResponse`, `AICallOptions`, `SubprocessResult`, `RetryOptions`, `TelemetryEntry`, `RunLog`, `FileRead` types from `./types.js`; `AIServiceError` from `./types.js`; `AIService` and `AIServiceOptions` from `./service.js`; `BackendRegistry`, `createBackendRegistry()`, `resolveBackend()`, `detectBackend()`, `getInstallInstructions()` from `./registry.js`; `withRetry()`, `DEFAULT_RETRY_OPTIONS` from `./retry.js`; `runSubprocess()` from `./subprocess.js`; `SubprocessProvider`, `SubprocessProviderOptions` from `./providers/subprocess.js`; `isCommandOnPath()` from `./backends/common.js`
- [`registry.ts`](./registry.ts): `BackendRegistry` manages registered `AIBackend` instances with `register()`, `get()`, `getAll()` methods; `createBackendRegistry()` returns pre-populated registry with `ClaudeBackend`, `CodexBackend`, `GeminiBackend`, `OpenCodeBackend` in priority order; `detectBackend()` scans registry for first available backend via `isAvailable()`; `resolveBackend()` auto-detects or validates requested backend, throwing `AIServiceError('CLI_NOT_FOUND')` with install instructions on failure
- [`retry.ts`](./retry.ts): `withRetry<T>(fn, options)` executes async function with exponential backoff retry on transient failures, using delay formula `min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter[0,500ms]`, throwing immediately on permanent failure via `isRetryable(error)` predicate or after `maxRetries` exhaustion; `DEFAULT_RETRY_OPTIONS` sets `maxRetries: 3`, `baseDelayMs: 1000`, `maxDelayMs: 8000`, `multiplier: 2`
- [`service.ts`](./service.ts): `AIService` orchestrates AI calls with retry via `withRetry()`, telemetry via `TelemetryLogger`, subprocess log writing via `setSubprocessLogDir()`, optional tracing via `ITraceWriter`; `call(options)` merges service-level `model` default, wraps provider call with `withRetry()` (only retrying `RATE_LIMIT` errors, not `TIMEOUT`), records `TelemetryEntry`, increments `callCount`; `finalize(projectRoot)` writes run log via `writeRunLog()`, cleans old logs via `cleanupOldLogs()`, returns log path and summary; auto-wraps `AIBackend` via `SubprocessProvider` if not already `AIProvider`
- [`subprocess.ts`](./subprocess.ts): `runSubprocess(command, args, options)` spawns CLI subprocess via `execFile`, writes `options.input` to stdin, enforces `options.timeoutMs` via SIGTERM, escalates to SIGKILL after `SIGKILL_GRACE_MS` (5000ms), invokes synchronous `options.onSpawn(pid)` callback, tracks active subprocesses in `activeSubprocesses` Map, resolves with `SubprocessResult` containing `stdout`, `stderr`, `exitCode`, `signal`, `durationMs`, `timedOut`, `childPid`; `getActiveSubprocessCount()` and `getActiveSubprocesses()` expose runtime diagnostics; sets `maxBuffer: 10MB`, merges `process.env` with `options.env`
- [`types.ts`](./types.ts): TypeScript interfaces defining `SubprocessResult`, `AICallOptions`, `AIResponse`, `AIProvider`, `AIBackend`, `RetryOptions`, `FileRead`, `TelemetryEntry`, `RunLog`, `AIServiceErrorCode` (`'CLI_NOT_FOUND' | 'TIMEOUT' | 'PARSE_ERROR' | 'SUBPROCESS_ERROR' | 'RATE_LIMIT'`), and `AIServiceError` class

## Subdirectories

- [`backends/`](./backends/): CLI adapters for Claude Code, Gemini, Codex, OpenCode, implementing `AIBackend` interface with CLI argument construction, output parsing (JSON, NDJSON, JSONL), token metric extraction, model alias resolution, and system prompt integration via native flags or XML tags
- [`providers/`](./providers/): `SubprocessProvider` implements `AIProvider` by spawning CLI subprocesses via `AIBackend.buildArgs()`, enforcing timeout via `runSubprocess()`, detecting rate limits via pattern matching, emitting trace events, and logging subprocess output streams
- [`telemetry/`](./telemetry/): `TelemetryLogger` accumulates `TelemetryEntry[]` in-memory; `writeRunLog()` persists `RunLog` to `.agents-reverse-engineer/logs/run-{command}-{backend}-{model}-{timestamp}.json`; `cleanupOldLogs()` enforces retention policy

## Architecture

**Request Flow**: CLI commands invoke `createBackendRegistry()` → `resolveBackend(registry, 'auto')` → `new AIService(backend, {timeoutMs, maxRetries, telemetry})` → `service.call({prompt, systemPrompt, model, taskLabel})` → `SubprocessProvider.call()` → `runSubprocess()` → backend-specific CLI invocation → `backend.parseResponse()` → `AIResponse` normalization → telemetry recording → retry on `RATE_LIMIT` errors.

**Backend Auto-Detection**: `detectBackend()` scans registry in priority order (Claude → Codex → Gemini → OpenCode), calling `isAvailable()` (PATH detection via `isCommandOnPath()`) on each until first match, throwing `AIServiceError('CLI_NOT_FOUND')` with aggregated install instructions if none available.

**Provider Abstraction**: `AIService` accepts `AIProvider | AIBackend`; if `AIBackend`, auto-wraps via `SubprocessProvider`; uses `isAIBackend()` type guard checking for `buildArgs`, `parseResponse`, `cliCommand` properties.

## Retry Strategy

`AIService.call()` retries only `RATE_LIMIT` errors via `withRetry()` with `DEFAULT_RETRY_OPTIONS` and user-configured `maxRetries`. `TIMEOUT` errors are **not** retried to prevent resource exhaustion. Delay formula: `min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter[0,500ms]` where jitter prevents thundering herd. `onRetry` callback logs warnings, increments `retryCount`, emits `{type: 'retry', attempt, taskLabel, errorCode}` trace events.

## Telemetry

`TelemetryLogger` accumulates per-call `TelemetryEntry` with `timestamp`, `prompt`, `systemPrompt`, `response`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `latencyMs`, `exitCode`, `retryCount`, `thinking: 'not supported'`, `filesRead: FileRead[]`, optional `error`. `finalize()` produces `RunLog` with aggregate `summary` (`totalCalls`, `totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheCreationTokens`, `totalDurationMs`, `errorCount`, `totalFilesRead`, `uniqueFilesRead`), writes to timestamped JSON file via `writeRunLog()`, enforces retention via `cleanupOldLogs(projectRoot, keepCount)`.

## Subprocess Management

`runSubprocess()` tracks active subprocesses in `activeSubprocesses` Map (pid → `{command, spawnedAt}`), untracked on exit. Timeout detection via `error.killed === true` from `execFile`. SIGTERM sent on timeout, escalation to SIGKILL after `SIGKILL_GRACE_MS` (5000ms), unref'd to prevent event loop blocking. Attempts process group kill `process.kill(-child.pid, 'SIGKILL')` before single process `process.kill(child.pid, 'SIGKILL')`. Stdin always closed via `child.stdin.end()` to prevent EOF blocking. `maxBuffer: 10MB` for large AI responses.

## Error Handling

`AIServiceError` extends Error with `code: AIServiceErrorCode` for machine-readable branching. `resolveBackend()` throws `CLI_NOT_FOUND` with install instructions when backend unavailable. `SubprocessProvider` throws `TIMEOUT` when subprocess exceeds `timeoutMs`, `RATE_LIMIT` when stderr matches patterns (`['rate limit', '429', 'too many requests', 'overloaded']`), `SUBPROCESS_ERROR` on non-zero exit, `PARSE_ERROR` when `backend.parseResponse()` fails. All errors preserve original messages and stack traces.

## Behavioral Contracts

**Backend Priority Order** (from `registry.ts`):
```
Claude → Codex → Gemini → OpenCode
```

**Default Retry Options** (from `retry.ts`):
```javascript
{
  maxRetries: 3,
  baseDelayMs: 1000,
  maxDelayMs: 8000,
  multiplier: 2
}
```

**Subprocess Timeout Escalation** (from `subprocess.ts`):
```
SIGKILL_GRACE_MS = 5000
```

**Telemetry Log Filename Pattern** (from `telemetry/run-log.ts`):
```
.agents-reverse-engineer/logs/run-{command}-{backend}-{model}-{timestamp}.json
```

**Rate Limit Patterns** (from `providers/subprocess.ts`):
```javascript
['rate limit', '429', 'too many requests', 'overloaded']
```

**Thinking Field Literal** (from `service.ts`):
```javascript
thinking: 'not supported'
```