---
generated_at: 2026-02-09T17:44:29.075Z
content_hash: 8b123030a9ae9b650e3148fccfc8bcfe2bc0e1b2bb0bfa9db2d6a0d7901c3178
purpose: Barrel export aggregating AI service layer public API: exports AIService orchestrator, BackendRegistry with resolveBa...
---
**Barrel export aggregating AI service layer public API: exports AIService orchestrator, BackendRegistry with resolveBackend/detectBackend/createBackendRegistry, withRetry retry utility, runSubprocess wrapper, isCommandOnPath utility, and all types from ./types.js (AIBackend, AIResponse, AICallOptions, SubprocessResult, RetryOptions, TelemetryEntry, RunLog, FileRead, AIServiceError) with AIServiceOptions from ./service.js.**

## Exported Symbols

**Types:**
- `AIBackend` — Backend interface with `name`, `isAvailable()`, `call()` methods
- `AIResponse` — Response shape with `content: string`, `tokensUsed`, `costUsd` metrics
- `AICallOptions` — Call parameters with `prompt: string`, `fileContext`, `model`, `taskType`, `filePath`
- `SubprocessResult` — Subprocess execution result with `stdout`, `stderr`, `exitCode`, `signal`, `error`
- `RetryOptions` — Retry configuration with `maxAttempts: number`, `baseDelayMs: number`, `maxDelayMs: number`, `shouldRetry: (error) => boolean`
- `TelemetryEntry` — Per-call telemetry with `timestamp`, `backend`, `model`, `tokensUsed`, `costUsd`, `durationMs`, `error`, `filesRead`
- `RunLog` — Aggregated run metadata with `runId`, `startTime`, `endTime`, `totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheWriteTokens`, `totalCostUsd`, `totalDurationMs`, `errorCount`, `uniqueFilesRead`, `entries: TelemetryEntry[]`
- `FileRead` — File read metadata with `path: string`, `sizeBytes: number`, `linesRead: number`
- `AIServiceOptions` — Service constructor options from `./service.js`

**Error Class:**
- `AIServiceError` — Custom error class for AI service failures

**Service Orchestrator:**
- `AIService` — Main service class coordinating backend calls, retry logic, telemetry logging

**Backend Registry:**
- `BackendRegistry` — Registry class managing available backends
- `createBackendRegistry()` — Factory creating registry with Claude/Gemini/OpenCode backends registered
- `resolveBackend(registry: BackendRegistry, backendName: string): Promise<AIBackend>` — Resolves backend by name ('claude' | 'gemini' | 'opencode' | 'auto'), auto-detection tries backends in order until `isAvailable()` succeeds
- `detectBackend(registry: BackendRegistry): Promise<AIBackend | null>` — Auto-detects first available backend
- `getInstallInstructions(backendName: string): string` — Returns installation instructions for specified backend

**Retry Utility:**
- `withRetry<T>(fn: () => Promise<T>, options?: RetryOptions): Promise<T>` — Exponential backoff retry wrapper
- `DEFAULT_RETRY_OPTIONS` — Default retry configuration constant

**Subprocess Wrapper:**
- `runSubprocess(options: {...}): Promise<SubprocessResult>` — Spawns subprocess with resource limits, timeout enforcement, process group killing

**Backend Utilities:**
- `isCommandOnPath(command: string): Promise<boolean>` — Checks if command exists in PATH via `which` (Unix) or `where` (Windows)

## Architecture Role

Serves as the single entry point for AI service layer consumption by CLI commands and orchestration modules. Prevents direct imports from `src/ai/backends/` or `src/ai/telemetry/` by re-exporting all necessary symbols. Consumers import from `./ai/index.js` exclusively.

## Module Isolation Boundary

Enforces encapsulation of backend implementations (Claude/Gemini/OpenCode adapters in `./backends/`) and telemetry subsystem (`./telemetry/`) by exposing only high-level abstractions. Internal implementation details remain hidden behind `AIBackend` interface and `AIService` orchestrator.

## Usage Pattern

```typescript
import { AIService, createBackendRegistry, resolveBackend } from './ai/index.js';

const registry = createBackendRegistry();
const backend = await resolveBackend(registry, 'auto');
const service = new AIService(backend, {
  timeoutMs: 120_000,
  maxRetries: 3,
  telemetry: { keepRuns: 10 },
});

const response = await service.call({ prompt: 'Hello' });
```