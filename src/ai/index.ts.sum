---
generated_at: 2026-02-09T16:09:25.839Z
content_hash: 8b123030a9ae9b650e3148fccfc8bcfe2bc0e1b2bb0bfa9db2d6a0d7901c3178
purpose: Barrel export consolidating AI service layer into single public interface: AIService, BackendRegistry, createBackendR...
---
**Barrel export consolidating AI service layer into single public interface: AIService, BackendRegistry, createBackendRegistry, resolveBackend, detectBackend, getInstallInstructions, withRetry, runSubprocess, isCommandOnPath, plus type exports (AIBackend, AIResponse, AICallOptions, SubprocessResult, RetryOptions, TelemetryEntry, RunLog, FileRead) and AIServiceError.**

## Public API Surface

All imports from `src/ai/` must go through this barrel export. Direct imports from `src/ai/backends/` or `src/ai/telemetry/` violate encapsulation.

### Service Orchestration

- **AIService** (class) — Main orchestrator for AI backend calls with telemetry, retries, timeout enforcement
- **AIServiceOptions** (type) — Configuration interface: `timeoutMs`, `maxRetries`, `telemetry: { keepRuns }`, optional tracer

### Backend Registry

- **BackendRegistry** (class) — Container for backend implementations with registration and lookup
- **createBackendRegistry(): BackendRegistry** — Factory initializing registry with Claude, Gemini, OpenCode backends
- **resolveBackend(registry: BackendRegistry, name: string | 'auto'): Promise<AIBackend>** — Returns backend by name or auto-detects first available
- **detectBackend(registry: BackendRegistry): Promise<AIBackend | null>** — Iterates registry to find first backend with available command
- **getInstallInstructions(backendName: string): string** — Returns installation instructions for specified backend

### Retry Logic

- **withRetry<T>(fn: () => Promise<T>, options?: RetryOptions): Promise<T>** — Exponential backoff retry wrapper
- **DEFAULT_RETRY_OPTIONS** (const) — Default retry configuration

### Subprocess Management

- **runSubprocess(options: SubprocessOptions): Promise<SubprocessResult>** — Spawns AI CLI child process with timeout, resource limits, process group killing

### Backend Utilities

- **isCommandOnPath(command: string): Promise<boolean>** — Checks command availability via `which` (exported from `backends/claude.ts`)

## Type Exports

- **AIBackend** — Interface with `name`, `command`, `buildArgs()`, `parseResponse()`, `isAvailable()`
- **AIResponse** — Standardized response: `content: string`, `finishReason: string`, `usage?: TokenUsage`
- **AICallOptions** — Call parameters: `prompt: string`, `temperature?: number`, `maxTokens?: number`, `systemPrompt?: string`
- **SubprocessResult** — Execution result: `stdout: string`, `stderr: string`, `exitCode: number | null`, `signal: string | null`, `pid?: number`, `durationMs: number`
- **RetryOptions** — Retry config: `maxRetries: number`, `initialDelayMs: number`, `maxDelayMs: number`, `backoffFactor: number`
- **TelemetryEntry** — Per-call telemetry: `timestamp`, `backend`, `model`, `durationMs`, `tokens`, `cost`, `error?`, `filesRead[]`
- **RunLog** — Aggregated run log: `startTime`, `endTime`, `calls[]`, `summary: { totalCost, errorCount, uniqueFilesRead }`
- **FileRead** — File metadata: `path: string`, `sizeBytes: number`, `linesRead: number`

## Error Types

- **AIServiceError** (class extends Error) — Discriminated error with `code` property values: `'BACKEND_NOT_FOUND'`, `'SUBPROCESS_ERROR'`, `'TIMEOUT'`, `'RATE_LIMIT'`, `'PARSE_ERROR'`, `'CONFIG_ERROR'`

## Usage Pattern

```typescript
import { AIService, createBackendRegistry, resolveBackend } from './ai/index.js';

const registry = createBackendRegistry();
const backend = await resolveBackend(registry, 'auto');
const service = new AIService(backend, {
  timeoutMs: 120_000,
  maxRetries: 3,
  telemetry: { keepRuns: 10 },
});

const response = await service.call({ prompt: 'Hello' });
```

## Module Constraints

This barrel export enforces layering: consumers import from `ai/index.js`, never reaching into `ai/backends/` or `ai/telemetry/` directly. Internal modules remain encapsulated.