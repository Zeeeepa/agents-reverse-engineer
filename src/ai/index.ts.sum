---
generated_at: 2026-02-09T15:06:30.598Z
content_hash: 8b123030a9ae9b650e3148fccfc8bcfe2bc0e1b2bb0bfa9db2d6a0d7901c3178
purpose: Barrel export module unifying AI service layer public API with backend registry, retry utilities, subprocess executio...
---
**Barrel export module unifying AI service layer public API with backend registry, retry utilities, subprocess execution, and telemetry types.**

## Exported Types

- `AIBackend` — Interface defining backend contract (name, detectAvailable, spawn)
- `AIResponse` — Parsed response from AI subprocess (content, metadata, tokenUsage, cachingMetrics)
- `AICallOptions` — Parameters for `AIService.call()` (prompt, filePath, promptType, disallowedTools, modelOverride, contextPaths, tracer)
- `SubprocessResult` — Raw subprocess execution result (stdout, stderr, exitCode, signal, duration, killed)
- `RetryOptions` — Exponential backoff configuration (maxRetries, initialDelayMs, backoffFactor, maxDelayMs, shouldRetry predicate)
- `TelemetryEntry` — Per-call telemetry record (callId, timestamp, promptType, filePath, duration, tokenUsage, cachingMetrics, error, filesRead)
- `RunLog` — Aggregated run metadata (runId, timestamp, backend, totalCalls, totalInputTokens, totalOutputTokens, totalCacheReadTokens, totalCacheWriteTokens, totalCost, errorCount, uniqueFilesRead, filesRead)
- `FileRead` — File access metadata (path, sizeBytes, linesRead)
- `AIServiceError` — Error class with code discriminator (BACKEND_UNAVAILABLE, SUBPROCESS_ERROR, VALIDATION_ERROR, RATE_LIMIT, TIMEOUT)
- `AIServiceOptions` — Constructor options for `AIService` (timeoutMs, maxRetries, telemetry config with enabled/keepRuns/costThresholdUsd, pricing per backend)

## Exported Classes and Functions

- `AIService` — Main orchestrator with `call(options: AICallOptions): Promise<AIResponse>` invoking subprocess via retry wrapper, telemetry emission to `.agents-reverse-engineer/logs/run-<timestamp>.json`, and response validation
- `BackendRegistry` — Registry class with `register(backend: AIBackend)` and `get(name: string): AIBackend | undefined` methods
- `createBackendRegistry(): BackendRegistry` — Factory initializing registry with Claude/Gemini/OpenCode backends pre-registered
- `resolveBackend(registry: BackendRegistry, name: string): Promise<AIBackend>` — Backend resolution with 'auto' detection fallback
- `detectBackend(registry: BackendRegistry): Promise<AIBackend | null>` — First-available detection across registered backends via `detectAvailable()` calls
- `getInstallInstructions(backendName: string): string` — Returns installation commands for Claude/Gemini/OpenCode
- `withRetry<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T>` — Exponential backoff wrapper with rate limit detection (stderr pattern matching: "rate limit", "429", "too many requests", "overloaded")
- `DEFAULT_RETRY_OPTIONS` — Default retry config (maxRetries: 3, initialDelayMs: 1000, backoffFactor: 2, maxDelayMs: 30000)
- `runSubprocess(backend: AIBackend, options: AICallOptions, timeoutMs: number): Promise<SubprocessResult>` — Spawns child process via `execFile()` with resource limits (NODE_OPTIONS='--max-old-space-size=512', UV_THREADPOOL_SIZE='4', CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'), SIGTERM/SIGKILL timeout enforcement, process group killing via `kill(-pid)`
- `isCommandOnPath(command: string): boolean` — Binary availability check via `which` command (sourced from `claude.ts` backend)

## Module Purpose

Enforces encapsulation boundary for AI service layer by preventing direct imports from `src/ai/backends/` or `src/ai/telemetry/` subdirectories. All consumers import through this index: `import { AIService, resolveBackend } from './ai/index.js'`.

## Integration Points

Consumed by:
- `src/generation/executor.ts` — Constructs `AIService` instance with config-derived options, calls `service.call()` per file/directory/root task
- `src/cli/generate.ts` and `src/cli/update.ts` — Pass `tracer` from `CommandRunOptions` to `AICallOptions` for NDJSON trace emission
- `src/orchestration/runner.ts` — Threads `ITraceWriter` instance through `AIService` call chain for subprocess event logging

## Backend Implementations

Registry pre-populates with:
- `ClaudeBackend` (`src/ai/backends/claude.ts`) — Spawns `claude-code --disallowedTools Task --stdin` subprocess
- `GeminiBackend` (`src/ai/backends/gemini.ts`) — Stub throwing `SUBPROCESS_ERROR` until JSON output format stabilizes
- `OpenCodeBackend` (`src/ai/backends/opencode.ts`) — Stub throwing `SUBPROCESS_ERROR` until JSONL parsing implemented