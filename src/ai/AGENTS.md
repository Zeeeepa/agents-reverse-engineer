<!-- Generated by agents-reverse-engineer -->

# src/ai

AI service orchestration layer providing backend-agnostic subprocess management, exponential backoff retry, telemetry logging, and trace emission for concurrent worker pools executing file analysis, directory aggregation, and root synthesis phases.

## Contents

### Core Orchestration

**[service.ts](./service.ts)** — `AIService` class orchestrates subprocess invocations via `call(options: AICallOptions): Promise<AIResponse>`, wrapping `runSubprocess()` in `withRetry()` exponential backoff with rate limit detection (stderr patterns: "rate limit", "429", "too many requests", "overloaded"), parsing responses via `AIBackend.parseResponse()`, accumulating `TelemetryEntry` records through `TelemetryLogger.addEntry()`, emitting subprocess lifecycle trace events (`subprocess:spawn`, `subprocess:exit`, `retry`) to optional `ITraceWriter`, enforcing resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`), and finalizing runs via `finalize()` producing `RunLog` JSON files with `cleanupOldLogs()` retention enforcement.

**[subprocess.ts](./subprocess.ts)** — `runSubprocess(command: string, args: string[], options: SubprocessOptions): Promise<SubprocessResult>` spawns AI CLI via `execFile()` with SIGTERM timeout at `options.timeoutMs`, SIGKILL escalation after `SIGKILL_GRACE_MS` (5000ms) grace period, stdin piping via `.end()` for EOF delivery, process group killing via `kill(-pid)` for subprocess tree termination, unref'd timeout handles preventing event loop blocking, and active subprocess tracking via `activeSubprocesses` Map exposing `getActiveSubprocessCount()` and `getActiveSubprocesses()` concurrency diagnostics.

**[registry.ts](./registry.ts)** — `BackendRegistry` manages insertion-order `AIBackend` instances with `register()`, `get()`, `getAll()` methods, `createBackendRegistry()` factory pre-populates with ClaudeBackend, GeminiBackend, OpenCodeBackend in priority order, `detectBackend()` iterates `getAll()` calling `isAvailable()` returning first available backend or null, `resolveBackend()` handles auto-detection and explicit selection with `AIServiceError('CLI_NOT_FOUND')` thrown when unavailable, `getInstallInstructions()` aggregates `backend.getInstallInstructions()` into newline-separated multi-line string.

**[retry.ts](./retry.ts)** — `withRetry<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T>` executes async function with exponential backoff calculated as `min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter` where jitter is `Math.random() * 500`, invokes `isRetryable(error)` predicate to distinguish transient (rate limit, network timeout) from permanent failures (authentication, invalid input), calls `onRetry?.(attempt, error)` callback before delay, terminates immediately on non-retryable errors or after exhausting `maxRetries`, `DEFAULT_RETRY_OPTIONS` exports baseline configuration (`maxRetries: 3`, `baseDelayMs: 1000`, `maxDelayMs: 8000`, `multiplier: 2`).

**[types.ts](./types.ts)** — Defines `AIBackend` interface requiring `name`, `cliCommand`, `isAvailable()`, `buildArgs()`, `parseResponse()`, `getInstallInstructions()`, `SubprocessResult` capturing `stdout`, `stderr`, `exitCode`, `signal`, `durationMs`, `timedOut`, `childPid`, `AICallOptions` with `prompt`, `systemPrompt?`, `model?`, `timeoutMs?`, `maxTurns?`, `taskLabel?`, `AIResponse` normalizing `text`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `exitCode`, `raw`, `RetryOptions` with `maxRetries`, `baseDelayMs`, `maxDelayMs`, `multiplier`, `isRetryable`, `onRetry?`, `TelemetryEntry` logging `timestamp`, `prompt`, `systemPrompt?`, `response`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `latencyMs`, `exitCode`, `error?`, `retryCount`, `thinking`, `filesRead`, `RunLog` aggregating `runId`, `startTime`, `endTime`, `entries`, `summary` with token totals, `FileRead` tracking `path`, `sizeBytes`, `AIServiceError` with `AIServiceErrorCode` enum (`'CLI_NOT_FOUND'`, `'TIMEOUT'`, `'PARSE_ERROR'`, `'SUBPROCESS_ERROR'`, `'RATE_LIMIT'`).

**[index.ts](./index.ts)** — Barrel export enforcing encapsulation boundary by re-exporting `AIService`, `BackendRegistry`, `createBackendRegistry()`, `resolveBackend()`, `detectBackend()`, `getInstallInstructions()`, `withRetry()`, `DEFAULT_RETRY_OPTIONS`, `runSubprocess()`, `isCommandOnPath()`, all types from `types.ts`, preventing direct imports from `backends/` or `telemetry/` subdirectories.

## Subdirectories

**[backends/](./backends/)** — ClaudeBackend, GeminiBackend, OpenCodeBackend implementations with `buildArgs()` constructing CLI argument arrays, `parseResponse()` extracting AIResponse from JSON stdout (GeminiBackend and OpenCodeBackend are stubs throwing `SUBPROCESS_ERROR`), `isAvailable()` detecting CLI via PATH scanning, `getInstallInstructions()` returning npm/installation commands, shared `isCommandOnPath()` utility in claude.ts iterating PATH directories with platform-specific PATHEXT handling.

**[telemetry/](./telemetry/)** — `TelemetryLogger` accumulating `TelemetryEntry` instances with `addEntry()` and `setFilesReadOnLastEntry()`, computing aggregate statistics via `getSummary()` (total tokens, error counts, unique files), `writeRunLog()` serializing `RunLog` objects to timestamped JSON files (`.agents-reverse-engineer/logs/run-<timestamp>.json`) with `:` and `.` sanitization to `-`, `cleanupOldLogs()` enforcing retention limits via lexicographic sort descending and `fs.unlink()` deletion.

## Architecture Patterns

### Backend Abstraction

`AIBackend` interface decouples service layer from CLI-specific invocations enabling runtime backend selection via `resolveBackend()`. Registry pattern in `BackendRegistry` supports auto-detection (`backend: 'auto'`) and explicit selection (`backend: 'claude'`). Backends implement argument construction (`buildArgs`), response parsing (`parseResponse`), and availability detection (`isAvailable`) allowing seamless backend swapping without modifying service layer.

### Subprocess Resource Management

`runSubprocess()` mitigates Claude CLI thread exhaustion (GitHub #5771: 200 NodeJS instances) via environment variables limiting heap (`NODE_OPTIONS='--max-old-space-size=512'`), thread pool (`UV_THREADPOOL_SIZE='4'`), and background tasks (`CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`). Process group killing via `kill(-pid)` terminates entire subprocess tree preventing zombie processes. Default concurrency reduced from 5 → 2 for WSL environments. `activeSubprocesses` Map tracks concurrent processes with `getActiveSubprocessCount()` and `getActiveSubprocesses()` diagnostics.

### Retry Strategy

`withRetry()` wrapper applies exponential backoff to transient failures identified by `isRetryable()` predicate. `AIService.call()` configures predicate allowing only `AIServiceError` with `code === 'RATE_LIMIT'` (timeouts NOT retried). Rate limit detection in `isRateLimitStderr()` scans subprocess stderr for `['rate limit', '429', 'too many requests', 'overloaded']` patterns. Jitter (0-500ms) prevents thundering herd on shared backend APIs.

### Telemetry Accumulation

`TelemetryLogger` accumulates per-call metadata in memory during run via `addEntry()` invoked after each subprocess completion. `FileRead` metadata attached via `setFilesReadOnLastEntry()` after file context determination. `toRunLog()` assembles complete `RunLog` with shallow-copied entries and `getSummary()` aggregations (total tokens, error counts, unique files). `writeRunLog()` serializes to timestamped JSON enabling post-run cost analysis. `cleanupOldLogs()` enforces `Config.ai.telemetry.keepRuns` retention limit (default 50) via lexicographic sort descending.

### Trace Emission

`AIService` accepts optional `ITraceWriter` via `setTracer()`, emits `subprocess:spawn` events synchronously after `execFile()` returns child object with `.pid`, emits `subprocess:exit` events after completion with `exitCode`, `signal`, `durationMs`, `timedOut`, emits `retry` events via `withRetry()` `onRetry` callback with `attempt`, `taskLabel`, `errorCode`. Trace writer serializes events through promise chain in `src/orchestration/trace.ts` ensuring NDJSON line order despite concurrent worker emissions.

## Integration Points

**Consumed By:**
- `src/generation/executor.ts` — Constructs `AIService` instances with config-derived `AIServiceOptions`, invokes `call()` per file/directory/root task in three-phase pipeline
- `src/cli/generate.ts`, `src/cli/update.ts` — Thread `ITraceWriter` from `CommandRunOptions` to `AICallOptions` for NDJSON trace emission
- `src/orchestration/runner.ts` — Passes `tracer` through `AIService.call()` chain for subprocess event logging

**Provides To:**
- Backend adapters in `src/ai/backends/` import `AIBackend`, `AICallOptions`, `AIResponse`, `SubprocessResult` for interface compliance
- Telemetry modules import `TelemetryEntry`, `RunLog`, `FileRead` for schema definitions
- Quality validators import `AIServiceError` for error type discrimination