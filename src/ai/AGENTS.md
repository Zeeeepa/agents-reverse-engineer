<!-- Generated by agents-reverse-engineer -->

# src/ai

AI service layer implementing backend-agnostic subprocess orchestration with exponential backoff retry, timeout enforcement (SIGTERM→SIGKILL escalation), telemetry recording (per-call tokens/latency/cost), and registry-based runtime selection for Claude/Gemini/OpenCode CLI backends.

## Contents

**[index.ts](./index.ts)** — Barrel export enforcing architectural boundary: re-exports `AIService`, `AIServiceOptions` from `./service.js`, `BackendRegistry`, `createBackendRegistry()`, `resolveBackend()`, `detectBackend()`, `getInstallInstructions()` from `./registry.js`, `withRetry()`, `DEFAULT_RETRY_OPTIONS` from `./retry.js`, `runSubprocess()` from `./subprocess.js`, `SubprocessProvider` from `./providers/subprocess.js`, `isCommandOnPath()` from `./backends/claude.js`, all types (`AIProvider`, `AIBackend`, `AIResponse`, `AICallOptions`, `SubprocessResult`, `RetryOptions`, `TelemetryEntry`, `RunLog`, `FileRead`, `AIServiceError`, `SubprocessProviderOptions`) from `./types.js`. Prohibits direct imports from `backends/`, `telemetry/`, or `providers/` subdirectories.

**[registry.ts](./registry.ts)** — `BackendRegistry` stores `AIBackend` instances in insertion-order Map (determines auto-detection priority), `createBackendRegistry()` pre-populates ClaudeBackend→GeminiBackend→OpenCodeBackend, `detectBackend()` returns first `isAvailable()` backend or null, `resolveBackend(requested)` handles `'auto'` via `detectBackend()` or explicit name lookup with `isAvailable()` validation, throws `AIServiceError` code `CLI_NOT_FOUND` with `getInstallInstructions()` on failure.

**[retry.ts](./retry.ts)** — `withRetry<T>(fn, options)` executes fn with exponential backoff (`min(baseDelayMs * multiplier^attempt, maxDelayMs) + random(500)`), retries only when `options.isRetryable(error) === true`, invokes `options.onRetry?.(attempt, error)` before sleep, throws immediately on non-retryable errors or exhausted retries. `DEFAULT_RETRY_OPTIONS` provides `maxRetries: 3, baseDelayMs: 1_000, maxDelayMs: 8_000, multiplier: 2`.

**[service.ts](./service.ts)** — `AIService` orchestrates AI calls with `AIProvider` or `AIBackend` (auto-wrapped in `SubprocessProvider`): `call(options)` merges service-level model default, wraps `provider.call()` in `withRetry()` (retries only `RATE_LIMIT` errors, not `TIMEOUT`), records `TelemetryLogger.addEntry()` with tokens/latency/error, emits `retry` trace events via `tracer?.emit()`. `finalize(projectRoot)` writes `RunLog` via `writeRunLog()`, invokes `cleanupOldLogs()` retention. `setTracer()` forwards to `SubprocessProvider` for `subprocess:spawn`/`subprocess:exit` events. `setSubprocessLogDir()` forwards to `SubprocessProvider` for `.log` file serialization. Maintains `callCount` and in-memory `TelemetryLogger`.

**[subprocess.ts](./subprocess.ts)** — `runSubprocess(command, args, options)` spawns child via `execFile` with `maxBuffer: 10MB`, pipes `options.input` to stdin then calls `.end()`, enforces `options.timeoutMs` with SIGTERM, escalates to `process.kill(-childPid, 'SIGKILL')` after `SIGKILL_GRACE_MS` (5000ms), always resolves with `SubprocessResult` (never rejects), tracks active processes in Map, fires `options.onSpawn(childPid)` callback synchronously. Exports `getActiveSubprocessCount()`, `getActiveSubprocesses()` for debugging concurrency.

**[types.ts](./types.ts)** — Defines `AIProvider` interface (`call(options): Promise<AIResponse>`), `AIBackend` interface (`isAvailable`, `buildArgs`, `parseResponse`, `getInstallInstructions`), `AICallOptions` (`prompt`, `systemPrompt?`, `model?`, `timeoutMs?`, `maxTurns?`, `taskLabel?`), `AIResponse` normalized shape (`text`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `exitCode`, `raw`), `SubprocessResult` (`stdout`, `stderr`, `exitCode`, `signal`, `durationMs`, `timedOut`, `childPid?`), `RetryOptions`, `TelemetryEntry`, `RunLog`, `FileRead`, `AIServiceErrorCode` union (`CLI_NOT_FOUND | TIMEOUT | PARSE_ERROR | SUBPROCESS_ERROR | RATE_LIMIT`), `AIServiceError` class.

## Subdirectories

**[backends/](./backends/)** — Concrete `AIBackend` implementations: `ClaudeBackend` (full JSON/NDJSON parsing via `ClaudeResponseSchema`, `--allowedTools Read,Write`, `--model`/`--system-prompt`/`--max-turns` flags), `GeminiBackend` + `OpenCodeBackend` stubs (both throw `SUBPROCESS_ERROR` in `parseResponse()` pending CLI stabilization). Exports shared `isCommandOnPath()` for PATH detection.

**[providers/](./providers/)** — `AIProvider` implementations: `SubprocessProvider` wraps `AIBackend` in provider interface, spawns subprocess via `runSubprocess()`, parses response via `backend.parseResponse()`, emits `subprocess:spawn`/`subprocess:exit` trace events, serializes subprocess logs via promise chain to `.log` files when `subprocessLogDir` set.

**[telemetry/](./telemetry/)** — Telemetry accumulation (`TelemetryLogger.addEntry()`, `getSummary()` totals, `toRunLog()`), persistence (`writeRunLog()` to `.agents-reverse-engineer/logs/run-${timestamp}.json`), retention (`cleanupOldLogs()` deletes oldest beyond `keepRuns` config).

## Architecture

### Three-Layer Call Flow

1. **Registry Layer** (`registry.ts`): `createBackendRegistry()` → `resolveBackend('auto')` → `detectBackend()` iterates backends calling `isAvailable()` → returns first available or throws `CLI_NOT_FOUND`
2. **Service Layer** (`service.ts`): `AIService.call(options)` → `withRetry(() => provider.call(...))` → `logger.addEntry()` telemetry → returns `AIResponse`
3. **Provider Layer** (`providers/subprocess.ts`): `SubprocessProvider.call()` → `backend.buildArgs()` → `runSubprocess()` → `backend.parseResponse()` → optional subprocess log write
4. **Subprocess Layer** (`subprocess.ts`): `runSubprocess()` spawns `execFile`, pipes stdin, enforces timeout, tracks active processes, returns `SubprocessResult` (never throws)

### Retry Strategy

`AIService.call()` configures `withRetry()` with `isRetryable: (error) => error instanceof AIServiceError && error.code === 'RATE_LIMIT'`. Timeouts are NOT retried (prevents resource exhaustion). Rate-limit detection performed in backend `parseResponse()` implementations. Retry callback increments `retryCount`, logs `[warn] Retrying "${taskLabel}" (attempt ${attempt}/${maxRetries}, reason: ${errorCode})`, emits `tracer.emit({ type: 'retry', attempt, taskLabel, errorCode })`.

### Timeout Escalation

`subprocess.ts` sets `timeout: options.timeoutMs` with `killSignal: 'SIGTERM'` in `execFile`. Parallel `setTimeout` schedules SIGKILL at `timeoutMs + SIGKILL_GRACE_MS`. On exit, clears timer. SIGKILL targets process group (`process.kill(-childPid, 'SIGKILL')`) to kill child and descendants, falls back to single-process kill if group kill fails. Timeout detection: `timedOut = error?.killed === true`.

### Telemetry Recording

`TelemetryLogger` accumulates `TelemetryEntry[]` in memory with fields: `timestamp`, `prompt`, `systemPrompt`, `response`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `latencyMs`, `exitCode`, `error`, `retryCount`, `thinking: 'not supported'`, `filesRead`. `getSummary()` totals tokens/duration/errors, counts unique file paths. `toRunLog()` produces `RunLog` with `runId`, `startTime`, `endTime`, `entries`, `summary`. `AIService.finalize()` writes JSON and prunes old logs.

### Provider Abstraction

`AIProvider` interface enables swapping AI transport layer without changing pipeline. `AIService` detects legacy `AIBackend` via `isAIBackend()` type guard (checks `buildArgs`, `parseResponse`, `cliCommand` properties) and auto-wraps in `SubprocessProvider`. Custom providers can implement HTTP API clients, in-memory mocks, or alternative CLIs.

## Behavioral Contracts

### Exponential Backoff Formula
```javascript
delay = min(baseDelayMs * multiplier^attempt, maxDelayMs) + random(500)
// Defaults: baseDelayMs=1000, multiplier=2, maxDelayMs=8000, jitter=[0,500ms]
```

### Timeout Detection
```typescript
timedOut = error !== null && 'killed' in error && error.killed === true
```

### SIGKILL Escalation Delay
```typescript
SIGKILL_GRACE_MS = 5000  // milliseconds after SIGTERM
```

### Subprocess Log Filename Sanitization
```typescript
sanitized = taskLabel.replace(/\//g, '--').replace(/[^a-zA-Z0-9._-]/g, '_')
filename = `${sanitized}_pid${childPid}.log`
```

### Telemetry Log Retention
```javascript
cleanupOldLogs(projectRoot, keepCount)
// Filters: run-*.json sorted lexicographically, deletes oldest beyond keepCount
```

### Backend Priority Order
```typescript
// From createBackendRegistry() insertion order
['ClaudeBackend', 'GeminiBackend', 'OpenCodeBackend']
```

### Exit Code Extraction
```typescript
exitCode = error === null ? 0 :
           typeof error.code === 'number' ? error.code :
           child.exitCode !== null ? child.exitCode : 1
```

### ClaudeBackend CLI Flags
```javascript
['-p', '--output-format', 'json', '--no-session-persistence', '--allowedTools', 'Read', 'Write']
// Optional: --model, --system-prompt, --max-turns
```

### Subprocess maxBuffer
```typescript
maxBuffer: 10 * 1024 * 1024  // 10MB for large AI responses
```

## Integration Points

`src/generation/orchestrator.ts` calls `resolveBackend()` + `new AIService()`, invokes `service.call()` in worker pool (`runPool()` from `src/orchestration/pool.ts`), attaches filesRead metadata via `service.addFilesReadToLastEntry()`, finalizes telemetry via `service.finalize()`. `src/orchestration/trace.ts` provides `ITraceWriter` injected via `service.setTracer()`. CLI commands (`src/cli/generate.ts`, `src/cli/update.ts`) instantiate orchestrator with `config.ai.backend` and `config.ai.concurrency` settings.