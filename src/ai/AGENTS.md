<!-- Generated by agents-reverse-engineer -->

# src/ai

AI service orchestration layer abstracting Claude Code, Gemini, and OpenCode CLIs through backend adapters, exponential backoff retry, subprocess resource management, telemetry logging, and timeout enforcement for concurrent file analysis pools.

## Contents

### Core Orchestration

**[service.ts](./service.ts)** — AIService class coordinating backend selection, subprocess execution via `runSubprocess()`, retry logic via `withRetry()`, telemetry accumulation via `TelemetryLogger`, trace emission via `ITraceWriter`, rate-limit detection matching stderr patterns (`'rate limit'`, `'429'`, `'too many requests'`, `'overloaded'`), optional debug logging with heap/RSS metrics via `formatBytes()`, and fire-and-forget subprocess log serialization via `enqueueSubprocessLog()` promise chain.

**[registry.ts](./registry.ts)** — BackendRegistry managing adapter map with `register()`, `get()`, `getAll()` methods. Exports `createBackendRegistry()` instantiating registry with ClaudeBackend, GeminiBackend, OpenCodeBackend in priority order. Exports `resolveBackend(registry, requested)` implementing auto-detection via `detectBackend()` iterating `backend.isAvailable()` or throwing `AIServiceError` with code `'CLI_NOT_FOUND'` and aggregated install instructions via `getInstallInstructions()`.

**[subprocess.ts](./subprocess.ts)** — `runSubprocess(command, args, options)` spawning `execFile()` child processes with stdin piping, timeout enforcement via SIGTERM at `options.timeoutMs`, SIGKILL escalation after 5s grace period, process group killing via `kill(-pid)`, active subprocess tracking in module Map enabling `getActiveSubprocessCount()` and `getActiveSubprocesses()` inspection, and `onSpawn(pid)` callback at spawn time.

**[retry.ts](./retry.ts)** — `withRetry(fn, options)` exponential backoff wrapper executing async function with delay formula `min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter` (jitter uniform random 0-500ms). Exports `DEFAULT_RETRY_OPTIONS` constant with `maxRetries: 3`, `baseDelayMs: 1000`, `maxDelayMs: 8000`, `multiplier: 2`. Retry flow controlled by `options.isRetryable(error)` predicate and optional `options.onRetry(attempt, error)` callback.

**[types.ts](./types.ts)** — Type definitions: `AIBackend` interface with `isAvailable()`, `buildArgs()`, `parseResponse()`, `getInstallInstructions()` contract. `AIResponse` normalized response shape with `text`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `exitCode`, `raw`. `AICallOptions` with `prompt`, `systemPrompt`, `model`, `timeoutMs`, `maxTurns`, `taskLabel`. `SubprocessResult` with `stdout`, `stderr`, `exitCode`, `signal`, `durationMs`, `timedOut`, `childPid`. `TelemetryEntry` per-call metadata, `RunLog` aggregated run structure, `FileRead` file metadata, `RetryOptions` retry config, `AIServiceError` typed error with `code` discriminator (`'CLI_NOT_FOUND'`, `'TIMEOUT'`, `'PARSE_ERROR'`, `'SUBPROCESS_ERROR'`, `'RATE_LIMIT'`).

**[index.ts](./index.ts)** — Barrel export aggregating public API: AIService, BackendRegistry, resolveBackend, detectBackend, createBackendRegistry, withRetry, runSubprocess, isCommandOnPath, all types from `./types.js`, AIServiceOptions from `./service.js`.

## Subdirectories

**[backends/](./backends/)** — AIBackend adapter implementations: ClaudeBackend with Zod validation via `ClaudeResponseSchema`, GeminiBackend stub throwing `SUBPROCESS_ERROR` until JSON format stabilizes, OpenCodeBackend stub throwing `SUBPROCESS_ERROR` until JSONL parsing implemented. Shared `isCommandOnPath()` utility scanning `process.env.PATH` with Windows `PATHEXT` support.

**[telemetry/](./telemetry/)** — Telemetry subsystem: TelemetryLogger accumulating TelemetryEntry instances, `writeRunLog()` persisting JSON to `.agents-reverse-engineer/logs/run-<timestamp>.json`, `cleanupOldLogs()` enforcing retention via lexicographic filename sorting.

## Architecture

### Backend Adapter Pattern

AIBackend interface decouples CLI invocation from backend-specific argument construction and JSON parsing. Registry selects backend at runtime via `config.ai.backend` field (`'claude'` | `'gemini'` | `'opencode'` | `'auto'`). Auto-detection calls `isAvailable()` on each backend in registration order (Claude → Gemini → OpenCode) until first CLI found on PATH.

### Subprocess Resource Management

Mitigates Claude CLI thread exhaustion (GitHub #5771: 200 Node.js instances):
- `NODE_OPTIONS='--max-old-space-size=512'` limits heap to 512MB per subprocess
- `UV_THREADPOOL_SIZE='4'` constrains libuv thread pool to 4 threads
- `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` prevents background task spawning
- `--disallowedTools Task` prevents subagent spawning
- Process group killing via `kill(-pid)` terminates subprocess trees
- Default concurrency 2 for WSL environments (5 elsewhere)

### Retry Strategy

`AIService.call()` wraps `runSubprocess()` in `withRetry()` configured to retry only `RATE_LIMIT` errors (timeouts excluded). Rate-limit detection via `isRateLimitStderr()` substring matching. Exponential backoff adds uniform jitter (0-500ms) preventing thundering herd when multiple workers hit rate limits simultaneously.

### Telemetry Accumulation

TelemetryLogger maintains in-memory `entries: TelemetryEntry[]` array throughout CLI run. After each `AIService.call()`, logger records timestamp, prompt, response, model, token counts (input/output/cacheRead/cacheCreation), latency, exitCode, retryCount, and filesRead metadata. On run completion, `logger.toRunLog()` serializes entries plus computed summary (totalCalls, totalInputTokens, totalOutputTokens, totalCacheReadTokens, totalCacheCreationTokens, totalDurationMs, errorCount, uniqueFilesRead) to `RunLog` JSON structure. `writeRunLog()` persists with ISO-8601-derived filename, `cleanupOldLogs()` enforces retention by deleting oldest logs exceeding `config.ai.telemetry.keepRuns` threshold.

### Timeout Enforcement

`runSubprocess()` sends SIGTERM at `timeoutMs`, schedules unref'd SIGKILL timer at `timeoutMs + 5000ms` for hung processes ignoring SIGTERM. Sets `SubprocessResult.timedOut = true` when `execFile` error has `killed: true` property. AIService throws `AIServiceError('TIMEOUT')` on timeout detection (non-retryable per resource constraint mitigation).

### Trace Emission

AIService invokes `tracer.emit()` for `subprocess:spawn` at `onSpawn` callback time (includes `childPid`, `taskLabel`, `command`, `args`), `subprocess:exit` after completion (includes `exitCode`, `signal`, `durationMs`, `timedOut`), and `retry` events before delay (includes `attempt`, `taskLabel`, `errorCode`). ITraceWriter from `src/orchestration/trace.ts` provides promise-chain serialization ensuring NDJSON line order matches emission order despite concurrent workers.

## Behavioral Contracts

### Rate Limit Patterns

```typescript
const RATE_LIMIT_PATTERNS = ['rate limit', '429', 'too many requests', 'overloaded'];
```

### Default Retry Configuration

```typescript
DEFAULT_RETRY_OPTIONS = {
  maxRetries: 3,
  baseDelayMs: 1_000,
  maxDelayMs: 8_000,
  multiplier: 2
}
```

### SIGKILL Grace Period

```typescript
const SIGKILL_GRACE_MS = 5_000;
```

### Subprocess maxBuffer

```typescript
maxBuffer: 10 * 1024 * 1024  // 10MB stdout/stderr capture limit
```

## Integration Points

**Consumed by:**
- `src/orchestration/runner.ts` — Creates AIService instance, calls `setTracer()` and `setDebug()` based on CLI flags, invokes `call()` for each task, calls `finalize()` at run end
- `src/generation/executor.ts` — Handles AIServiceError codes for failure modes, extracts error messages for progress reporting

**Imports from:**
- `src/orchestration/trace.ts` — ITraceWriter interface for trace event emission
- `src/config/schema.ts` — AIServiceOptions validation schema

**Exports to:**
- `src/cli/*.ts` — All CLI commands import AIService, createBackendRegistry, resolveBackend from `./ai/index.js`