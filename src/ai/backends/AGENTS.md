<!-- Generated by agents-reverse-engineer v0.8.11 -->

# src/ai/backends

CLI adapter layer implementing AIBackend interface for three runtime targets: Claude Code (production), Gemini CLI (stub), OpenCode (production). Each backend translates AICallOptions into CLI args, validates availability via PATH lookup, parses CLI output into normalized AIResponse, and provides installation instructions.

## Contents

**[claude.ts](./claude.ts)** — ClaudeBackend constructs args `['-p', '--output-format', 'json', '--no-session-persistence', '--allowedTools', 'Read', 'Write', '--model', '--system-prompt', '--max-turns']`, implements tri-format parser via `extractResultJson()` (JSON array for CLI ≥2.1.38, NDJSON, legacy single-object), validates `ClaudeResponseSchema` (Zod) extracting `modelUsage`/`usage`/`total_cost_usd`/`duration_ms`, exports `isCommandOnPath()` utility scanning `process.env.PATH` + Windows `PATHEXT` via `fs.stat()`.

**[gemini.ts](./gemini.ts)** — GeminiBackend stub returning `['-p', '--output-format', 'json']` from `buildArgs()`, throwing `AIServiceError('SUBPROCESS_ERROR', 'Gemini backend is not yet implemented. Use Claude backend.')` from `parseResponse()`. Delegates `isAvailable()` to `claude.ts` `isCommandOnPath()`. Install instructions: `npm install -g @anthropic-ai/gemini-cli`.

**[opencode.ts](./opencode.ts)** — OpenCodeBackend production adapter constructs args `['run', '--format', 'json', '--agent', 'are-summarizer', '--model']` via `buildArgs()`, injects agent config `.opencode/agents/are-summarizer.md` (YAML frontmatter `steps: 5`, `tools: {"*": false}`) through `ensureProjectConfig()`, wraps system prompt in `<system-instructions>` tags via `composeStdinInput()` (no native `--system-prompt` flag), parses NDJSON events via `parseNdjson()` (concatenates `text` events from `OpenCodeTextSchema`, aggregates `step_finish` token metrics from `OpenCodeStepFinishSchema`), calculates cost via `calculateCostFromTokens()` (INPUT_COST_PER_MTOK=15, OUTPUT_COST_PER_MTOK=75, CACHE_WRITE_COST_PER_MTOK=18.75, CACHE_READ_COST_PER_MTOK=1.50) when `totalCost === 0`, resolves model aliases through `resolveModelForOpenCode()` (`'sonnet'` → `'anthropic/claude-sonnet-4-5'`), strips `''` marker (throws `AIServiceError` code `PARSE_ERROR` if cleaned length < 100), returns `AIResponse` with `model: 'unknown'` and `raw: {events, numTurns, reasoningTokens, calculatedCost}`.

## Architecture

### Backend Selection
Consumed by `src/ai/registry.ts` `getBackend(backendName: string): AIBackend` which instantiates backend classes. `src/ai/subprocess.ts` `runSubprocess()` invokes `backend.buildArgs(options)`, spawns `backend.cliCommand` via `execFile()`, pipes prompt to stdin, calls `backend.parseResponse(stdout, durationMs, exitCode)`.

### AIBackend Contract
Each backend implements four methods:
- `isAvailable(): Promise<boolean>` — PATH lookup via `isCommandOnPath()` (Windows PATHEXT-aware)
- `buildArgs(options: AICallOptions): string[]` — constructs CLI args array (prompt excluded per contract, sent via stdin)
- `parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse` — parses CLI output, normalizes tokens/cost/model/duration
- `getInstallInstructions(): string` — returns installation command for missing CLI

### Prompt Separation
Per AIBackend contract, prompts sent via stdin not CLI args. Prevents shell escaping issues, supports unbounded prompt lengths. `buildArgs()` constructs flags/options only; `runSubprocess()` pipes `options.prompt` to child process stdin separately.

### OpenCode System Prompt Handling
OpenCode lacks native `--system-prompt` flag. `composeStdinInput()` wraps `systemPrompt` in `<system-instructions>` XML tags, appends user `prompt`. Agent config `OPENCODE_AGENT_CONTENT` instructs: "follow `<system-instructions>` tags exactly", "user prompt after `</system-instructions>`". `ensureProjectConfig()` writes `.opencode/agents/are-summarizer.md` with `tools: {"*": false}` (disables all tools).

## Behavioral Contracts

### PATH Lookup
`isCommandOnPath()` scans `process.env.PATH.split(path.delimiter)` directories, checks `process.env.PATHEXT` on Windows (`.exe;.cmd;.bat`), uses `fs.stat()` for existence (not Unix execute bit). Returns `Promise<boolean>`.

### Claude Output Formats
`extractResultJson()` handles three CLI versions:
1. **JSON array** (CLI ≥2.1.38): `[{system}, {assistant}, {result}]` — finds `type:"result"` element
2. **NDJSON**: line-delimited `{...}\n{...}\n{"type":"result",...}` — splits by `\n`, finds result line
3. **Legacy** (CLI ≤2.1.31): `Non-JSON text{"type":"result",...}` — slices from first `{`

Throws `AIServiceError('PARSE_ERROR', ...)` if no result object found.

### OpenCode NDJSON Parsing
`parseNdjson()` splits stdout by `\n`, filters lines starting with `{`, parses JSON (skips malformed gracefully via `try-catch`), aggregates:
- `text` events: `OpenCodeTextSchema` → `textParts.push(parsed.data.part.text)` → `text = textParts.join('')`
- `step_finish` tokens: `OpenCodeStepFinishSchema` → accumulates `inputTokens`, `outputTokens`, `reasoningTokens`, `cacheReadTokens`, `cacheWriteTokens`, `totalCost` from `parsed.data.part.tokens`/`parsed.data.part.cost`

Throws `AIServiceError('PARSE_ERROR', ...)` if `!parsed.text`.

### OpenCode Cost Calculation
`calculateCostFromTokens(inputTokens, outputTokens, cacheReadTokens, cacheWriteTokens)` uses Anthropic Claude Sonnet pricing constants:
```
INPUT_COST_PER_MTOK = 15
OUTPUT_COST_PER_MTOK = 75
CACHE_WRITE_COST_PER_MTOK = 18.75
CACHE_READ_COST_PER_MTOK = 1.50
```
Formula: `(inputTokens/1e6)*15 + (outputTokens/1e6)*75 + (cacheWriteTokens/1e6)*18.75 + (cacheReadTokens/1e6)*1.50`. Applied when `totalCost === 0 && (inputTokens > 0 || outputTokens > 0)`.

### OpenCode Model Alias Resolution
`resolveModelForOpenCode(model: string): string` returns input if contains `/`, else looks up `MODEL_ALIASES[model]`:
- `'sonnet'` → `'anthropic/claude-sonnet-4-5'`
- `'opus'` → `'anthropic/claude-opus-4-6'`
- `'haiku'` → `'anthropic/claude-haiku-4-5'`

Fallback to input if no alias match.

### Claude Schema Validation
`ClaudeResponseSchema` (Zod) validates:
```typescript
{
  type: 'result',
  subtype: 'success' | 'error',
  is_error: boolean,
  duration_ms: number,
  duration_api_ms: number,
  num_turns: number,
  result: string,
  session_id: string,
  total_cost_usd: number,
  usage: {
    input_tokens: number,
    cache_creation_input_tokens: number,
    cache_read_input_tokens: number,
    output_tokens: number
  },
  modelUsage: {
    [model: string]: {
      inputTokens: number,
      outputTokens: number,
      cacheReadInputTokens: number,
      cacheCreationInputTokens: number,
      costUSD: number
    }
  }
}
```
Uses `.passthrough()` on nested objects for forward compatibility with new fields.

### OpenCode Schemas
- `OpenCodeTokensSchema`: `{total?, input?, output?, reasoning?, cache: {read?, write?}}` with `.optional().default(0)` on numeric fields
- `OpenCodeStepFinishPartSchema`: `{type: 'step-finish', cost?, tokens?: OpenCodeTokensSchema}`
- `OpenCodeStepFinishSchema`: `{type: 'step_finish', part: OpenCodeStepFinishPartSchema}`
- `OpenCodeTextPartSchema`: `{type: 'text', text: string}`
- `OpenCodeTextSchema`: `{type: 'text', part: OpenCodeTextPartSchema}`

### OpenCode Agent Config
`OPENCODE_AGENT_CONTENT` defines agent behavior:
```yaml
---
steps: 5
tools:
  "*": false
---
```
System prompt: "Output ONLY raw content — your entire response IS the document", "Do NOT include preamble, thinking, planning", "When `<system-instructions>` tags present, follow exactly", "Content after `</system-instructions>` is user prompt". Always overwrites `.opencode/agents/are-summarizer.md` via `ensureProjectConfig()`.

### Tool Pre-approval
`ClaudeBackend.buildArgs()` includes `--allowedTools Read Write` to prevent permission prompts when running as root. Bypasses need for `--bypassPermissions` which is blocked in privileged contexts.

### Model Name Extraction
Claude: `parseResponse()` extracts model name from first key in `modelUsage` object (`Object.keys(validated.modelUsage)[0] ?? 'unknown'`). OpenCode: always returns `model: 'unknown'` (CLI provides no model metadata).

## Integration

### Registry Lookup
`src/ai/registry.ts` maps backend names to classes:
```typescript
backends.set('claude', new ClaudeBackend())
backends.set('gemini', new GeminiBackend())
backends.set('opencode', new OpenCodeBackend())
```

### Subprocess Invocation
`src/ai/subprocess.ts` `runSubprocess()` flow:
1. `backend.buildArgs(options)` → `string[]`
2. `execFile(backend.cliCommand, args, {timeout})` → child process
3. `child.stdin.write(options.prompt)` → pipe prompt
4. Wait for stdout/stderr/exit
5. `backend.parseResponse(stdout, durationMs, exitCode)` → `AIResponse`

### Error Propagation
Stub backends throw `AIServiceError('SUBPROCESS_ERROR', ...)` caught by `src/ai/service.ts` `AIService.call()`, logged to telemetry, surfaced to CLI via `src/output/logger.ts`.