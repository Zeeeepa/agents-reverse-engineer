<!-- Generated by agents-reverse-engineer v0.8.10 -->

# src/ai/backends

CLI adapter layer implementing AIBackend interface for three runtime targets: Claude Code (production), Gemini CLI (stub), OpenCode (production). Each backend translates AICallOptions into CLI args, validates availability via PATH lookup, parses CLI output into normalized AIResponse, and provides installation instructions.

## Contents

**[claude.ts](./claude.ts)** — ClaudeBackend constructs args `['-p', '--output-format', 'json', '--no-session-persistence', '--allowedTools', 'Read', 'Write', '--model', '--system-prompt', '--max-turns']`, implements tri-format parser via `extractResultJson()` (JSON array for CLI ≥2.1.38, NDJSON, legacy single-object), validates `ClaudeResponseSchema` (Zod) extracting `modelUsage`/`usage`/`total_cost_usd`/`duration_ms`, exports `isCommandOnPath()` utility scanning `process.env.PATH` + Windows `PATHEXT` via `fs.stat()`.

**[gemini.ts](./gemini.ts)** — GeminiBackend stub returning `['-p', '--output-format', 'json']` from `buildArgs()`, throwing `AIServiceError('SUBPROCESS_ERROR', 'Gemini backend is not yet implemented. Use Claude backend.')` from `parseResponse()`. Delegates `isAvailable()` to `claude.ts` `isCommandOnPath()`. Install instructions: `npm install -g @anthropic-ai/gemini-cli`.

**[opencode.ts](./opencode.ts)** — OpencodeBackend production adapter returning `['run', '--format', 'json', '--model']` from `buildArgs()`, parsing NDJSON events via `parseNdjson()` (aggregates `text` events, `step_finish` token metrics from `OpencodeStepFinishSchema`), calculates cost via `calculateCostFromTokens()` (INPUT_COST_PER_MTOK=15, OUTPUT_COST_PER_MTOK=75, CACHE_WRITE_COST_PER_MTOK=18.75, CACHE_READ_COST_PER_MTOK=1.50) when `totalCost === 0`, returns `AIResponse` with `model: 'unknown'` and `raw: {events, numTurns, reasoningTokens, calculatedCost}`. Reuses `isCommandOnPath()` from `claude.ts`. Install instructions: curl-based shell script. Limitations: no `--max-turns`, `--allowedTools`, `--system-prompt`, `--no-session-persistence` equivalents.

## Architecture

### Backend Selection
Consumed by `src/ai/registry.ts` `getBackend(backendName: string): AIBackend` which instantiates backend classes. `src/ai/subprocess.ts` `runSubprocess()` invokes `backend.buildArgs(options)`, spawns `backend.cliCommand` via `execFile()`, pipes prompt to stdin, calls `backend.parseResponse(stdout, durationMs, exitCode)`.

### AIBackend Contract
Each backend implements four methods:
- `isAvailable(): Promise<boolean>` — PATH lookup via `isCommandOnPath()` (Windows PATHEXT-aware)
- `buildArgs(options: AICallOptions): string[]` — constructs CLI args array (prompt excluded per contract, sent via stdin)
- `parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse` — parses CLI output, normalizes tokens/cost/model/duration
- `getInstallInstructions(): string` — returns installation command for missing CLI

### Prompt Separation
Per AIBackend contract, prompts sent via stdin not CLI args. Prevents shell escaping issues, supports unbounded prompt lengths. `buildArgs()` constructs flags/options only; `runSubprocess()` pipes `options.prompt` to child process stdin separately.

## Behavioral Contracts

### PATH Lookup
`isCommandOnPath()` scans `process.env.PATH.split(path.delimiter)` directories, checks `process.env.PATHEXT` on Windows (`.exe;.cmd;.bat`), uses `fs.stat()` for existence (not Unix execute bit). Returns `Promise<boolean>`.

### Claude Output Formats
`extractResultJson()` handles three CLI versions:
1. **JSON array** (CLI ≥2.1.38): `[{system}, {assistant}, {result}]` — finds `type:"result"` element
2. **NDJSON**: line-delimited `{...}\n{...}\n{"type":"result",...}` — splits by `\n`, finds result line
3. **Legacy** (CLI ≤2.1.31): `Non-JSON text{"type":"result",...}` — slices from first `{`

Throws `AIServiceError('PARSE_ERROR', ...)` if no result object found.

### Opencode NDJSON Parsing
`parseNdjson()` splits stdout by `\n`, filters lines starting with `{`, parses JSON (skips malformed gracefully via `try-catch`), aggregates:
- `text` events: `OpencodeTextSchema` → `textParts.push(parsed.data.part.text)` → `text = textParts.join('')`
- `step_finish` tokens: `OpencodeStepFinishSchema` → accumulates `inputTokens`, `outputTokens`, `reasoningTokens`, `cacheReadTokens`, `cacheWriteTokens`, `totalCost` from `parsed.data.part.tokens`/`parsed.data.part.cost`

Throws `AIServiceError('PARSE_ERROR', ...)` if `!parsed.text`.

### Opencode Cost Calculation
`calculateCostFromTokens(inputTokens, outputTokens, cacheReadTokens, cacheWriteTokens)` uses Anthropic Claude Sonnet pricing constants:
```
INPUT_COST_PER_MTOK = 15
OUTPUT_COST_PER_MTOK = 75
CACHE_WRITE_COST_PER_MTOK = 18.75
CACHE_READ_COST_PER_MTOK = 1.50
```
Formula: `(inputTokens/1e6)*15 + (outputTokens/1e6)*75 + (cacheWriteTokens/1e6)*18.75 + (cacheReadTokens/1e6)*1.50`. Applied when `totalCost === 0 && (inputTokens > 0 || outputTokens > 0)`.

### Claude Schema Validation
`ClaudeResponseSchema` (Zod) validates:
```typescript
{
  type: 'result',
  subtype: 'success' | 'error',
  is_error: boolean,
  duration_ms: number,
  duration_api_ms: number,
  num_turns: number,
  result: string,
  session_id: string,
  total_cost_usd: number,
  usage: {
    input_tokens: number,
    cache_creation_input_tokens: number,
    cache_read_input_tokens: number,
    output_tokens: number
  },
  modelUsage: {
    [model: string]: {
      inputTokens: number,
      outputTokens: number,
      cacheReadInputTokens: number,
      cacheCreationInputTokens: number,
      costUSD: number
    }
  }
}
```
Uses `.passthrough()` on nested objects for forward compatibility with new fields.

### Opencode Schemas
- `OpencodeTokensSchema`: `{total?, input?, output?, reasoning?, cache: {read?, write?}}` with `.optional().default(0)` on numeric fields
- `OpencodeStepFinishPartSchema`: `{type: 'step-finish', cost?, tokens?: OpencodeTokensSchema}`
- `OpencodeStepFinishSchema`: `{type: 'step_finish', part: OpencodeStepFinishPartSchema}`
- `OpencodeTextPartSchema`: `{type: 'text', text: string}`
- `OpencodeTextSchema`: `{type: 'text', part: OpencodeTextPartSchema}`

### Tool Pre-approval
`ClaudeBackend.buildArgs()` includes `--allowedTools Read Write` to prevent permission prompts when running as root. Bypasses need for `--bypassPermissions` which is blocked in privileged contexts.

### Model Name Extraction
Claude: `parseResponse()` extracts model name from first key in `modelUsage` object (`Object.keys(validated.modelUsage)[0] ?? 'unknown'`). Opencode: always returns `model: 'unknown'` (CLI provides no model metadata).

## Integration

### Registry Lookup
`src/ai/registry.ts` maps backend names to classes:
```typescript
backends.set('claude', new ClaudeBackend())
backends.set('gemini', new GeminiBackend())
backends.set('opencode', new OpencodeBackend())
```

### Subprocess Invocation
`src/ai/subprocess.ts` `runSubprocess()` flow:
1. `backend.buildArgs(options)` → `string[]`
2. `execFile(backend.cliCommand, args, {timeout})` → child process
3. `child.stdin.write(options.prompt)` → pipe prompt
4. Wait for stdout/stderr/exit
5. `backend.parseResponse(stdout, durationMs, exitCode)` → `AIResponse`

### Error Propagation
Stub backends throw `AIServiceError('SUBPROCESS_ERROR', ...)` caught by `src/ai/service.ts` `AIService.call()`, logged to telemetry, surfaced to CLI via `src/output/logger.ts`.