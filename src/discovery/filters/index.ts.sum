---
generated_at: 2026-02-09T15:05:58.968Z
content_hash: f3124a988e86b4fd955b0436cc2b3fc12e5bc5433442c4f37fcbc1d813dea324
purpose: Filter chain orchestrator exporting all filter creators (`createGitignoreFilter`, `createVendorFilter`, `createBinary...
---
**Filter chain orchestrator exporting all filter creators (`createGitignoreFilter`, `createVendorFilter`, `createBinaryFilter`, `createCustomFilter`) and providing `applyFilters()` function that processes file arrays through sequential filter predicates with short-circuit evaluation, bounded concurrency, and trace emission.**

## Exports

**Re-exported filter creators:**
- `createGitignoreFilter` from `./gitignore.js` — builds gitignore parser-based file exclusion predicate
- `createVendorFilter` from `./vendor.js` — creates directory name matcher against vendor list, exports `DEFAULT_VENDOR_DIRS` constant
- `createBinaryFilter` from `./binary.js` — constructs extension + content-based binary detector accepting `BinaryFilterOptions`, exports `BINARY_EXTENSIONS` constant and `BinaryFilterOptions` type
- `createCustomFilter` from `./custom.js` — generates user-defined glob pattern matcher

**Primary orchestration function:**
- `applyFilters(files: string[], filters: FileFilter[], options?: { tracer?: ITraceWriter; debug?: boolean }): Promise<FilterResult>` — executes filter chain with concurrency control, returns `FilterResult` containing `included` and `excluded` arrays

## Filter Chain Execution Pattern

`applyFilters()` processes files through filter array with short-circuit logic: each file runs through `filter.shouldExclude()` predicates in order until first rejection. Worker pool with `CONCURRENCY=30` bound prevents file descriptor exhaustion during binary content detection I/O (called by `isBinaryFile()` in binary filter). Uses iterator-based task distribution pattern matching `src/orchestration/pool.ts` architecture: single shared iterator across N concurrent workers.

## Result Construction

Returns `FilterResult` with:
- `included: string[]` — files passing all filters
- `excluded: ExcludedFile[]` — rejected files with `{ path, reason, filter }` metadata indicating which filter excluded them

Collects exclusions via worker results with `{ index, file, excluded?: ExcludedFile }` tuples, sorts by original index to preserve input order, aggregates per-filter statistics into `Map<string, { matched, rejected }>`.

## Trace Emission

Emits `filter:applied` events via `options.tracer` with `{ type, filterName, filesMatched, filesRejected }` payloads. Updates `filterStats` map during result aggregation: rejected files increment `stats.rejected`, included files increment `stats.matched` for all filters they passed. Debug mode outputs rejection counts via `console.error()` with `pc.dim()` formatting when `options.debug && stats.rejected > 0`.

## Concurrency Control

Spawns `Math.min(CONCURRENCY, files.length)` workers sharing single `files.entries()` iterator. Each worker pulls `[index, file]` entries synchronously from shared iterator, executes filter chain sequentially per file, accumulates local results array, returns after iterator exhaustion. Pattern prevents over-allocation of file handles during binary detection phase.