<!-- Generated by agents-reverse-engineer -->

# src/orchestration

**Worker-pool concurrency control with iterator-based task distribution, progress telemetry via ETA calculation, serialized plan/log/trace writers for concurrent-safe output, and high-level command workflows integrating three-phase AI-driven documentation pipelines.**

## Contents

### Core Modules

**[index.ts](./index.ts)** — Barrel export aggregating `runPool`, `createTraceWriter`, `cleanupOldTraces`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `CommandRunner`, plus types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`)

**[pool.ts](./pool.ts)** — `runPool<T>(tasks, options, onComplete?)` iterator-based worker pool sharing single `tasks.entries()` iterator across N workers, returns `Promise<TaskResult<T>[]>` preserving task index, enforces `options.concurrency` cap via `Math.min(options.concurrency, tasks.length)`, supports fail-fast abort via shared `aborted` flag, emits trace events (`worker:start/end`, `task:pickup/done`) with `activeTasks` counter

**[runner.ts](./runner.ts)** — `CommandRunner` orchestrates `executeGenerate(plan)` via three-phase pipeline (concurrent file analysis → post-order directory aggregation → sequential root synthesis) with pre/post validation phases (pre-phase-1 cache for stale-doc detection, post-phase-1 code-vs-doc/code-vs-code checks, post-phase-2 phantom path resolution), `executeUpdate(filesToAnalyze)` runs Phase 1 only for incremental workflows, helpers `stripPreamble()` remove LLM conversational prefix via `\n---\n` or bold purpose detection, `extractPurpose()` scans lines skipping `PREAMBLE_PREFIXES` (`['now i', 'perfect', 'based on', ...]`)

**[progress.ts](./progress.ts)** — `ProgressReporter` streams build-log output with format `[X/Y] ANALYZING/DONE/FAIL path` for files, `[dir X/Y] ANALYZING/DONE dirPath/AGENTS.md` for directories, `[root] DONE docPath` for roots, calculates ETA via moving average of last 10 completion times in `completionTimes[]`/`dirCompletionTimes[]` arrays, `printSummary(summary)` outputs end-of-run aggregates; `ProgressLog` mirrors console output to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes with lazy file handle creation, `stripAnsi(str)` removes color codes via regex `/\x1b\[[0-9;]*m/g`

**[trace.ts](./trace.ts)** — `ITraceWriter` interface with `emit(event)`, `finalize()`, `filePath`, `createTraceWriter(projectRoot, enabled)` factory returns `TraceWriter` writing NDJSON to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson` or `NullTraceWriter` no-op stub, `TraceWriter` auto-populates `TraceEventBase` fields (`seq`, `ts`, `pid`, `elapsedMs` via `process.hrtime.bigint()`), serializes via promise-chain pattern, `cleanupOldTraces(projectRoot, keepCount=500)` removes old traces keeping most recent, event types: `phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`, `discovery:start/end`, `filter:applied`, `plan:created`, `config:loaded`

**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` updates `GENERATION-PLAN.md` checkboxes via `markDone(itemPath)` replacing `- [ ] \`${itemPath}\`` with `- [x] \`${itemPath}\``, maintains `content: string` in-memory, serializes writes via `writeQueue: Promise<void>` chain pattern, `initialize()` creates parent directory and writes initial markdown, `flush()` drains pending writes before command completion

**[types.ts](./types.ts)** — `FileTaskResult` (path, success, tokensIn/Out, cacheReadTokens, cacheCreationTokens, durationMs, model, error?), `RunSummary` (version, filesProcessed/Failed/Skipped, totalCalls, token totals, totalDurationMs, errorCount, retryCount, totalFilesRead, uniqueFilesRead, inconsistenciesCodeVsDoc/CodeVsCode, phantomPaths?, inconsistencyReport?), `ProgressEvent` discriminated by type (`start|done|error|dir-done|root-done`), `CommandRunOptions` (concurrency, failFast?, debug?, dryRun?, tracer?, progressLog?)

## Architecture Patterns

### Iterator-Based Worker Pool

`pool.ts` shares single `tasks.entries()` iterator across N workers via JavaScript iterator protocol guaranteeing atomic `.next()` calls. Workers consume `[index, task]` pairs in `for...of` loop, execute task factory, immediately pull next without batch idle periods. Effective concurrency capped via `Math.min(options.concurrency, tasks.length)`. Fail-fast mode sets shared `aborted` flag on error, workers check via `if (aborted) break` before pulling next. Results array sparse-populated via `results[index] = result` to preserve task position.

### Promise-Chain Serialization

`PlanTracker.writeQueue`, `ProgressLog.writeQueue`, `TraceWriter.writeQueue` chain writes via `this.writeQueue = this.writeQueue.then(async () => {...}).catch(() => {})` pattern. Prevents NDJSON corruption and markdown TOCTOU errors from concurrent pool workers. Lazy file handle creation (first write opens file, subsequent writes reuse handle). Write errors silently swallowed (non-critical telemetry loss acceptable).

### Three-Phase Execution Pipeline

`runner.ts` executes:
1. **Pre-Phase-1**: Throttled read (concurrency=20) of existing `.sum` files into `oldSumCache` for stale-doc detection
2. **Phase 1**: Concurrent file analysis via `runPool()` calling `aiService.call()` with `buildFilePrompt()`, writes `.sum` with YAML frontmatter (generatedAt, contentHash, purpose), caches source in `sourceContentCache`
3. **Post-Phase-1**: Quality validation via `checkCodeVsDoc()` twice (against `oldSumCache` for stale, against fresh `.sum` for omissions), `checkCodeVsCode()` for duplicate exports
4. **Phase 2**: Post-order directory aggregation sorted by depth descending via `sort((a,b) => b-a)`, waits for all child `.sum` files via implicit dependency, calls `aiService.call()` with `buildDirectoryPrompt()`, writes `AGENTS.md` via `writeAgentsMd()` merging `AGENTS.local.md`
5. **Post-Phase-2**: Phantom path validation via `checkPhantomPaths()` extracting path-like strings with three regex patterns (markdown links, backtick paths, prose-embedded), resolves via `existsSync()` with `.ts`/`.js` fallback
6. **Phase 3**: Sequential root synthesis (concurrency=1) via `runPool()` calling `aiService.call()` with `buildRootPrompt()` injecting all `AGENTS.md` via `collectAgentsDocs()`, strips conversational preamble via markdown start detection (`indexOf('# ')`), writes to `rootTask.outputPath`

### ETA Calculation

`ProgressReporter` maintains sliding windows `completionTimes[]` and `dirCompletionTimes[]` with max size `windowSize=10`. Records task duration on completion, computes moving average via `reduce((a,b)=>a+b, 0)/length`, multiplies by remaining tasks. Formats via `formatETA()` as `~12s remaining` or `~2m 30s remaining`. Returns empty string if fewer than 2 completions (insufficient sample).

### Trace Event Emission

Tracer threaded via `CommandRunOptions.tracer` → pool options → AIService. `TraceWriter` auto-populates base fields: `seq` (monotonic counter), `ts` (ISO 8601), `pid` (process.pid), `elapsedMs` (high-resolution fractional via `process.hrtime.bigint()` delta). Events: `phase:start` (taskCount, concurrency, phase), `phase:end` (durationMs, tasksCompleted, tasksFailed, phase), `worker:start` (workerId, phase), `worker:end` (workerId, phase, tasksExecuted), `task:pickup` (workerId, taskIndex, taskLabel, activeTasks), `task:done` (workerId, taskIndex, taskLabel, durationMs, success, error?, activeTasks), `subprocess:spawn` (childPid, command, taskLabel), `subprocess:exit` (childPid, command, taskLabel, exitCode, signal, durationMs, timedOut), `retry` (attempt, taskLabel, errorCode).

## Incremental Update Strategy

`runner.executeUpdate()` runs Phase 1 only for `filesToAnalyze: FileChange[]`. Passes `existingSum: existingSumContent?.summary` to `buildFilePrompt()` for incremental mode. Caches source in `updateSourceCache`, runs quality validation (code-vs-doc new-doc check, code-vs-code duplicate detection). Returns `RunSummary` with `filesSkipped: 0`. Caller (`src/update/orchestrator.ts`) handles Phase 2 `AGENTS.md` regeneration for `affectedDirs`.

## Quality Validation Phases

**Pre-Phase-1 Cache**: Reads existing `.sum` files into `oldSumCache: Map<string, SumFileContent>` for stale documentation detection in post-phase-1 code-vs-doc checks.

**Post-Phase-1 Code-vs-Doc**: Calls `checkCodeVsDoc()` twice per file — once against `oldSumCache` (detect stale exports), once against freshly written `.sum` (detect omissions). Extracts exports via `/^[ \t]*export\s+(?:default\s+)?(?:function|class|const|let|var|type|interface|enum)\s+(\w+)/gm`, verifies substring presence in summary.

**Post-Phase-1 Code-vs-Code**: Groups files by directory via `path.dirname()`, calls `checkCodeVsCode()` aggregating exports per directory into `Map<symbol, string[]>`, detects duplicates.

**Post-Phase-2 Phantom Paths**: Reads each `AGENTS.md`, calls `checkPhantomPaths()` extracting path-like strings via three regex patterns (markdown links: `/\[(?:[^\]]*)\]\((\.[^)]+)\)/g`, backtick paths: `` /`((?:src\/|\.\.?\/)[^`]+\.[a-z]{1,4})`/g ``, prose-embedded: `/(?:from|in|by|via|see)\s+`?(src\/[\w\-./]+)`?/gi`), resolves against `AGENTS.md` directory and project root with `.ts`/`.js` fallback via `existsSync()`.

## Behavioral Contracts

### PlanTracker Checkbox Update Pattern
```typescript
markDone(itemPath: string) {
  // Replaces:  - [ ] `${itemPath}`
  // With:      - [x] `${itemPath}`
}
```

### ProgressReporter Output Formats
```
File progress:
  [X/Y] ANALYZING path
  [X/Y] DONE path Xs in/out tok model ~Ns remaining
  [X/Y] FAIL path error

Directory progress:
  [dir X/Y] ANALYZING dirPath/AGENTS.md
  [dir X/Y] DONE dirPath/AGENTS.md Xs in/out tok model ~ETA

Root progress:
  [root] DONE docPath

Summary format:
  === Run Summary ===
    ARE version:     <version>
    Files processed: <count>
    Files failed:    <count>
    Files skipped:   <count>
    Total calls:     <count>
    Tokens:          <totalIn> in / <totalOut> out
    Cache:           <cacheRead> read / <cacheCreated> created
    Files read:      <total> (<unique> unique)
    Total time:      <elapsed>s
    Errors:          <count>
    Retries:         <count>
```

### Preamble Stripping Patterns
```typescript
stripPreamble(responseText: string): string {
  // Pattern 1: Content after \n---\n separator within first 500 chars
  // Pattern 2: Content starting with bold purpose **[A-Z] if preceding text <300 chars and lacks ##
}

extractPurpose(responseText: string): string {
  // Skip lines: empty, #headers, ---separators
  // Skip prefixes (case-insensitive): 'now i', 'perfect', 'based on', 'let me', 
  //   'here is', 'i\'ll', 'i will', 'great', 'okay', 'sure', 'certainly', 'alright'
  // Strip bold wrapper **, truncate to 120 chars with ... suffix
}
```

### TraceEvent Base Field Population
```typescript
emit(event: TraceEventPayload): void {
  // Auto-populate:
  //   seq: monotonic counter
  //   ts: new Date().toISOString()
  //   pid: process.pid
  //   elapsedMs: Number(process.hrtime.bigint() - startHr) / 1e6
}
```

### Pool Worker Task Distribution
```typescript
runPool<T>(tasks, options, onComplete?) {
  const iterator = tasks.entries(); // Shared across workers
  const workers = Array.from({ length: effectiveConcurrency }, (_, workerId) => 
    worker(iterator, workerId)
  );
  // Each worker pulls [index, task] via for...of over shared iterator
  // Iterator protocol guarantees atomic .next() calls → no duplicate pickups
}
```

## Reproduction-Critical Constants

Full prompt template texts referenced in `runner.ts`:
- [runner.ts.annex.md](./runner.ts.annex.md)