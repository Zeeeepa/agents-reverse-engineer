<!-- Generated by agents-reverse-engineer v0.8.4 -->

# src/orchestration

Concurrency control and pipeline orchestration: iterator-based worker pool (`runPool()` shared-iterator pattern), five-phase command runner (pre-phase-1-cache → phase-1-files → post-phase-1-quality → phase-2-dirs → post-phase-2), frontmatter-based update orchestration, serialized progress logging via promise-chain `PlanTracker`/`ProgressReporter`, NDJSON trace emission for subprocess/task lifecycle debugging.

## Contents

### Core Orchestration

**[orchestrator.ts](./orchestrator.ts)** — `DocumentationOrchestrator` coordinates generate (full-project) and update (incremental) workflows via unified task building: `createPlan()` executes `prepareFiles()` → `filterExistingFiles()` (unless `force: true`) → `createFileTasks()` → `filterExistingDirectories()` (dirty propagation via `markDirtyWithAncestors()`) → `createDirectoryTasks()`, nullifies `PreparedFile.content` after prompt building to free memory; `preparePlan()` performs frontmatter-based change detection (reads existing `.sum`, compares `contentHash` against `computeContentHash()`, populates `filesToAnalyze`/`filesToSkip`), calls `cleanupOrphans()` for deleted files, `getAffectedDirectories()` sorted by depth descending. Exports factory `createOrchestrator(config, projectRoot, options?)`, `createUpdateOrchestrator()` (backward-compatibility alias), types `GenerationPlan`, `UpdatePlan`, `AnalysisTask` (union: file-type with prompts or directory-type with `sumFiles`/`fileCount`), `PreparedFile`.

**[runner.ts](./runner.ts)** — `CommandRunner` executes five-phase pipeline: **pre-phase-1-cache** (reads existing `.sum` into `oldSumCache` via `runPool()` concurrency 20), **phase-1-files** (parallel AI calls via `aiService.call()`, writes `.sum`/`.annex.sum`, caches source in `sourceContentCache`), **post-phase-1-quality** (throttled `checkCodeVsDoc()` against old/new `.sum` + `checkCodeVsCode()` per directory group, concurrency 10), **phase-2-dirs** (depth-grouped post-order aggregation via `buildDirectoryPrompt()` + `writeAgentsMd()`, sequentially by depth, concurrently within depth), **post-phase-2** (`checkPhantomPaths()` markdown link validation). Separate `executeUpdate()` method runs phase-1 only for changed files, caller handles AGENTS.md regeneration. Response processing: `stripPreamble()` detects `\n---\n` separator or bold preamble line, `extractPurpose()` extracts first non-header line skipping preamble prefixes. Exports `CommandRunner`, `RunSummary` schema.

### Worker Pool

**[pool.ts](./pool.ts)** — `runPool<T>(tasks, options, onComplete?)` spawns `Math.min(options.concurrency, tasks.length)` workers sharing single `tasks.entries()` iterator, each worker loops `for (const [index, task] of iterator)` pulling next task when previous completes, returns sparse `TaskResult<T>[]` indexed by original position with `{ index, success, value?, error? }`, invokes optional `onComplete(result)` callback after each task settles, supports `options.failFast` (sets shared `aborted` flag on first error), emits tracer events `worker:start`, `task:pickup`, `task:done`, `worker:end` when `options.tracer` present. Exports `PoolOptions`, `TaskResult<T>`, `runPool()`.

### Progress Tracking

**[progress.ts](./progress.ts)** — `ProgressLog` mirrors console output to `.agents-reverse-engineer/progress.log` via promise-chain serialization, strips ANSI via `/\x1b\[[0-9;]*m/g`. `ProgressReporter` maintains sliding windows `completionTimes`/`dirCompletionTimes` (max `windowSize = 10`) for moving-average ETA calculation, methods `onFileStart()`/`onFileDone(durationMs, tokensIn, tokensOut, model, cacheReadTokens, cacheCreationTokens)`/`onFileError()`, `onDirectoryStart()`/`onDirectoryDone()`, `printSummary(summary: RunSummary)` formats run statistics with cache read/creation tokens, files read counts, elapsed time. Exports `stripAnsi()` utility, `PROGRESS_LOG_FILENAME` constant, `ProgressLog`/`ProgressReporter` classes.

**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` maintains in-memory `GENERATION-PLAN.md` content, serializes writes via `this.writeQueue = this.writeQueue.then(() => writeFile(...))` promise chain to handle concurrent phase-1 task completions. Methods: `initialize()` writes initial markdown with recursive directory creation, `markDone(itemPath)` replaces `- [ ] \`${itemPath}\`` with `- [x] \`${itemPath}\`` in memory and queues write (skips if no regex match), `flush()` awaits all queued writes. Integrates with `runPool()` `onComplete` callback for serialized progress logging. Both `initialize()` and `markDone()` catch-ignore exceptions (non-critical tracking failures).

### Telemetry

**[trace.ts](./trace.ts)** — `ITraceWriter` interface with `emit(event: TraceEventPayload)`, `finalize()`, `filePath` property. `createTraceWriter(projectRoot, enabled)` returns `NullTraceWriter` (zero overhead no-op) when disabled, else `TraceWriter` appending to `.agents-reverse-engineer/traces/trace-{ISO8601}.ndjson` (colons/periods → hyphens) via promise-chain serialization, lazy file handle opening on first write. 14 event types: `PhaseStartEvent`/`PhaseEndEvent`, `WorkerStartEvent`/`WorkerEndEvent`, `TaskPickupEvent`/`TaskDoneEvent`, `TaskStartEvent`, `SubprocessSpawnEvent`/`SubprocessExitEvent`, `RetryEvent`, `DiscoveryStartEvent`/`DiscoveryEndEvent`, `FilterAppliedEvent`, `PlanCreatedEvent`, `ConfigLoadedEvent`, each with injected base fields `seq` (monotonic counter), `ts` (ISO 8601), `pid`, `elapsedMs` (high-res ms since run start via `Number(hrtime.bigint() - startHr) / 1_000_000`). `cleanupOldTraces(projectRoot, keepCount = 500)` deletes oldest traces exceeding retention limit. Exports `ITraceWriter`, `TraceEvent` discriminated union, `TraceEventPayload` type (`DistributiveOmit<TraceEvent, 'seq' | 'ts' | 'pid' | 'elapsedMs'>`), `createTraceWriter()`, `cleanupOldTraces()`.

### Types

**[types.ts](./types.ts)** — `FileTaskResult` (single file outcome: path, success, tokens, duration, model, error), `RunSummary` (aggregated metrics: version, files processed/failed/skipped, total calls/tokens/cache tokens, duration, errors, retries, files read, quality metrics `inconsistenciesCodeVsDoc`/`inconsistenciesCodeVsCode`/`phantomPaths`, optional `inconsistencyReport`), `ProgressEvent` (event envelope: type, filePath, index, total, optional duration/tokens/model/error), `CommandRunOptions` (concurrency, failFast, debug, dryRun, tracer, progressLog).

**[index.ts](./index.ts)** — Barrel export re-exporting `CommandRunner`, `ProgressReporter`, `PlanTracker`, `runPool()`, `createTraceWriter()`, `cleanupOldTraces()`, nine types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`).

## Architecture

### Iterator-Based Concurrency

`runPool()` in `pool.ts` spawns `effectiveConcurrency` workers sharing single `tasks.entries()` iterator, each worker loops `for (const [index, task] of iterator)` pulling next `[index, task]` pair when previous completes. Avoids batch-processing idle time where `Promise.all` chunks wait for slowest task per batch. Tracks `activeTasks` counter incremented at pickup, decremented at completion for trace snapshots. `aborted` flag checked before each `iterator` pull to halt on `failFast` errors. Workers use `Promise.allSettled` so individual worker failures don't prevent result collection.

### Five-Phase Pipeline (Generate)

**Pre-Phase-1 (Cache Build)**: `runner.ts` reads existing `.sum` files into `oldSumCache: Map<string, SumFileContent>` via `runPool()` concurrency 20, enables stale documentation detection in post-phase-1 quality checks.

**Phase-1 (File Analysis)**: Executes `plan.fileTasks` through `runPool()` with user-configured concurrency, reads source via `readFile()`, caches in `sourceContentCache`, calls `aiService.call()`, computes `contentHash` via `computeContentHashFromString()`, strips preamble via `stripPreamble()`, extracts purpose via `extractPurpose()`, writes `.sum` via `writeSumFile()`, writes `.annex.sum` via `writeAnnexFile()` if response contains `## Annex References`, updates `ProgressReporter` and `PlanTracker` via `onComplete` callback.

**Post-Phase-1 (Inconsistency Detection)**: Groups processed files by directory (`Map<string, string[]>`), runs throttled quality checks (concurrency 10) per directory group via `runPool()`. For each file: runs `checkCodeVsDoc()` against `oldSumCache` entry (if exists) with " (stale documentation)" suffix, runs `checkCodeVsDoc()` against freshly written `.sum`, accumulates issues. After all files in group: runs `checkCodeVsCode()` on group's `filesForCodeVsCode: Array<{path, content}>`. Aggregates issues via `buildInconsistencyReport()`, prints via `formatReportForCli()`, populates `summary.inconsistenciesCodeVsDoc` and `summary.inconsistenciesCodeVsCode`. Clears `sourceContentCache` after checks complete. Non-throwing: errors logged but do not abort pipeline.

**Phase-2 (Directory Aggregation)**: Groups `plan.directoryTasks` by `metadata.depth`, sorts depth levels descending (deepest first = post-order). For each depth level sequentially: executes tasks in parallel with concurrency `Math.min(options.concurrency, dirsAtDepth.length)`, phase label `phase-2-dirs-depth-{depth}`. Each task calls `buildDirectoryPrompt()` with `knownDirs: Set<string>` (directories in plan) and `projectStructure`, invokes `aiService.call()`, writes `AGENTS.md` via `writeAgentsMd()`, writes companion `CLAUDE.md` via `writeClaudeMdPointer()`, updates reporters. Maintains post-order guarantee: children processed before parents.

**Post-Phase-2 (Phantom Path Validation)**: Iterates `plan.directoryTasks`, reads generated `AGENTS.md` files, runs `checkPhantomPaths()` to detect broken relative paths in markdown links/backticks/prose. Aggregates issues via `buildInconsistencyReport()`, prints via `formatReportForCli()`, populates `summary.phantomPaths`. Non-throwing.

### Frontmatter-Based Update Strategy

`orchestrator.ts` `preparePlan()` reads existing `.sum` YAML frontmatter via `readSumFile()`, compares stored `contentHash` against `computeContentHash()` (SHA-256 hex digest), populates `filesToAnalyze` on mismatch (status `'added'` if no .sum, `'modified'` if hash differs), populates `filesToSkip` on match. Calls `cleanupOrphans()` deleting `.sum`/`.annex.sum` for git-deleted files, removing AGENTS.md when no source files remain. Invokes `getAffectedDirectories()` collecting parent directories sorted by depth descending (`depthB - depthA`), enables sequential AGENTS.md regeneration consuming updated child `.sum`. Sets `isFirstRun = filesToSkip.length === 0` when no existing documentation found.

### Dirty Propagation

`orchestrator.ts` `filterExistingDirectories()` implements dirty propagation: marks directories with processed files and all ancestors via `markDirtyWithAncestors()`, checks `isGeneratedAgentsMd()` for existing artifacts, skips clean directories. `markDirtyWithAncestors(dir, dirtySet)` climbs directory tree via `path.dirname()` until reaching root (`'.'`), adding each ancestor to `dirtySet`.

### Serialized Logging

`plan-tracker.ts` uses promise-chain pattern: `this.writeQueue = this.writeQueue.then(() => writeFile(...))` ensures GENERATION-PLAN.md checkbox updates maintain order despite concurrent `markDone()` calls from multiple pool workers. `progress.ts` `ProgressLog` uses same pattern for plain-text log mirroring. Matches `trace.ts` `TraceWriter` lazy file handle opening strategy.

### Memory Optimization

`orchestrator.ts` `createPlan()` nullifies `PreparedFile.content = ''` after `createFileTasks()` to release memory (task prompts already built, runner re-reads disk).

## Behavioral Contracts

### Post-Order Sort
```javascript
getDirectoryDepth(dirB) - getDirectoryDepth(dirA)  // Descending depth
// getDirectoryDepth(dir) = dir === '.' ? 0 : dir.split(path.sep).length
```

### Dirty Propagation Loop
```javascript
current = dir;
while (current !== '.' && current !== '') {
  dirtySet.add(current);
  current = path.dirname(current);
}
```

### Hash-Based Change Detection
```javascript
storedHash !== currentHash  // Triggers re-analysis
// Missing storedHash or absent .sum → 'added' status
```

### Affected Directories Sort
```javascript
depthB - depthA  // Descending depth ensures children processed before parents
// depth = dir === '.' ? 0 : dir.split(path.sep).length
```

### Iterator-Based Pool
```javascript
for (const [index, task] of iterator) {
  // Shared iterator consumed by N workers
}
```

### Serialized Write Queue
```javascript
this.writeQueue = this.writeQueue.then(() => writeFile(...))  // Promise chain
```

### ETA Calculation
```javascript
avg = sum(completionTimes) / length
etaMs = avg * (totalFiles - completed - failed)
// Requires completionTimes.length >= 2, windowSize = 10
```

### Preamble Detection (stripPreamble)
```javascript
// Pattern 1: \n---\n separator within first 500 chars
// Pattern 2: **[A-Z] bold line preceded by <300 chars without ##
```

### Purpose Extraction (extractPurpose)
```javascript
// Skip lines starting with #, ---, or preamble prefixes:
['now i', 'perfect', 'based on', 'let me', 'here is', 'i\'ll', 'i will', 'great', 'okay', 'sure', 'certainly', 'alright']
// Strip **bold** wrapper, truncate to 120 chars with ... suffix
```

### Trace Event Base Fields
```javascript
{
  seq: number,            // Monotonic counter
  ts: string,             // ISO 8601
  pid: number,            // process.pid
  elapsedMs: number       // Number(hrtime.bigint() - startHr) / 1_000_000
}
```

### ANSI Strip Regex
```javascript
/\x1b\[[0-9;]*m/g  // Removes ANSI escape sequences
```

### Progress Log Filename
```javascript
PROGRESS_LOG_FILENAME = 'progress.log'  // In .agents-reverse-engineer/
```

### Traces Directory
```javascript
TRACES_DIR = '.agents-reverse-engineer/traces'
```

### Trace Filename Format
```javascript
`trace-${new Date().toISOString().replace(/[:.]/g, '-')}.ndjson`
```

### Cleanup Retention
```javascript
cleanupOldTraces(projectRoot, keepCount = 500)
// Filters: name.startsWith('trace-') && name.endsWith('.ndjson')
// Sorts: ISO timestamps lexicographically reversed
```

## Reproduction-Critical Constants

Full exit code definitions, concurrency calculation formula, retry policy regex, timeout escalation sequence, code-vs-doc export extraction regex, plan-tracker checkbox replacement logic: [runner.annex.sum](./runner.annex.sum)