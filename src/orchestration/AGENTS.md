<!-- Generated by agents-reverse-engineer -->

# src/orchestration

Orchestrates AI-driven documentation generation through three-phase pipeline (concurrent file analysis, post-order directory AGENTS.md generation, sequential root document generation) with iterator-based concurrency control, NDJSON tracing, and progress reporting.

## Contents

### Core Orchestration

**[runner.ts](./runner.ts)** — CommandRunner executes `executeGenerate()` three-phase pipeline: Phase 1 calls `buildFilePrompt()` → `aiService.call()` → `writeSumFile()` with `runPool()` concurrency, Phase 2 groups `directoryTasks` by depth and calls `buildDirectoryPrompt()` → `writeAgentsMd()` in post-order traversal, Phase 3 runs `buildRootPrompt()` → `writeFile()` sequentially, wraps each phase with pre/post quality checks (`checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`), returns `RunSummary` aggregate. Implements `executeUpdate()` for incremental file updates (Phase 1 only). Wires `options.tracer` into `aiService.setTracer()` for subprocess event propagation. Emits `phase:start`/`phase:end`/`task:start`/`task:done` trace events. Uses `stripPreamble()` to remove LLM conversational output before content markers (`'\n---\n'` or bold purpose line regex).

**[pool.ts](./pool.ts)** — `runPool<T>(tasks, options, onComplete)` executes async task factories through shared-iterator worker pattern, spawning `Math.min(options.concurrency, tasks.length)` workers that pull `[index, task]` pairs from single shared `tasks.entries()` iterator. Each worker calls `onComplete?.(result)` after task settles, checks `aborted` flag when `failFast` enabled to break loop on first error. Returns `TaskResult<T>[]` indexed by original task position (may be sparse if aborted mid-execution). Emits `worker:start`/`worker:end`/`task:pickup`/`task:done` trace events with `workerId`, `taskIndex`, `taskLabel`, `activeTasks`, `durationMs`, `success`. Accepts `PoolOptions` with `concurrency`, `failFast?`, `tracer?`, `phaseLabel?`, `taskLabels?`.

**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` serializes concurrent checkbox updates to `GENERATION-PLAN.md` during Phase 1 file analysis, maintains in-memory `content` string with markdown task list, exposes `markDone(itemPath)` to replace `- [ ]` with `- [x]`, queues writes via `writeQueue: Promise<void>` chain to prevent corruption from parallel worker completions. Caller must pass `itemPath` exactly as it appears in markdown: `src/cli/init.ts` for files, `src/cli/AGENTS.md` for directories, `CLAUDE.md` for root docs. Constructor computes `planPath` as `{projectRoot}/${CONFIG_DIR}/GENERATION-PLAN.md`. Swallows errors silently to treat tracking failures as non-critical.

### Progress Reporting

**[progress.ts](./progress.ts)** — `ProgressReporter` streams colored console output via `picocolors` (`pc.cyan()`, `pc.green()`, `pc.red()`, `pc.blue()`) with ETA calculation using moving average of last 10 completion times (`completionTimes[]` sliding window), exposes `onFileStart()/onFileDone()/onFileError()` for file tasks, `onDirectoryStart()/onDirectoryDone()` for directory tasks, `onRootDone()` for root tasks, `printSummary(summary)` for final metrics. Computes `totalIn = tokensIn + cacheReadTokens + cacheCreationTokens` to display total prompt size including cached tokens, formats as `${totalIn}/${tokensOut} tok`. `ProgressLog` mirrors console output to `.agents-reverse-engineer/progress.log` without ANSI escape codes via `stripAnsi()` regex `/\x1b\[[0-9;]*m/g`, uses `FileHandle` from `node:fs/promises` opened in mode `'w'`, serializes writes via `writeQueue` promise-chain pattern, exposes `write(line)` and `finalize()`.

### Tracing

**[trace.ts](./trace.ts)** — `createTraceWriter(projectRoot, enabled)` factory returns `NullTraceWriter` (zero overhead) when disabled or `TraceWriter` that appends NDJSON events to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson`. `TraceWriter` maintains `seq` (monotonic counter), `nodePid` (process.pid), `startHr` (process.hrtime.bigint()), serializes writes via `writeQueue` chain, lazily opens `fd: FileHandle` on first `emit()`. Auto-populates each event with `seq`, `ts` (ISO 8601), `pid`, `elapsedMs` (high-resolution fractional ms since run start). Exposes `emit(event)` and `finalize()`. `cleanupOldTraces(projectRoot, keepCount)` removes old trace files, keeping most recent `keepCount` entries, returns count deleted. `ITraceWriter` interface defines public contract. `TraceEvent` discriminated union includes `PhaseStartEvent`, `PhaseEndEvent`, `WorkerStartEvent`, `WorkerEndEvent`, `TaskPickupEvent`, `TaskDoneEvent`, `TaskStartEvent`, `SubprocessSpawnEvent`, `SubprocessExitEvent`, `RetryEvent`, `DiscoveryStartEvent`, `DiscoveryEndEvent`, `FilterAppliedEvent`, `PlanCreatedEvent`, `ConfigLoadedEvent`. `TraceEventPayload` type uses `DistributiveOmit<TraceEvent, BaseKeys>` to strip auto-populated fields before user passes event to `emit()`.

### Types & API Facade

**[types.ts](./types.ts)** — `FileTaskResult` represents outcome of single file analysis with `path`, `success`, `tokensIn`, `tokensOut`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `model`, `error?`. `RunSummary` aggregates metrics from complete generate or update command execution with `version`, `filesProcessed`, `filesFailed`, `filesSkipped`, `totalCalls`, `totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheCreationTokens`, `totalDurationMs`, `errorCount`, `retryCount`, `totalFilesRead`, `uniqueFilesRead`, `inconsistenciesCodeVsDoc?`, `inconsistenciesCodeVsCode?`, `phantomPaths?`, `inconsistencyReport?`. `ProgressEvent` discriminated union emitted during execution with `type: 'start' | 'done' | 'error' | 'dir-done' | 'root-done'`, includes `filePath`, `index`, `total`, `durationMs?`, `tokensIn?`, `tokensOut?`, `model?`, `error?`. `CommandRunOptions` configures execution with `concurrency`, `failFast?`, `debug?`, `dryRun?`, `tracer?`, `progressLog?`.

**[index.ts](./index.ts)** — Barrel export re-exports all types, functions, and classes from pool.ts (`runPool`, `PoolOptions`, `TaskResult`), progress.ts (`ProgressReporter`, `ProgressLog`), plan-tracker.ts (`PlanTracker`), trace.ts (`createTraceWriter`, `cleanupOldTraces`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`), runner.ts (`CommandRunner`), types.ts (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`). Serves as public API facade for orchestration module.

## Architecture

### Three-Phase Pipeline

1. **Pre-Phase 1 (cache)**: Reads existing `.sum` files concurrently (concurrency=20) into `oldSumCache` for stale documentation detection, phase label `'pre-phase-1-cache'`
2. **Phase 1 (files)**: Runs `plan.fileTasks` through `runPool()` with `options.concurrency`, calls `buildFilePrompt()` → `aiService.call()` → `stripPreamble()` → `writeSumFile()` + `writeAnnexFile()` (if response contains `'## Annex References'`), caches source content for inconsistency detection, phase label `'phase-1-files'`
3. **Post-Phase 1 (quality)**: Groups processed files by directory, runs `checkCodeVsDoc()` (old-doc stale + new-doc omission) and `checkCodeVsCode()` per directory group with concurrency=10, phase label `'post-phase-1-quality'`, builds `InconsistencyReport`
4. **Phase 2 (directories)**: Groups `plan.directoryTasks` by `metadata.depth`, processes depth levels in descending order (deepest first = post-order traversal), each depth level runs concurrently with phase label `'phase-2-dirs-depth-{depth}'`, calls `buildDirectoryPrompt()` → `aiService.call()` → `writeAgentsMd()`
5. **Post-Phase 2 (phantom paths)**: Reads all generated `AGENTS.md` files, runs `checkPhantomPaths()` to detect references to non-existent files, phase label `'post-phase-2-phantom'`
6. **Phase 3 (root)**: Runs `plan.rootTasks` sequentially (concurrency=1) with phase label `'phase-3-root'`, calls `buildRootPrompt()` → `aiService.call()` with `maxTurns: 1` → strips conversational preamble by finding first `'# '` heading → `writeFile()`

### Shared-Iterator Concurrency Pattern

All workers iterate over single shared `tasks.entries()` iterator. Each `worker(iterator, workerId)` pulls `[index, task]` pairs in for-of loop, ensuring exactly one worker executes each task. When worker completes task, it immediately pulls next entry from iterator, avoiding batch-based idling where `Promise.all` on chunks waits for slowest task in each batch. The `aborted` flag set to `true` when `failFast` enabled and any task throws, workers check `if (aborted) break` before pulling next task.

### Promise-Chain Serialization

`writeQueue: Promise<void>` field initialized to `Promise.resolve()` serves as promise chain anchor. Each write appends `writeQueue.then(() => writeFile(...))` to serialize concurrent writes from pool workers. Pattern used in: `PlanTracker.markDone()`, `ProgressLog.write()`, `TraceWriter.emit()`. Errors caught and suppressed with empty catch block to treat telemetry failures as non-critical.

## Trace Events

Phase lifecycle: `phase:start` (before pool spawn) → `phase:end` (after pool settles) with `phase`, `taskCount`, `concurrency`, `durationMs`, `tasksCompleted`, `tasksFailed`

Worker lifecycle: `worker:start` (before pulling first task) → `task:pickup` (before executing task) → `task:done` (after task settles) → `worker:end` (after loop exits) with `workerId`, `taskIndex`, `taskLabel`, `activeTasks`, `durationMs`, `success`, `error?`

Subprocess lifecycle: `subprocess:spawn` (after `execFile()` call) → `subprocess:exit` (after process ends) with `childPid`, `command`, `taskLabel`, `exitCode`, `signal`, `durationMs`, `timedOut`

Retry events: `retry` with `attempt`, `taskLabel`, `errorCode`

Discovery events: `discovery:start`/`discovery:end`, `filter:applied`

Config events: `config:loaded`, `plan:created`

## Data Flow

```
CLI → CommandRunner.executeGenerate(plan)
  → Pre-Phase 1: runPool(read .sum files) → oldSumCache
  → Phase 1: runPool(buildFilePrompt → aiService.call → writeSumFile) → FileTaskResult[]
    → PlanTracker.markDone(path) for each completion
    → ProgressReporter.onFileDone() for each success
  → Post-Phase 1: runPool(checkCodeVsDoc + checkCodeVsCode) → InconsistencyReport
  → Phase 2: for each depth in descending order:
      runPool(buildDirectoryPrompt → aiService.call → writeAgentsMd)
  → Post-Phase 2: runPool(checkPhantomPaths) → InconsistencyReport
  → Phase 3: runPool(buildRootPrompt → aiService.call → writeFile, concurrency=1)
  → RunSummary (merge aiService.getSummary() + phase counters + quality metrics)
```

## Behavioral Contracts

### Preamble Stripping Patterns

**Pattern 1 (separator)**: `'\n---\n'` within first 500 chars, returns content after separator

**Pattern 2 (bold purpose line)**: `/^[\s\S]{0,500}?(\*\*[A-Z])/` finds bold purpose line, strips preceding text if <300 chars and lacks `'##'`

**Purpose extraction prefixes**: Skip lines starting with `PREAMBLE_PREFIXES = ['now i', 'perfect', 'based on', 'let me', 'here is', 'i\'ll', 'i will', 'great', 'okay', 'sure', 'certainly', 'alright']`, strip `**...**` wrapper, truncate at 120 chars with `'...'` suffix

### Trace Filename Format

`trace-${safeTimestamp}.ndjson` where `safeTimestamp = new Date().toISOString().replace(/[:.]/g, '-')`

### ANSI Stripping Regex

`/\x1b\[[0-9;]*m/g` removes ANSI escape codes before writing to ProgressLog

### Task Path Format (PlanTracker)

- File tasks: `src/cli/init.ts` (relative file path)
- Directory tasks: `src/cli/AGENTS.md` (caller appends `/AGENTS.md` suffix)
- Root document tasks: `CLAUDE.md` (bare filename)

## Reproduction-Critical Constants

Full preamble stripping logic and phase label strings: [runner.ts.annex.md](./runner.ts.annex.md)