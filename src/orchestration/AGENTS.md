<!-- Generated by agents-reverse-engineer -->

# src/orchestration

**Worker pool concurrency control, promise-chain serialized progress tracking, NDJSON trace emission, and three-phase pipeline orchestration executing concurrent file analysis, post-order directory aggregation, and sequential root synthesis with integrated quality validation, ETA calculation, and subprocess lifecycle tracing.**

## Contents

### Core Orchestration

**[index.ts](./index.ts)** — Barrel export consolidating `runPool`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `createTraceWriter`, `cleanupOldTraces`, `CommandRunner`, and shared types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`).

**[pool.ts](./pool.ts)** — Iterator-based worker pool executing `Array<() => Promise<T>>` tasks via shared `tasks.entries()` iterator consumed by N workers, preventing batch-stall anti-pattern where `Promise.all()` chunks idle workers waiting for slowest task. Emits `worker:start/end`, `task:pickup/done` trace events. Supports `failFast` via shared `aborted` boolean flag checked at loop start. Effective concurrency via `Math.min(options.concurrency, tasks.length)`.

**[runner.ts](./runner.ts)** — `CommandRunner` orchestrates three-phase pipeline via `executeGenerate(plan)` and `executeUpdate(filesToAnalyze, projectRoot, config)`. Phase 1: concurrent file analysis via `runPool()` with `options.concurrency`, reads source via `readFile()`, caches in `sourceContentCache`, calls `aiService.call()`, computes `contentHash` via `computeContentHashFromString()`, strips preamble via `stripPreamble()`, extracts purpose via `extractPurpose()`, writes via `writeSumFile()`, detects `## Annex References` marker for `writeAnnexFile()`. Post-Phase 1: groups files by directory, runs quality checks concurrently (concurrency=10) via `checkCodeVsDoc(source, oldSum)` (stale), `checkCodeVsDoc(source, newSum)` (fresh), `checkCodeVsCode(filesForCodeVsCode)`, builds `InconsistencyReport`, clears `sourceContentCache`. Phase 2: groups `directoryTasks` by depth, processes in descending order (deepest first) with concurrency `Math.min(options.concurrency, dirsAtDepth.length)`, builds prompts via `buildDirectoryPrompt()`, writes via `writeAgentsMd()`. Post-Phase 2: validates phantom paths via `checkPhantomPaths(agentsMdPath, content, projectRoot)`. Phase 3: sequential root document synthesis (concurrency=1), strips conversational preamble before `writeFile()`. Returns `RunSummary` with counts from `aiService.getSummary()` plus `inconsistenciesCodeVsDoc`, `inconsistenciesCodeVsCode`, `phantomPaths`.

### Progress Tracking

**[progress.ts](./progress.ts)** — `ProgressReporter` streams colored console output with ETA calculation via moving average of last 10 `completionTimes` (window size 10), displays after 2+ completions. `ProgressLog` mirrors plain-text output to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes with ANSI stripping (`/\x1b\[[0-9;]*m/g`). Static factory `ProgressLog.create(projectRoot)` constructs path. Methods: `onFileStart(filePath)` (`[X/Y] ANALYZING path`), `onFileDone(filePath, durationMs, tokensIn, tokensOut, model, cacheReadTokens?, cacheCreationTokens?)` (`[X/Y] DONE path Xs in/out tok model ~Ns remaining`), `onFileError(filePath, error)` (`[X/Y] FAIL path error`), `onDirectoryStart(dirPath)`, `onDirectoryDone()`, `onRootDone(docPath)`, `printSummary(summary)`. ETA formatted via `formatETA()` computing `avg * remaining` as `~Ns remaining` (<60s) or `~Mm Ss remaining` (≥60s).

**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` maintains in-memory `GENERATION-PLAN.md` content, serializes concurrent checkbox updates via promise-chain writes. Constructor accepts `projectRoot` and `initialMarkdown`, computes `planPath` as `path.join(projectRoot, CONFIG_DIR, 'GENERATION-PLAN.md')`. `markDone(itemPath)` replaces `` `- [ ] \`${itemPath}\`` `` → `` `- [x] \`${itemPath}\`` ``, chains write to `writeQueue` promise. `initialize()` creates parent directory via `mkdir(..., {recursive: true})`, writes initial content. `flush()` awaits `writeQueue` completion.

### Trace Infrastructure

**[trace.ts](./trace.ts)** — `createTraceWriter(projectRoot, enabled)` factory returns `NullTraceWriter` (zero overhead) when disabled or `TraceWriter` appending NDJSON to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson` with promise-chain serialization. `TraceWriter` auto-populates `seq` (monotonic), `ts` (ISO 8601), `pid` (`process.pid`), `elapsedMs` (high-resolution `process.hrtime.bigint()` delta) on `emit(partial: TraceEventPayload)`. `finalize()` awaits `writeQueue`, closes `fd`. `cleanupOldTraces(projectRoot, keepCount=500)` removes old traces, keeps most recent 500.

**Event types:** `phase:start/end` (phase, taskCount, concurrency, durationMs, tasksCompleted, tasksFailed), `worker:start/end` (workerId, phase, tasksExecuted), `task:pickup/done` (workerId, taskIndex, taskLabel, activeTasks, durationMs, success, error?), `task:start` (taskLabel, phase), `subprocess:spawn/exit` (childPid, command, taskLabel, exitCode, signal, durationMs, timedOut), `retry` (attempt, taskLabel, errorCode), `discovery:start/end` (targetPath, filesIncluded, filesExcluded, durationMs), `filter:applied` (filterName, filesMatched, filesRejected), `plan:created` (planType, fileCount, taskCount), `config:loaded` (configPath, model, concurrency).

**[types.ts](./types.ts)** — Defines `FileTaskResult` (path, success, tokensIn, tokensOut, cacheReadTokens, cacheCreationTokens, durationMs, model, error?), `RunSummary` (version, filesProcessed, filesFailed, filesSkipped, totalCalls, totalInputTokens, totalOutputTokens, totalCacheReadTokens, totalCacheCreationTokens, totalDurationMs, errorCount, retryCount, totalFilesRead, uniqueFilesRead, inconsistenciesCodeVsDoc?, inconsistenciesCodeVsCode?, phantomPaths?, inconsistencyReport?), `ProgressEvent` (discriminated type: start|done|error|dir-done|root-done with filePath, index, total, durationMs?, tokensIn?, tokensOut?, model?, error?), `CommandRunOptions` (concurrency, failFast?, debug?, dryRun?, tracer?: ITraceWriter, progressLog?: ProgressLog), `PoolOptions` (concurrency, failFast?, tracer?, phaseLabel?, taskLabels?), `TaskResult<T>` (index, success, value?, error?).

## Architecture

### Shared-Iterator Concurrency

`runPool()` creates `tasks.entries()` iterator shared across N workers via `for (const [index, task] of iterator)` loop. Workers race to pull tasks atomically via iterator protocol, preventing over-allocation where `Promise.all()` chunks spawn tasks eagerly. Effective concurrency via `Math.min(options.concurrency, tasks.length)` prevents idle workers when task count < pool size.

### Promise-Chain Serialization

`PlanTracker`, `ProgressLog`, `TraceWriter` serialize concurrent writes via `this.writeQueue = this.writeQueue.then(() => writeOp())` pattern. Each write operation chains onto tail of promise, forming sequential execution queue despite concurrent worker invocations. Errors caught via `.catch()` suppression (non-critical telemetry).

### Three-Phase Pipeline

Phase 1: concurrent file analysis via `runPool(fileTasks, {concurrency: options.concurrency})`, reads source via `readFile()` once, caches in `sourceContentCache` Map, calls `aiService.call()`, writes `.sum` via `writeSumFile()`, writes `.annex.md` if `## Annex References` detected. Post-Phase 1: groups files by directory, validates via `checkCodeVsDoc(source, oldSum)` (stale docs), `checkCodeVsDoc(source, newSum)` (LLM omissions), `checkCodeVsCode(files)` (duplicate exports) at concurrency=10, clears `sourceContentCache`.

Phase 2: groups `directoryTasks` by depth (`task.metadata.depth`), processes depth levels sequentially in descending order (deepest first) via `Array.from(dirsByDepth.keys()).sort((a,b) => b-a)`, executes depth level concurrently with `Math.min(concurrency, dirsAtDepth.length)`, builds prompts via `buildDirectoryPrompt()`, writes via `writeAgentsMd()`. Post-Phase 2: validates phantom paths via `checkPhantomPaths()` extracting path-like strings via three regex patterns, resolving against directory and project root.

Phase 3: sequential root synthesis (concurrency=1), builds prompts via `buildRootPrompt()`, calls `aiService.call()` with `maxTurns: 1`, strips conversational preamble before `writeFile()`.

### Quality Validation Timing

Pre-Phase 1: reads existing `.sum` files concurrently (concurrency=20) into `oldSumCache` Map. Post-Phase 1: compares `oldSum` vs. source (stale documentation from previous runs), compares `newSum` vs. source (LLM omissions in current run), aggregates duplicate exports. Post-Phase 2: validates AGENTS.md path references. Validation failures logged to stderr with `[quality]` prefix, never throw (non-blocking).

### Trace Event Threading

`CommandRunOptions.tracer` threaded through pool → AIService → runner. Phase-level `phase:start/end` emitted by runner. Pool-level `worker:start/end`, `task:pickup/done` emitted by `runPool()`. Subprocess-level `subprocess:spawn/exit`, `retry` emitted by `AIService`. Zero overhead when `tracer` is `NullTraceWriter`.

### ETA Calculation

`ProgressReporter` maintains sliding windows `completionTimes` and `dirCompletionTimes` (max size 10). `formatETA()` computes `avg = sum(completionTimes) / completionTimes.length`, `remaining = totalFiles - completed - failed`, `etaMs = avg * remaining`. Displays after 2+ completions to avoid inaccurate early estimates. Formats as `~Ns remaining` (<60s) or `~Mm Ss remaining` (≥60s).

## Behavioral Contracts

### Preamble Detection Patterns (from runner.ts)

Full patterns preserved in [runner.ts.annex.md](./runner.ts.annex.md).

**Separator pattern:** Detects `\n---\n` within first 500 chars.

**Bold header pattern:** Matches `/^[\s\S]{0,500}?(\*\*[A-Z])/`, strips preceding content if <300 chars, no `##` markers.

**Preamble prefixes (case-insensitive):** `'now i'`, `'perfect'`, `'based on'`, `'let me'`, `'here is'`, `'i\'ll'`, `'i will'`, `'great'`, `'okay'`, `'sure'`, `'certainly'`, `'alright'`.

### Checkbox Update Pattern (from plan-tracker.ts)

Replaces `` `- [ ] \`${itemPath}\`` `` → `` `- [x] \`${itemPath}\`` `` via string substitution. Item path conventions: files use relative paths (`src/cli/init.ts`), directories append `/AGENTS.md` suffix (`src/cli/AGENTS.md`), root documents use filename only (`CLAUDE.md`).

### ANSI Stripping Regex (from progress.ts)

`/\x1b\[[0-9;]*m/g` matches all SGR, cursor, and erase sequences before writing to `.agents-reverse-engineer/progress.log`.

### Trace Filename Format (from trace.ts)

`trace-{timestamp}.ndjson` where timestamp from `new Date().toISOString().replace(/[:.]/g, '-')` (e.g., `trace-2026-02-09T12-34-56-789Z.ndjson`).

## File Relationships

`CommandRunner` orchestrates via dependencies: `runPool()` for worker execution, `PlanTracker` for checkbox updates, `ProgressReporter` for console output, `ProgressLog` for file mirroring, `TraceWriter` for NDJSON events, `AIService` for subprocess calls, `buildFilePrompt/buildDirectoryPrompt/buildRootPrompt` from generation module, `writeSumFile/readSumFile/writeAnnexFile/writeAgentsMd` from writers, `checkCodeVsDoc/checkCodeVsCode/checkPhantomPaths` from quality module, `computeContentHashFromString` from change-detection.

`runPool()` invokes task factories, emits trace events via `tracer?.emit()`, invokes `onComplete` callback per task settlement, returns `TaskResult[]` array.

`ProgressReporter` receives events via `onFileStart/Done/Error/DirectoryStart/Done/RootDone`, computes ETA via sliding windows, delegates to `ProgressLog.write()` for file mirroring, prints summary via `printSummary(RunSummary)`.

`PlanTracker` initialized with `formatExecutionPlanAsMarkdown()` output, updated via `markDone(itemPath)` from pool workers, flushed via `flush()` before orchestrator return.

`TraceWriter` emits events via `emit(partial)`, auto-populates base fields (`seq`, `ts`, `pid`, `elapsedMs`), serializes writes via promise chain, finalized via `finalize()` after all phases complete.