<!-- Generated by agents-reverse-engineer -->

# src/orchestration

Iterator-based concurrency engine for two-phase AI documentation generation: parallel file analysis via shared-iterator worker pool (`pool.ts` `runPool()`), post-order directory aggregation sorted by depth descending (`runner.ts` `dirsByDepth`), promise-chain serialized progress tracking (`plan-tracker.ts` `PlanTracker`, `progress.ts` `ProgressLog`), and append-only NDJSON trace emission for subprocess/worker/task lifecycle debugging (`trace.ts` `TraceWriter`).

## Contents

**[index.ts](./index.ts)** — Barrel export re-exporting `FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`, `runPool`, `createTraceWriter`, `cleanupOldTraces`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `CommandRunner`.

**[pool.ts](./pool.ts)** — Zero-dependency concurrency limiter `runPool<T>(tasks, options, onComplete)` spawning `min(concurrency, tasks.length)` workers sharing single `tasks.entries()` iterator. Each worker pulls `[index, task]` pairs until exhausted or `aborted` flag set via `failFast`. Returns `TaskResult<T>[]` preserving original task order via `index` field. Tracing emits `worker:start`, `worker:end`, `task:pickup`, `task:done` events via `ITraceWriter`.

**[runner.ts](./runner.ts)** — Five-phase orchestrator `CommandRunner.executeGenerate(plan)`: pre-phase-1-cache (reads existing `.sum` into `oldSumCache`), phase-1-files (parallel `aiService.call` + `writeSumFile` + `writeAnnexFile`), post-phase-1-quality (`checkCodeVsDoc` old/new-doc + `checkCodeVsCode`), phase-2-dirs (post-order `writeAgentsMd` + `writeClaudeMdPointer` grouped by depth descending), post-phase-2 (`checkPhantomPaths` on `AGENTS.md`). `executeUpdate(filesToAnalyze)` runs phase-1/post-phase-1 for changed files. Emits `RunSummary` with token counts, inconsistency counts, telemetry.

**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` serializes `GENERATION-PLAN.md` checkbox updates via promise-chain `writeQueue` pattern. `markDone(itemPath)` replaces `- [ ] \`${itemPath}\`` with `- [x] \`${itemPath}\`` in-memory, chains write to `writeQueue`. `flush()` waits for pending writes.

**[progress.ts](./progress.ts)** — `ProgressReporter` streams build-log events via `console.log` with colored `picocolors` output: `onFileStart` logs `[X/Y] ANALYZING path`, `onFileDone` logs `[X/Y] DONE path Xs in/out tok model ~Ns remaining` with ETA from `completionTimes` sliding window (size 10), `onDirectoryDone` logs `[dir X/Y] DONE dirPath/AGENTS.md Xs in/out tok model`. `ProgressLog` mirrors output to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes for `tail -f` monitoring.

**[trace.ts](./trace.ts)** — `ITraceWriter.emit(event)` appends NDJSON events to `.agents-reverse-engineer/traces/trace-{ISO8601}.ndjson` with auto-populated `seq`, `ts`, `pid`, `elapsedMs` (microsecond precision via `process.hrtime.bigint()`). Supports 16 event types: `PhaseStartEvent`/`PhaseEndEvent`, `WorkerStartEvent`/`WorkerEndEvent`, `TaskPickupEvent`/`TaskDoneEvent`, `SubprocessSpawnEvent`/`SubprocessExitEvent`, `RetryEvent`, `DiscoveryStartEvent`/`DiscoveryEndEvent`, `FilterAppliedEvent`, `PlanCreatedEvent`, `ConfigLoadedEvent`. Promise-chain serialization via `writeQueue` ensures safe concurrent writes. `cleanupOldTraces(projectRoot, keepCount=500)` removes old trace files.

**[types.ts](./types.ts)** — Type contracts: `FileTaskResult` (path, success, tokensIn, tokensOut, cacheReadTokens, cacheCreationTokens, durationMs, model, error), `RunSummary` (version, filesProcessed, filesFailed, filesSkipped, totalCalls, totalInputTokens, totalOutputTokens, totalCacheReadTokens, totalCacheCreationTokens, totalDurationMs, errorCount, retryCount, totalFilesRead, uniqueFilesRead, inconsistenciesCodeVsDoc, inconsistenciesCodeVsCode, phantomPaths, inconsistencyReport), `ProgressEvent` (type `'start'|'done'|'error'|'dir-done'`, filePath, index, total, durationMs, tokensIn, tokensOut, model, error), `CommandRunOptions` (concurrency, failFast, debug, dryRun, tracer, progressLog).

## Architecture

### Shared-Iterator Worker Pattern

`runPool()` spawns `min(concurrency, tasks.length)` async workers sharing single `tasks.entries()` iterator. Each worker runs `for (const [index, task] of taskIterator)` loop pulling `[index, task]` pairs until exhausted. Shared iterator ensures exactly one worker picks up each task, maintaining full utilization as variable-duration tasks complete. When `failFast: true` and any task throws, worker sets `aborted = true` and breaks; other workers check `if (aborted)` before next pull.

### Post-Order Aggregation

`CommandRunner` sorts directory tasks via `dirsByDepth` grouping by `getDirectoryDepth(dirB) - getDirectoryDepth(dirA)` (descending). Processes each depth level sequentially (awaits completion before next depth), executes concurrently within depth level via `runPool()`. Ensures child `.sum` files exist before parent `AGENTS.md` generation via `buildDirectoryPrompt()` reads.

### Promise-Chain Serialization

`PlanTracker.writeQueue` and `ProgressLog.writeQueue` use pattern `this.writeQueue = this.writeQueue.then(async () => writeFile(...)).catch(() => {})` to serialize concurrent `writeFile()` calls from multiple pool workers. Each `markDone()` or `write()` call appends write to chain, ensuring sequential disk updates without corruption. `finalize()` waits for `writeQueue` completion.

### Five-Phase Execution

1. **pre-phase-1-cache**: Read existing `.sum` YAML frontmatter into `oldSumCache` for stale-doc detection (concurrency 20).
2. **phase-1-files**: Parallel `aiService.call` → `writeSumFile` + `writeAnnexFile` for each file task (user concurrency).
3. **post-phase-1-quality**: Group files by `path.dirname`, run `checkCodeVsDoc` twice (old-doc + new-doc), run `checkCodeVsCode` per group (concurrency 10).
4. **phase-2-dirs**: Post-order `buildDirectoryPrompt` → `writeAgentsMd` + `writeClaudeMdPointer` grouped by depth (concurrent per depth level).
5. **post-phase-2**: `checkPhantomPaths` on generated `AGENTS.md` files.

### Telemetry Integration

`ITraceWriter.emit()` logs 16 event types with `seq` (monotonic counter), `ts` (ISO 8601), `pid`, `elapsedMs` (microsecond precision via `process.hrtime.bigint()`). Events track phase lifecycle (`PhaseStartEvent`/`PhaseEndEvent` with `phase`, `taskCount`, `concurrency`, `durationMs`, `tasksCompleted`, `tasksFailed`), worker lifecycle (`WorkerStartEvent`/`WorkerEndEvent` with `workerId`, `phase`, `tasksExecuted`), task tracking (`TaskPickupEvent`/`TaskDoneEvent` with `workerId`, `taskIndex`, `taskLabel`, `activeTasks`, `durationMs`, `success`, `error`), subprocess monitoring (`SubprocessSpawnEvent`/`SubprocessExitEvent` with `childPid`, `command`, `exitCode`, `signal`, `timedOut`), retry attempts (`RetryEvent` with `attempt`, `errorCode`), discovery (`DiscoveryStartEvent`/`DiscoveryEndEvent` with `filesIncluded`, `filesExcluded`), planning (`PlanCreatedEvent` with `planType`, `fileCount`), configuration (`ConfigLoadedEvent` with `configPath`, `model`). `createTraceWriter(projectRoot, enabled)` returns `NullTraceWriter` when `enabled=false` for zero-overhead no-op.

## Quality Check Integration

Post-phase-1-quality groups processed files by directory, runs `checkCodeVsDoc(filePath, sourceContent, sumContent)` twice per file: once with `oldSumCache` for stale-doc detection (missing exports in old doc), once with freshly read `.sum` for LLM-omission detection (missing exports in new doc). Runs `checkCodeVsCode(dirPath, filesForCodeVsCode)` per directory group to detect duplicate symbols. Post-phase-2 runs `checkPhantomPaths(agentsMdPath)` to validate markdown links via `/\[(?:[^\]]*)\]\((\.[^)]+)\)/g` + backtick paths + prose references. Builds `InconsistencyReport` via `buildInconsistencyReport()`, emits formatted output via `formatReportForCli()`. All quality checks wrapped in try-catch to prevent pipeline breakage.

## Progress Tracking

`ProgressReporter.onFileDone()` records `durationMs` in `completionTimes` sliding window (size 10), computes ETA via `remaining = totalFiles - completed - failed` × average completion time, formats as `~12s remaining` or `~2m 30s remaining`. `ProgressLog` mirrors console output to `.agents-reverse-engineer/progress.log` via `stripAnsi()` removing ANSI escape codes (`/\x1b\[[0-9;]*m/g`), enables `tail -f` monitoring in buffered environments. `PlanTracker` writes `GENERATION-PLAN.md` via `formatExecutionPlanAsMarkdown()`, updates checkboxes via `markDone(itemPath)` replacing `- [ ] \`${itemPath}\`` with `- [x] \`${itemPath}\``.

## Behavioral Contracts

### Concurrency Spawn Count
```javascript
Math.min(options.concurrency, tasks.length)
```
Never spawn more workers than tasks.

### Post-Order Depth Sort
```javascript
getDirectoryDepth(dirB) - getDirectoryDepth(dirA)  // Descending depth
// getDirectoryDepth(dir) = dir === '.' ? 0 : dir.split(path.sep).length
```

### Promise-Chain Write Serialization
```javascript
this.writeQueue = this.writeQueue.then(async () => writeFile(...)).catch(() => {})
```
Each write appends to chain, ensuring sequential disk updates.

### ETA Sliding Window
```javascript
windowSize = 10  // completionTimes array max length
averageMs = sum(completionTimes) / completionTimes.length
eta = averageMs * (totalFiles - completed - failed)
```
Requires at least 2 completions before computing ETA.

### Trace Event Base Fields
```javascript
{
  seq: number,          // this.seq++ (monotonic counter)
  ts: string,           // new Date().toISOString()
  pid: number,          // process.pid
  elapsedMs: number     // Number(process.hrtime.bigint() - startHr) / 1_000_000
}
```

### Trace File Naming
```javascript
`trace-${new Date().toISOString().replace(/[:.]/g, '-')}.ndjson`
```
Replaces colons/dots with hyphens for filesystem compatibility.

### ANSI Strip Pattern
```regex
/\x1b\[[0-9;]*m/g
```
Removes ANSI escape sequences for plain-text log output.

### Trace Cleanup Sort
```javascript
entries.filter(e => e.name.startsWith('trace-') && e.name.endsWith('.ndjson'))
  .sort()  // Lexicographic sort (ISO timestamps sort correctly)
  .reverse()  // Newest first
  .slice(keepCount)  // Identify deletion candidates
```

## Annex References

- Full preamble stripping logic and quality check patterns: [runner.annex.sum](./runner.annex.sum)