---
generated_at: 2026-02-09T17:46:15.433Z
content_hash: c54b67ea5f368404974a24012da22317186b49543249ead73a5cec227f874c98
purpose: Barrel export consolidating orchestration module: `runPool`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `creat...
---
**Barrel export consolidating orchestration module: `runPool`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `createTraceWriter`, `cleanupOldTraces`, `CommandRunner`, and shared types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`).**

## Exported Types

**FileTaskResult** — result of single file AI analysis with `path`, `success`, `tokensIn`, `tokensOut`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `model`, `error?`.

**RunSummary** — aggregated run summary with `version`, `filesProcessed`, `filesFailed`, `filesSkipped`, `totalCalls`, `totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheCreationTokens`, `totalDurationMs`, `errorCount`, `retryCount`, `totalFilesRead`, `uniqueFilesRead`, `inconsistenciesCodeVsDoc?`, `inconsistenciesCodeVsCode?`, `phantomPaths?`, `inconsistencyReport?`.

**ProgressEvent** — event emitted to `ProgressReporter` with discriminated `type` (`start` | `done` | `error` | `dir-done` | `root-done`), `filePath`, `index`, `total`, `durationMs?`, `tokensIn?`, `tokensOut?`, `model?`, `error?`.

**CommandRunOptions** — execution options with `concurrency`, `failFast?`, `debug?`, `dryRun?`, `tracer?: ITraceWriter`, `progressLog?: ProgressLog`.

**PoolOptions** — pool configuration with `concurrency`, `failFast?`, `tracer?: ITraceWriter`, `phaseLabel?`, `taskLabels?: string[]`.

**TaskResult<T>** — pool task result with `index`, `success`, `value?: T`, `error?: Error`.

**ITraceWriter** — interface for trace event emission with `emit(event: TraceEventPayload): void`, `finalize(): Promise<void>`, `readonly filePath: string`.

**TraceEvent** — discriminated union of 14 event types: `PhaseStartEvent`, `PhaseEndEvent`, `WorkerStartEvent`, `WorkerEndEvent`, `TaskPickupEvent`, `TaskDoneEvent`, `TaskStartEvent`, `SubprocessSpawnEvent`, `SubprocessExitEvent`, `RetryEvent`, `DiscoveryStartEvent`, `DiscoveryEndEvent`, `FilterAppliedEvent`, `PlanCreatedEvent`, `ConfigLoadedEvent`.

**TraceEventPayload** — `DistributiveOmit<TraceEvent, 'seq' | 'ts' | 'pid' | 'elapsedMs'>` for event payload without auto-populated base fields.

## Exported Functions

**runPool<T>(tasks: Array<() => Promise<T>>, options: PoolOptions, onComplete?: (result: TaskResult<T>) => void): Promise<TaskResult<T>[]>** — iterator-based concurrency pool executing tasks via shared iterator pattern with N workers, optional `onComplete` callback per task settlement, failFast abort on first error, trace event emission for `worker:start/end`, `task:pickup/done`.

**createTraceWriter(projectRoot: string, enabled: boolean): ITraceWriter** — factory returning `NullTraceWriter` when disabled (zero overhead) or `TraceWriter` appending NDJSON to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson` with promise-chain serialization for concurrent-safe writes.

**cleanupOldTraces(projectRoot: string, keepCount?: number): Promise<number>** — removes old trace files from `.agents-reverse-engineer/traces/`, keeps most recent `keepCount` (default 500), returns deletion count.

## Exported Classes

**ProgressReporter** — streaming build-log reporter with `onFileStart(filePath)`, `onFileDone(filePath, durationMs, tokensIn, tokensOut, model, cacheReadTokens?, cacheCreationTokens?)`, `onFileError(filePath, error)`, `onDirectoryStart(dirPath)`, `onDirectoryDone(dirPath, durationMs, tokensIn, tokensOut, model, cacheReadTokens?, cacheCreationTokens?)`, `onRootDone(docPath)`, `printSummary(summary: RunSummary)`. Computes ETA via moving average of last 10 completion times (window size 10), displays after 2+ completions. Constructor: `new ProgressReporter(totalFiles: number, totalDirectories?: number, progressLog?: ProgressLog)`.

**ProgressLog** — file-based progress log mirroring console output to `.agents-reverse-engineer/progress.log` with ANSI stripping via regex `/\x1b\[[0-9;]*m/g`, promise-chain serialized writes, `write(line: string): void`, `finalize(): Promise<void>`. Static factory: `ProgressLog.create(projectRoot: string): ProgressLog`.

**PlanTracker** — updates `GENERATION-PLAN.md` checkboxes during generation via `markDone(itemPath: string): void`, replaces `- [ ] \`itemPath\`` → `- [x] \`itemPath\``, serializes writes via promise chain, `flush(): Promise<void>`. Constructor: `new PlanTracker(projectRoot: string, initialMarkdown: string)`. Methods: `initialize(): Promise<void>` creates parent directory and writes initial content.

**CommandRunner** — three-phase orchestrator with `executeGenerate(plan: ExecutionPlan): Promise<RunSummary>` (concurrent file analysis, post-order directory AGENTS.md, sequential root docs) and `executeUpdate(filesToAnalyze: FileChange[], projectRoot: string, config: Config): Promise<RunSummary>` (Phase 1 only, no directory/root generation). Constructor: `new CommandRunner(aiService: AIService, options: CommandRunOptions)`. Wires `tracer` into `AIService.setTracer()` for subprocess/retry events.

## Integration Pattern

`CommandRunner` orchestrates three-phase pipeline by invoking `runPool` for Phase 1 file tasks and Phase 2 directory tasks (grouped by depth), emitting trace events via `tracer?.emit()`, reporting progress via `ProgressReporter`, tracking GENERATION-PLAN.md checkboxes via `PlanTracker`, caching old `.sum` content for stale doc detection in Pre-Phase 1 (concurrency 20), running inconsistency checks post-Phase 1 via throttled directory groups (concurrency 10), validating phantom paths post-Phase 2, and sequentially executing Phase 3 root tasks with explicit `task:start/done` trace events.

## Concurrency Control

Phase 1 file analysis uses `this.options.concurrency` (user-configured). Phase 2 directory tasks group by depth and execute depth levels sequentially (descending order, deepest first) with `Math.min(concurrency, dirsAtDepth.length)` parallelism per depth level. Phase 3 root tasks execute sequentially (concurrency 1).

## Trace Event Flow

`CommandRunner.executeGenerate()` emits: `phase:start` (pre-phase-1-cache, phase-1-files, post-phase-1-quality, phase-2-dirs-depth-N, post-phase-2-quality, phase-3-root), `phase:end` with `tasksCompleted`/`tasksFailed`/`durationMs`. Phase 3 emits `task:start`/`task:done` per root document. `runPool` emits `worker:start`/`end`, `task:pickup`/`done`. `AIService` emits `subprocess:spawn`/`exit`, `retry`.

## Quality Validation Timing

Pre-Phase 1: reads existing `.sum` files via `readSumFile()` into `oldSumCache`. Post-Phase 1: groups files by directory, throttles inconsistency checks at concurrency 10, compares old `.sum` (stale) and new `.sum` (LLM omissions) via `checkCodeVsDoc()`, runs `checkCodeVsCode()` per directory group, emits `formatReportForCli()` to stderr. Post-Phase 2: validates phantom paths in AGENTS.md via `checkPhantomPaths()`.

## Preamble Stripping

**stripPreamble(responseText: string): string** — removes LLM preamble via two patterns: (1) content after `\n---\n` separator within first 500 chars, (2) content starting with bold purpose line (`**[A-Z]`) preceded by <300 chars preamble without `##` headers.

**extractPurpose(responseText: string): string** — skips lines matching preamble prefixes (`now i`, `perfect`, `based on`, `let me`, `here is`, `i'll`, `i will`, `great`, `okay`, `sure`, `certainly`, `alright`) or headers/separators, strips bold markdown wrapper `**...**`, truncates to 120 chars with `...` suffix.