---
generated_at: 2026-02-09T15:08:05.284Z
content_hash: 42c09530c03faf24c901c3a010c351a0a9bdabf54d884aca3f1e01ecece26b8d
purpose: Iterator-based concurrency pool implementing shared-iterator worker pattern for N concurrent async tasks with zero de...
---
**Iterator-based concurrency pool implementing shared-iterator worker pattern for N concurrent async tasks with zero dependencies, avoiding batch-induced worker idling via continuous task pickup from shared `entries()` iterator.**

## Exported Interface

**`runPool<T>(tasks, options, onComplete?): Promise<TaskResult<T>[]>`** — Executes array of async task factories `Array<() => Promise<T>>` through concurrency-limited pool, returns `TaskResult<T>[]` indexed by original task position, invokes optional `onComplete(result)` callback after each task settles.

**`PoolOptions`** — Configuration interface with:
- `concurrency: number` — Maximum concurrent workers
- `failFast?: boolean` — Aborts new task pickup on first error
- `tracer?: ITraceWriter` — Trace emission sink for debugging
- `phaseLabel?: string` — Phase identifier for trace events (e.g., `'phase-1-files'`)
- `taskLabels?: string[]` — Per-task labels by index for trace correlation

**`TaskResult<T>`** — Discriminated union result container:
- `index: number` — Zero-based position in original `tasks` array
- `success: boolean` — Discriminant for success/error paths
- `value?: T` — Present when `success === true`
- `error?: Error` — Present when `success === false`

## Concurrency Algorithm

Uses shared-iterator pattern to prevent batch anti-pattern. All workers iterate over same `tasks.entries()` iterator; each `[index, task]` pair consumed by exactly one worker via iterator protocol atomicity. Workers execute tight loop: pickup task → execute → emit result → pickup next, maintaining full worker slot utilization without idle periods between batches.

Effective concurrency capped at `Math.min(options.concurrency, tasks.length)` to prevent spawning unused workers. Worker count determines `Array.from({ length: effectiveConcurrency })` spawn loop.

## Fail-Fast Abort Mechanism

Shared mutable `let aborted = false` flag checked by workers before pulling next task from iterator via `if (aborted) break`. First error sets `aborted = true` when `options.failFast === true`, causing all workers to exit after completing current task. Results array may be sparse post-abort (only completed task indices populated).

## Trace Integration

Emits events via `tracer?.emit()` optional chaining:
- `worker:start` — Worker spawn with `workerId`, `phase`
- `task:pickup` — Task acquisition with `workerId`, `taskIndex`, `taskLabel`, `activeTasks` (live counter)
- `task:done` — Task completion with `durationMs`, `success`, `error?`, `activeTasks`
- `worker:end` — Worker termination with `tasksExecuted` count

Active task counter `let activeTasks = 0` incremented before task execution, decremented in both try/catch branches. Provides real-time concurrency snapshot in trace events.

## Error Handling Strategy

Try/catch wraps `await task()` with normalization: `err instanceof Error ? err : new Error(String(err))`. Both success and error paths invoke `onComplete?.(result)` callback with discriminated `TaskResult<T>`. Error stored in `results[index]` with `success: false` for caller inspection. Workers never throw; all errors captured in returned array.

## Worker Lifecycle

Each worker executes `async function worker(iterator, workerId)` consuming shared iterator in for-of loop. Tracks local `let tasksExecuted = 0` counter incremented in both success/error paths for final `worker:end` trace event. Workers exit naturally when iterator exhausted or `aborted` flag set, coordinated via `Promise.allSettled(workers)` awaiting all workers regardless of individual outcomes.

## Results Array Construction

Pre-allocated sparse array `const results: TaskResult<T>[] = []` populated via `results[index] = result` assignment preserving task order. Index from `tasks.entries()` iterator ensures caller can correlate result to original task position. Empty array returned immediately when `tasks.length === 0` (early-exit optimization).

## Usage Pattern

Caller wraps sync task array into async factories: `urls.map(url => () => fetch(url))`. Pool consumes factories not promises to defer execution until worker pickup. Callback `onComplete` enables streaming progress updates without awaiting full pool completion. Typical pattern in ARE: `runPool(fileTasks, { concurrency: 2, failFast: false }, (result) => progress.increment(result.success))`.