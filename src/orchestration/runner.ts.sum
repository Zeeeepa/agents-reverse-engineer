---
generated_at: 2026-02-09T14:10:22.869Z
content_hash: 52863b003f5248e4078c5f018400bad5039bdcbdb08ae6ecd6973861f12283a4
purpose: CommandRunner orchestrates the three-phase AI-driven documentation generation pipeline (file analysis → directory agg...
---
**CommandRunner orchestrates the three-phase AI-driven documentation generation pipeline (file analysis → directory aggregation → root synthesis) with concurrent worker pools, quality validation, progress tracking, and telemetry emission.**

## Exported Class

### CommandRunner

```typescript
class CommandRunner {
  constructor(aiService: AIService, options: CommandRunOptions)
  async executeGenerate(plan: ExecutionPlan): Promise<RunSummary>
  async executeUpdate(filesToAnalyze: FileChange[], projectRoot: string, config: Config): Promise<RunSummary>
}
```

Wires together `AIService`, `ExecutionPlan`, worker pool (`runPool`), `ProgressReporter`, `PlanTracker`, and optional `ITraceWriter` into cohesive execution engine. Instantiate once per CLI command invocation. Automatically sets tracer on `AIService` via `setTracer()` if `options.tracer` provided.

## Phase Execution Architecture

### executeGenerate Pipeline

**Pre-Phase 1 (Sum Cache Load):**
- Spawns 20-worker pool to read existing `.sum` files via `readSumFile()` into `oldSumCache` Map for stale documentation detection
- Emits `phase:start` and `phase:end` trace events with phase label `'pre-phase-1-cache'`

**Phase 1 (File Analysis - Concurrent):**
- Spawns N-worker pool (concurrency from `options.concurrency`) processing `plan.fileTasks`
- Each task: reads source file, calls `AIService.call()` with `buildFilePrompt()`, computes `contentHash` via `computeContentHashFromString()`, writes `.sum` via `writeSumFile()`, caches source content in `sourceContentCache` Map
- Calls `AIService.addFilesReadToLastEntry()` with file size from `Buffer.byteLength()` to track telemetry
- Pool callback updates `ProgressReporter` via `onFileDone()`/`onFileError()`, marks `PlanTracker` via `markDone()`, increments `filesProcessed`/`filesFailed`
- Emits trace events: `phase:start`/`phase:end` with phase label `'phase-1-files'`

**Post-Phase 1 (Quality Validation - Non-Throwing):**
- Groups processed files by directory via `path.dirname()` into `dirGroups` Map
- Spawns 10-worker pool processing directory groups (throttled I/O)
- Per group: runs `checkCodeVsDoc()` on cached `sourceContentCache` content against both `oldSumCache` (detects stale docs) and freshly written `.sum` files (detects LLM omissions), runs `checkCodeVsCode()` on group files, aggregates issues
- Clears `sourceContentCache` to free memory
- Builds `InconsistencyReport` via `buildInconsistencyReport()`, prints via `formatReportForCli()`, populates `inconsistenciesCodeVsDoc`/`inconsistenciesCodeVsCode` counters
- Emits trace events: `phase:start`/`phase:end` with phase label `'post-phase-1-quality'`

**Phase 2 (Directory Docs - Post-Order):**
- Groups `plan.directoryTasks` by depth via `metadata.depth` into `dirsByDepth` Map
- Processes depth levels in descending order (deepest first via `.sort((a,b) => b-a)`) to enforce post-order traversal
- Per depth level: spawns worker pool (concurrency = `min(options.concurrency, dirsAtDepth.length)`) with phase label `'phase-2-dirs-depth-N'`
- Each task: builds `knownDirs` Set from all directory task paths, calls `buildDirectoryPrompt()` with knownDirs and `plan.projectStructure`, invokes `AIService.call()`, writes `AGENTS.md` via `writeAgentsMd()`, updates `ProgressReporter` via `onDirectoryDone()`
- Emits trace events per depth level: `phase:start`/`phase:end` with depth-specific phase labels

**Post-Phase 2 (Phantom Path Validation - Non-Throwing):**
- Reads all `AGENTS.md` files from `plan.directoryTasks` via `readFile()`
- Runs `checkPhantomPaths()` per directory, aggregates issues, prints `InconsistencyReport`, populates `phantomPathCount`

**Phase 3 (Root Documents - Sequential):**
- Processes `plan.rootTasks` sequentially (concurrency=1)
- Per task: emits `task:start` trace event, calls `buildRootPrompt()` with `plan.projectRoot`, invokes `AIService.call()` with `maxTurns: 1`, strips conversational preamble (searches for `'# '` header), writes to `rootTask.outputPath` via `writeFile()`, updates `ProgressReporter` via `onRootDone()`, emits `task:done` trace event
- Emits trace events: `phase:start`/`phase:end` with phase label `'phase-3-root'`

**Finalization:**
- Calls `planTracker.flush()` to ensure serialized write completion
- Retrieves `AIService.getSummary()` aggregating token counts
- Builds `RunSummary` with quality metrics (`inconsistenciesCodeVsDoc`, `inconsistenciesCodeVsCode`, `phantomPaths`, `inconsistencyReport`)
- Calls `reporter.printSummary(summary)`

### executeUpdate Pipeline

Runs only Phase 1 (file analysis) for `filesToAnalyze` array. Does NOT regenerate directory/root docs (caller handles `AGENTS.md` for affected directories).

**Phase 1 (File Analysis - Concurrent):**
- Reads existing `GENERATION-PLAN.md` from `projectRoot/CONFIG_DIR` for project context (non-throwing)
- Spawns N-worker pool processing `filesToAnalyze` with phase label `'update-phase-1-files'`
- Each task: reads source file, calls `buildFilePrompt()` with optional `projectPlan`, invokes `AIService.call()`, computes `contentHash`, writes `.sum`, caches source in `updateSourceCache`
- Pool callback updates `ProgressReporter`, increments `filesProcessed`/`filesFailed`

**Post-Phase 1 (Quality Validation - Non-Throwing):**
- Groups processed files by directory, spawns 10-worker pool with phase label `'update-post-phase-1-quality'`
- Per group: runs `checkCodeVsDoc()` on cached content against freshly written `.sum` (no old-doc comparison), runs `checkCodeVsCode()`, aggregates issues
- Clears `updateSourceCache`, builds `InconsistencyReport`, prints, populates counters

**Finalization:**
- Builds `RunSummary` with quality metrics, calls `reporter.printSummary()`

## Helper Functions

### stripPreamble

```typescript
function stripPreamble(responseText: string): string
```

Removes LLM conversational preamble from AI response text. Detects Pattern 1: content after `\n---\n` separator (checks first 500 chars). Detects Pattern 2: content starting with bold marker `**[A-Z]` (strips preceding text if <300 chars, no `##` headers). Returns original text if no patterns match.

### extractPurpose

```typescript
function extractPurpose(responseText: string): string
```

Extracts single-line purpose statement from AI response. Skips lines matching: empty, markdown headers (`#`), separator (`---`), preamble prefixes (array `PREAMBLE_PREFIXES`: `'now i'`, `'perfect'`, `'based on'`, `'let me'`, `'here is'`, `'i\'ll'`, `'i will'`, `'great'`, `'okay'`, `'sure'`, `'certainly'`, `'alright'`). Strips bold markdown wrapper `**...**`. Truncates to 120 chars with `...` suffix. Returns empty string if no valid line found.

## Quality Validation Strategy

**Code-vs-Doc Detection:**
- Runs twice per file in `executeGenerate`: once against `oldSumCache` (flags stale docs with `' (stale documentation)'` suffix), once against freshly written `.sum` (detects LLM omissions)
- Runs once per file in `executeUpdate`: only against new `.sum` (no old-doc comparison)
- Uses `checkCodeVsDoc()` with source content and `SumFileContent` object

**Code-vs-Code Detection:**
- Scoped to per-directory file groups (avoids global symbol table)
- Aggregates files into array `filesForCodeVsCode: Array<{path, content}>`
- Calls `checkCodeVsCode()` once per group

**Phantom Path Detection:**
- Runs post-Phase 2 after all `AGENTS.md` files written
- Calls `checkPhantomPaths()` per `AGENTS.md` with `agentsMdPath`, `content`, `projectRoot`

**Error Handling:**
- All quality validation wrapped in try/catch printing error to console.error
- Validation failures do NOT abort pipeline (non-throwing)
- Quality metrics included in `RunSummary` even on partial failures

## Trace Event Emission

Emits via `this.tracer?.emit()` when `options.tracer` provided:
- `phase:start`: before each phase with `taskCount`, `concurrency`, `phase` label
- `phase:end`: after each phase with `durationMs`, `tasksCompleted`, `tasksFailed`, `phase` label
- `task:start`: before root document generation with `taskLabel`, `phase`
- `task:done`: after root document generation with `workerId: 0`, `taskIndex`, `taskLabel`, `durationMs`, `success`, optional `error`, `activeTasks: 0`

Worker pool trace events (`worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`) emitted by `runPool()` and `AIService` respectively.

## Progress Reporting Integration

Instantiates `ProgressReporter(fileTaskCount, directoryTaskCount, this.progressLog)` with optional `progressLog` WriteStream from `options.progressLog`. Calls reporter methods:
- `onFileStart(path)`, `onFileDone(path, durationMs, tokensIn, tokensOut, model, cacheReadTokens, cacheCreationTokens)`, `onFileError(path, errorMsg)`
- `onDirectoryStart(path)`, `onDirectoryDone(path, durationMs, tokensIn, tokensOut, model, cacheReadTokens, cacheCreationTokens)`
- `onRootDone(path)`
- `printSummary(summary: RunSummary)`

## Dependencies

Imports: `AIService` from `../ai/index.js`, `AIResponse` from `../ai/types.js`, `ExecutionPlan`/`ExecutionTask`/`formatExecutionPlanAsMarkdown` from `../generation/executor.js`, `writeSumFile`/`readSumFile`/`SumFileContent` from `../generation/writers/sum.js`, `writeAgentsMd` from `../generation/writers/agents-md.js`, `computeContentHashFromString` from `../change-detection/index.js`, `FileChange` from `../change-detection/types.js`, `buildFilePrompt`/`buildDirectoryPrompt`/`buildRootPrompt` from `../generation/prompts/index.js`, `Config` from `../config/schema.js`, `CONFIG_DIR` from `../config/loader.js`, quality module functions from `../quality/index.js`, `Inconsistency` type, `runPool` from `./pool.js`, `PlanTracker` from `./plan-tracker.js`, `ProgressReporter` from `./progress.js`, `ITraceWriter` from `./trace.js`, `FileTaskResult`/`RunSummary`/`CommandRunOptions` from `./types.js`. Node.js builtins: `path`, `readFile`/`writeFile` from `node:fs/promises`.