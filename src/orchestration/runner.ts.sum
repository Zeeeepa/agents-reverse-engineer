---
generated_at: 2026-02-09T21:30:43.072Z
content_hash: b5718adeb12dc90b39e4f47c108aec5e6d3b567e90d393393a20141c48c4a12c
purpose: CommandRunner orchestrates three-phase AI-driven documentation generation via concurrent file analysis, post-order di...
---
**CommandRunner orchestrates three-phase AI-driven documentation generation via concurrent file analysis, post-order directory aggregation, and sequential root document synthesis with quality validation, trace emission, and progress tracking.**

## Exported Class

`CommandRunner` — main orchestration class holding AIService reference and CommandRunOptions for executing generate/update workflows.

### Constructor

```typescript
constructor(aiService: AIService, options: CommandRunOptions)
```

Wires tracer into AIService via `setTracer()` if `options.tracer` provided.

### Primary Methods

`executeGenerate(plan: ExecutionPlan): Promise<RunSummary>` — runs full three-phase pipeline: file analysis (concurrent), directory AGENTS.md (post-order by depth), root documents (sequential). Returns aggregated RunSummary with token counts, inconsistency metrics, duration.

`executeUpdate(filesToAnalyze: FileChange[], projectRoot: string, config: Config): Promise<RunSummary>` — runs Phase 1 only for changed files, skips Phase 2/3. Supports incremental updates via hash-based change detection.

## Three-Phase Execution Pipeline

### Pre-Phase 1: Cache Existing .sum Content

Throttled parallel read (concurrency=20) of existing `.sum` files via `readSumFile()` into `oldSumCache: Map<string, SumFileContent>`. Used for stale documentation detection in quality validation. Emits `phase:start` and `phase:end` trace events with `phase: 'pre-phase-1-cache'`.

### Phase 1: File Analysis (Concurrent)

Maps `plan.fileTasks` to async functions calling:
1. `readFile(task.absolutePath)` for source content
2. `aiService.call()` with `buildFilePrompt()` user/system prompts
3. `computeContentHashFromString()` for SHA-256 hash
4. `stripPreamble()` on response text
5. `extractPurpose()` for one-line metadata
6. `writeSumFile()` with SumFileContent (summary, generatedAt, contentHash)
7. `writeAnnexFile()` if response contains `## Annex References` marker

Caches source content in `sourceContentCache: Map<string, string>` for reuse in quality validation. Executes via `runPool()` with `options.concurrency` workers. Updates `PlanTracker.markDone()` and `ProgressReporter.onFileDone()` per completion. Emits `phase:start`, `phase:end` traces with `phase: 'phase-1-files'`.

### Post-Phase 1: Quality Validation

Groups files by directory via `path.dirname()`, runs throttled parallel checks (concurrency=10):

**Code-vs-doc**: `checkCodeVsDoc()` twice per file — once against `oldSumCache` (stale detection), once against freshly written `.sum` (omission detection). Regex-extracts exports via `/^[ \t]*export\s+(?:default\s+)?(?:function|class|const|let|var|type|interface|enum)\s+(\w+)/gm`, verifies substring presence in summary.

**Code-vs-code**: `checkCodeVsCode()` aggregates exports per directory group into `Map<symbol, string[]>`, detects duplicates.

**Reporting**: Builds InconsistencyReport via `buildInconsistencyReport()`, prints via `formatReportForCli()`, assigns counts to `inconsistenciesCodeVsDoc`/`inconsistenciesCodeVsCode`. Non-throwing — logs errors to stderr on failure. Clears `sourceContentCache` after validation to free memory.

Emits `phase:start`, `phase:end` traces with `phase: 'post-phase-1-quality'`.

### Phase 2: Directory Aggregation (Post-Order by Depth)

Groups `plan.directoryTasks` by `metadata.depth` into `Map<number, ExecutionTask[]>`. Processes depth levels descending (`sort((a,b) => b-a)`) to ensure children precede parents.

Per depth level:
1. Computes `dirConcurrency = Math.min(options.concurrency, dirsAtDepth.length)`
2. Calls `buildDirectoryPrompt()` with knownDirs filter (`Set` from `plan.directoryTasks.map(t => t.path)`)
3. Invokes `aiService.call()` with directory prompt
4. Writes via `writeAgentsMd()` which merges user-authored `AGENTS.local.md` if present
5. Updates `PlanTracker.markDone()` and `ProgressReporter.onDirectoryDone()`

Emits `phase:start`, `phase:end` traces per depth with `phase: 'phase-2-dirs-depth-${depth}'`.

### Post-Phase 2: Phantom Path Validation

Reads each `AGENTS.md` via `readFile()`, calls `checkPhantomPaths()` to extract path-like strings via three regex patterns:
- Markdown links: `/\[(?:[^\]]*)\]\((\.[^)]+)\)/g`
- Backtick paths: `` /`((?:src\/|\.\.?\/)[^`]+\.[a-z]{1,4})`/g ``
- Prose-embedded: `/(?:from|in|by|via|see)\s+`?(src\/[\w\-./]+)`?/gi`

Resolves against `AGENTS.md` directory and project root with `.ts`/`.js` fallback via `existsSync()`. Builds PhantomPathInconsistency report, assigns `phantomPathCount`. Non-throwing — logs errors on failure.

### Phase 3: Root Documents (Sequential)

Iterates `plan.rootTasks` with concurrency=1:
1. Calls `buildRootPrompt()` which injects all `AGENTS.md` via `collectAgentsDocs()`
2. Invokes `aiService.call()` with `maxTurns: 1` (no tool use)
3. Strips conversational preamble via markdown start detection (`indexOf('# ')`)
4. Writes to `rootTask.outputPath` via `writeFile()`
5. Updates `PlanTracker.markDone()` and `ProgressReporter.onRootDone()`

Emits `task:start`, `task:done` (with success/error), `phase:start`, `phase:end` traces with `phase: 'phase-3-root'`. Re-throws errors to maintain existing error handling.

## Progress Tracking Infrastructure

`PlanTracker` — writes `GENERATION-PLAN.md` with checkbox syntax via `formatExecutionPlanAsMarkdown()`, updates via `markDone()`, flushes via promise chain.

`ProgressReporter` — streams human-readable progress to console and `options.progressLog` file via `onFileStart()`, `onFileDone()`, `onFileError()`, `onDirectoryStart()`, `onDirectoryDone()`, `onRootDone()`, `printSummary()`. Calculates ETA via moving average.

Trace emission via `this.tracer?.emit()` for events: `phase:start`, `phase:end`, `task:start`, `task:done`, `worker:start`, `worker:end`. Tracer threaded through `runPool()` options and `aiService.setTracer()`.

## Update Workflow (Incremental)

`executeUpdate()` runs Phase 1 only for `filesToAnalyze: FileChange[]`:
1. Reads existing project plan from `.agents-reverse-engineer/GENERATION-PLAN.md` for context (optional)
2. Passes `existingSum: existingSumContent?.summary` to `buildFilePrompt()` for incremental mode
3. Caches source in `updateSourceCache`, runs quality validation (code-vs-doc new-doc check, code-vs-code)
4. Skips Phase 2/3 — caller (`src/update/orchestrator.ts`) handles `AGENTS.md` regeneration for `affectedDirs`

Returns RunSummary with `filesSkipped: 0` (update mode doesn't skip).

## Helper Functions

`stripPreamble(responseText: string): string` — removes LLM conversational preamble via two patterns:
1. Content after `\n---\n` separator within first 500 chars
2. Content starting with bold purpose `**[A-Z]` if preceding text is <300 chars and lacks `##`

`extractPurpose(responseText: string): string` — scans lines skipping:
- Empty, `#` headers, `---` separators
- Lines starting with `PREAMBLE_PREFIXES` (case-insensitive): `['now i', 'perfect', 'based on', 'let me', 'here is', 'i\'ll', 'i will', 'great', 'okay', 'sure', 'certainly', 'alright']`

Strips bold wrapper `**...**`, truncates to 120 chars with `...` suffix.

## Dependencies

`AIService` — `call()`, `setTracer()`, `addFilesReadToLastEntry()`, `getSummary()` methods.

`ExecutionPlan` — fileTasks, directoryTasks, rootTasks arrays with metadata (depth, absolutePath, path, userPrompt, systemPrompt, outputPath).

`runPool()` — iterator-based concurrency pool from `src/orchestration/pool.ts` with `onResult` callback for progress updates.

`buildFilePrompt()`, `buildDirectoryPrompt()`, `buildRootPrompt()` — prompt construction from `src/generation/prompts/`.

`writeSumFile()`, `readSumFile()`, `writeAnnexFile()` — YAML frontmatter `.sum` file I/O from `src/generation/writers/sum.ts`.

`writeAgentsMd()` — directory doc writer from `src/generation/writers/agents-md.ts`.

`checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`, `buildInconsistencyReport()`, `formatReportForCli()` — quality validators from `src/quality/`.

`computeContentHashFromString()` — SHA-256 hashing from `src/change-detection/`.

`PlanTracker`, `ProgressReporter`, `ITraceWriter` — progress tracking from `src/orchestration/`.

`getVersion()` — package version from `src/version.ts`.

## Trace Events Emitted

All events auto-populated with `seq`, `ts`, `pid`, `elapsedMs` by TraceWriter.

- `phase:start` — taskCount, concurrency, phase label
- `phase:end` — durationMs, tasksCompleted, tasksFailed, phase label
- `task:start` — taskLabel, phase (Phase 3 only)
- `task:done` — workerId, taskIndex, taskLabel, durationMs, success, error?, activeTasks (Phase 3 only)

## RunSummary Schema

```typescript
{
  version: string,
  filesProcessed: number,
  filesFailed: number,
  filesSkipped: number,
  totalCalls: number,
  totalInputTokens: number,
  totalOutputTokens: number,
  totalCacheReadTokens: number,
  totalCacheCreationTokens: number,
  totalDurationMs: number,
  errorCount: number,
  retryCount: number,
  totalFilesRead: number,
  uniqueFilesRead: number,
  inconsistenciesCodeVsDoc: number,
  inconsistenciesCodeVsCode: number,
  phantomPaths?: number,
  inconsistencyReport?: InconsistencyReport
}
```

## Error Handling

Quality validation (code-vs-doc, code-vs-code, phantom-paths) wrapped in try-catch with `console.error()` — failures logged but don't abort pipeline.

Phase 3 re-throws errors after emitting `task:done` with `success: false` to preserve existing error propagation.

Pool failures handled via `onResult` callback checking `result.success` — updates `filesFailed` counter, logs via `reporter.onFileError()`.