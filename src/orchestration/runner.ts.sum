---
generated_at: 2026-02-09T14:26:24.970Z
content_hash: 3563e7fa010503b66352e163a3900c170cdeb3da69245d9b9ba6b3741ced161c
purpose: CommandRunner orchestrates AI-driven three-phase documentation generation via executeGenerate() (full pipeline: file ...
---
**CommandRunner orchestrates AI-driven three-phase documentation generation via executeGenerate() (full pipeline: file analysis → directory aggregation → root synthesis) and executeUpdate() (incremental file re-analysis only), integrating AIService, ExecutionPlan, runPool(), ProgressReporter, PlanTracker, and quality validators into cohesive execution workflows.**

## Exported API

**CommandRunner class**
- `constructor(aiService: AIService, options: CommandRunOptions)` — Initializes runner with AI service and execution config (concurrency, failFast, tracer, progressLog)
- `executeGenerate(plan: ExecutionPlan): Promise<RunSummary>` — Executes full three-phase pipeline for generate command
- `executeUpdate(filesToAnalyze: FileChange[], projectRoot: string, config: Config): Promise<RunSummary>` — Executes Phase 1 only for changed files in update command

## Three-Phase Execution Strategy

**executeGenerate() pipeline:**

**Pre-Phase 1: .sum Content Caching**
- Reads existing `.sum` files via `readSumFile()` for stale documentation detection (throttled concurrency=20)
- Populates `oldSumCache: Map<string, SumFileContent>` for code-vs-doc comparison
- Emits `phase:start/end` trace events with phase label `'pre-phase-1-cache'`

**Phase 1: File Analysis (concurrent pool)**
- Maps `plan.fileTasks` to async functions calling `buildFilePrompt()`, `aiService.call()`, `writeSumFile()`
- Caches `sourceContent` in `sourceContentCache: Map<string, string>` for quality validation
- Computes `contentHash` via `computeContentHashFromString()` from in-memory content (avoids double read)
- Constructs `SumFileContent` with `summary` (stripped preamble via `stripPreamble()`), `metadata.purpose` (via `extractPurpose()`), `generatedAt`, `contentHash`
- Tracks file size via `aiService.addFilesReadToLastEntry()` for telemetry
- Passes tasks to `runPool()` with `phaseLabel: 'phase-1-files'`, `taskLabels: plan.fileTasks.map(t => t.path)`
- Updates `ProgressReporter` via `onFileStart/onFileDone/onFileError` callbacks
- Marks completed tasks in `PlanTracker` via `markDone(path)`
- Emits trace events: `phase:start`, `phase:end` with counts `tasksCompleted`, `tasksFailed`

**Post-Phase 1: Inconsistency Detection (non-throwing)**
- Groups processed files by directory via `path.dirname()` into `dirGroups: Map<string, string[]>`
- Runs directory-scoped checks via throttled pool (concurrency=10):
  - **Stale doc check:** Compares cached `oldSumCache` content against `sourceContent` via `checkCodeVsDoc()`, appends `'(stale documentation)'` to description
  - **Fresh doc check:** Reads newly-written `.sum` files via `readSumFile()`, runs `checkCodeVsDoc()` for omission detection
  - **Duplicate export check:** Aggregates files per directory, runs `checkCodeVsCode()` to detect symbols appearing in multiple files
- Builds `InconsistencyReport` via `buildInconsistencyReport()` if issues found
- Outputs formatted report via `formatReportForCli()`, updates `inconsistenciesCodeVsDoc`, `inconsistenciesCodeVsCode` counters
- Clears `sourceContentCache` to free memory
- Emits trace events: `phase:start/end` with label `'post-phase-1-quality'`

**Phase 2: Directory AGENTS.md (post-order via depth-level batching)**
- Groups `plan.directoryTasks` by `metadata.depth` into `dirsByDepth: Map<number, typeof plan.directoryTasks>`
- Processes depth levels in descending order via `depthLevels.sort((a, b) => b - a)` (deepest first = post-order traversal)
- Per depth level:
  - Sets `dirConcurrency = Math.min(options.concurrency, dirsAtDepth.length)`
  - Maps tasks calling `buildDirectoryPrompt()` (injects child `.sum`, subdirectory `AGENTS.md`, import maps via `knownDirs` filter), `aiService.call()`, `writeAgentsMd()`
  - Passes to `runPool()` with `phaseLabel: 'phase-2-dirs-depth-${depth}'`
  - Updates `ProgressReporter` via `onDirectoryStart/onDirectoryDone`, marks done in `PlanTracker` via `markDone('${path}/AGENTS.md')`
  - Emits `phase:start/end` events per depth level

**Post-Phase 2: Phantom Path Validation (non-throwing)**
- Iterates `plan.directoryTasks`, reads generated `AGENTS.md` files via `readFile(path.join(absolutePath, 'AGENTS.md'))`
- Runs `checkPhantomPaths()` extracting path-like strings via regex, resolving against project root
- Builds `InconsistencyReport` for unresolved references, outputs via `formatReportForCli()`
- Updates `phantomPathCount` counter

**Phase 3: Root Document Synthesis (sequential concurrency=1)**
- Iterates `plan.rootTasks` sequentially, calls `buildRootPrompt()` (injects all `AGENTS.md` via `collectAgentsDocs()`), `aiService.call()` with `maxTurns: 1`
- Strips conversational preamble: finds first markdown header via `content.indexOf('# ')`, removes preceding non-header text
- Writes to `rootTask.outputPath` via `writeFile()`
- Updates `ProgressReporter` via `onRootDone()`, marks done in `PlanTracker`
- Emits `task:start`, `task:done` trace events per root task
- Emits `phase:start/end` with label `'phase-3-root'`

**Summary Construction:**
- Calls `aiService.getSummary()` for aggregated token counts, costs
- Constructs `RunSummary` with `version: getVersion()`, `filesProcessed`, `filesFailed`, `filesSkipped`, token metrics (`totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheCreationTokens`), `totalDurationMs`, `errorCount`, `retryCount`, telemetry fields (`totalFilesRead`, `uniqueFilesRead`), quality metrics (`inconsistenciesCodeVsDoc`, `inconsistenciesCodeVsCode`, `phantomPaths`), `inconsistencyReport`
- Calls `reporter.printSummary(summary)`
- Flushes `PlanTracker` via `await planTracker.flush()`

## Incremental Update Workflow

**executeUpdate() behavior:**
- Runs Phase 1 file analysis only (no directory/root regeneration)
- Reads optional `GENERATION-PLAN.md` from `CONFIG_DIR` for project structure context (falls back to undefined if missing)
- Passes `projectPlan` to `buildFilePrompt()` for bird's-eye context injection
- Caches source content in `updateSourceCache: Map<string, string>`
- Runs post-analysis quality checks identical to `executeGenerate()` Post-Phase 1:
  - Fresh doc check via `checkCodeVsDoc()` (no stale doc check since `oldSumCache` unavailable)
  - Directory-scoped duplicate export check via `checkCodeVsCode()`
- Clears `updateSourceCache` after validation to free memory
- Constructs `RunSummary` with update-specific inconsistency counters (`updateInconsistenciesCodeVsDoc`, `updateInconsistenciesCodeVsCode`)
- Emits trace events with label `'update-phase-1-files'`, `'update-post-phase-1-quality'`

## Text Processing Utilities

**stripPreamble(responseText: string): string**
- Detects LLM conversational preamble via two patterns:
  1. Content after `\n---\n` separator within first 500 chars
  2. Content starting with bold text `**[A-Z]` within first 500 chars (strips preceding text if < 300 chars and no `##` headers)
- Returns cleaned text with preamble removed

**extractPurpose(responseText: string): string**
- Iterates lines, skips markdown headers (`#`), separators (`---`), and preamble prefixes (13 patterns: 'now i', 'perfect', 'based on', 'let me', 'here is', 'i\'ll', 'i will', 'great', 'okay', 'sure', 'certainly', 'alright')
- Strips bold markdown wrapper via `/^\*\*(.+)\*\*$/` regex
- Truncates to 120 chars with `...` ellipsis
- Returns empty string if no valid purpose line found

## Tracer Integration

- Constructor wires `options.tracer` into `aiService.setTracer()` for subprocess/retry event propagation
- Emits `phase:start/end` events at phase boundaries with `phase`, `taskCount`, `concurrency`, `durationMs`, `tasksCompleted`, `tasksFailed` fields
- Emits `task:start` and `task:done` events for Phase 3 root tasks (sequential worker=0) with `taskLabel`, `durationMs`, `success`, `error`, `activeTasks` fields
- Pool-level `task:pickup/done`, `worker:start/end`, `subprocess:spawn/exit` events handled by `runPool()` and `AIService`

## Progress Reporting

- Creates `ProgressReporter` instance with total counts from `plan.fileTasks.length`, `plan.directoryTasks.length`, `options.progressLog`
- Mirrors terminal output to `progressLog` stream (if provided) for real-time monitoring via `tail -f`
- Calls `onFileStart/onFileDone/onFileError` during Phase 1, `onDirectoryStart/onDirectoryDone` during Phase 2, `onRootDone` during Phase 3
- Passes token metrics (`tokensIn`, `tokensOut`, `cacheReadTokens`, `cacheCreationTokens`), `durationMs`, `model` to reporter for ETA calculation and cost tracking
- Calls `printSummary(summary)` after all phases complete

## Plan Tracking

- Initializes `PlanTracker` with `formatExecutionPlanAsMarkdown(plan)` markdown template
- Writes `GENERATION-PLAN.md` with checkbox syntax via `await planTracker.initialize()`
- Marks tasks done via `planTracker.markDone(path)` (file paths, directory `AGENTS.md`, root doc paths)
- Flushes buffered writes via `await planTracker.flush()` before returning summary

## Error Handling

- Quality validation wrapped in try-catch blocks (non-throwing design prevents pipeline breakage)
- Logs errors via `console.error()` with `[quality]` prefix
- Pool execution respects `options.failFast` flag (abort on first failure vs. continue)
- Phase 3 root task failures re-throw after emitting `task:done` trace event with `success: false`
- Incremental update gracefully handles missing `GENERATION-PLAN.md` (proceeds without project structure context)

## Dependencies

**Core Imports:**
- `node:path` — Directory path manipulation, joining, dirname extraction
- `node:fs/promises` — `readFile()`, `writeFile()` for source content, `.sum` files, `AGENTS.md`, root docs
- `../ai/index.js` — `AIService` interface
- `../ai/types.js` — `AIResponse` type
- `../generation/executor.js` — `ExecutionPlan`, `ExecutionTask`, `formatExecutionPlanAsMarkdown()`
- `../generation/writers/sum.js` — `writeSumFile()`, `readSumFile()`, `SumFileContent` type
- `../generation/writers/agents-md.js` — `writeAgentsMd()`
- `../generation/prompts/index.js` — `buildFilePrompt()`, `buildDirectoryPrompt()`, `buildRootPrompt()`
- `../change-detection/index.js` — `computeContentHashFromString()`
- `../change-detection/types.js` — `FileChange` type
- `../config/schema.js` — `Config` type
- `../config/loader.js` — `CONFIG_DIR` constant
- `../quality/index.js` — `checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`, `buildInconsistencyReport()`, `formatReportForCli()`, `Inconsistency` type
- `../version.js` — `getVersion()`
- `./pool.js` — `runPool()` worker pool executor
- `./plan-tracker.js` — `PlanTracker` class
- `./progress.js` — `ProgressReporter` class
- `./trace.js` — `ITraceWriter` interface
- `./types.js` — `FileTaskResult`, `RunSummary`, `CommandRunOptions` types

## Type Constraints

- `FileTaskResult` requires `path`, `success`, `tokensIn`, `tokensOut`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `model` fields
- `RunSummary` aggregates pipeline metrics: file counts, token totals, duration, error/retry counts, telemetry fields, quality issue counts, optional `inconsistencyReport`
- `CommandRunOptions` provides `concurrency`, `failFast`, `debug`, optional `tracer`, optional `progressLog` stream
- `ExecutionTask` contains `path`, `absolutePath`, `userPrompt`, `systemPrompt`, `metadata` (depth for directory tasks), `outputPath` (for root tasks)
- `FileChange` requires `path`, `status` ('added'|'modified'|'deleted'|'renamed')