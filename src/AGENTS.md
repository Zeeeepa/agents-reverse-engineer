<!-- Generated by agents-reverse-engineer v0.8.3 -->

# src

TypeScript source root implementing eight-command CLI (`init`, `discover`, `generate`, `update`, `specify`, `rebuild`, `clean`, `install`/`uninstall`), two-phase AI documentation pipeline (file analysis → directory aggregation), iterator-based concurrency control, multi-backend subprocess orchestration (Claude/Gemini/OpenCode), frontmatter-based change detection, quality validation (code-vs-doc/code-vs-code/phantom-paths), specification synthesis, AI-driven reconstruction, and runtime integration (session hooks, slash commands, permission pre-approval).

## Contents

**[version.ts](./version.ts)** — `getVersion()` resolves `import.meta.url` → `fileURLToPath()` → `dirname()` → `join(__dirname, '..', 'package.json')`, parses JSON via `readFileSync()`, returns `version` field or `'unknown'` fallback on error. Used by CLI `--version` flags and telemetry metadata.

## Subdirectories

**[ai/](./ai/)** — AI service orchestration: subprocess spawning (`claude`/`gemini`/`opencode` CLI tools), exponential backoff retry (rate-limit only, timeouts NOT retried), timeout enforcement (SIGTERM → SIGKILL escalation at +5s), backend auto-detection (PATH scanning with insertion-order priority: Claude > Gemini > OpenCode), telemetry accumulation (`TelemetryEntry[]` → `RunLog` JSON with token/cache/latency/exit code/retry count), NDJSON trace emission (`subprocess:spawn`/`subprocess:exit`/`retry` events), provider abstraction (`AIProvider` interface decoupling transport from business logic). `AIService.call()` wraps provider in `withRetry()` configured with `isRetryable: (err) => err.code === 'RATE_LIMIT'`, records telemetry, emits trace events. `ClaudeBackend` tri-format JSON parser handles CLI ≥2.1.38 arrays, NDJSON, legacy single-object via Zod schema validation. Rate-limit detection: `['rate limit', '429', 'too many requests', 'overloaded'].some(pattern => stderr.toLowerCase().includes(pattern))`. Subprocess SIGKILL via `process.kill(-childPid, 'SIGKILL')` targeting process group. Telemetry cleanup: `cleanupOldLogs(projectRoot, keepRuns)` enforces retention.

**[change-detection/](./change-detection/)** — Git-based file change detection: `isGitRepo()` checks repository status, `getCurrentCommit()` fetches HEAD hash, `getChangedFiles()` detects modifications between `baseCommit` and HEAD via `git diff --name-status -M` with 50% rename threshold, optionally merges uncommitted changes from `git.status()` staged/modified/not_added/deleted arrays. `computeContentHash()` generates SHA-256 hex digest from file content. `computeContentHashFromString()` hashes in-memory strings. `ChangeType = 'added' | 'modified' | 'deleted' | 'renamed'`. Consumed by `src/update/orchestrator.ts` for frontmatter hash comparison triggering incremental regeneration.

**[cli/](./cli/)** — Command-line interface routing: `index.ts` shebang entry point parses commands/flags, maps short flags (`-h`→`help`, `-g`→`global`, `-l`→`local`, `-V`→`version`), triggers interactive installer on zero-argument invocation. Eight command handlers: `init` (creates config.yaml, adds `*.sum` to `.gitignore`, sets VS Code `files.exclude`), `discover` (four-filter chain → `GENERATION-PLAN.md`), `generate` (two-phase pipeline with quality gates), `update` (frontmatter hash comparison → incremental regeneration), `specify` (12-section spec synthesis with 15-minute timeout, opus upgrade), `rebuild` (AI-driven reconstruction from Build Plan phases), `clean` (marker-filtered artifact deletion with `.local.md` restoration), `install`/`uninstall` (runtime integration). Exit codes: 0 (success/no tasks), 1 (partial failure), 2 (total failure/CLI_NOT_FOUND). Default path resolution: `positional[0] || '.'`. Extended timeout: `Math.max(config.ai.timeoutMs, 900_000)` for specify/rebuild.

**[config/](./config/)** — Zod-based configuration: `loadConfig()` reads `.agents-reverse-engineer/config.yaml` via `yaml.parse()` + `ConfigSchema.parse()`, returns defaults on ENOENT, throws `ConfigError` on validation failure. `ConfigSchema` validates `exclude` (patterns/vendorDirs/binaryExtensions), `options` (followSymlinks/maxFileSize), `output.colors`, `generation.compressionRatio` clamped `[0.1, 1.0]`, `ai` (backend enum `['claude','gemini','opencode','auto']`, model, timeoutMs, maxRetries, concurrency clamped `[1, 20]`, telemetry.keepRuns). `getDefaultConcurrency()` computes `min(20, floor(totalMemGB * 0.5 / 0.512), max(2, os.availableParallelism() * 5))`. `writeDefaultConfig()` emits inline-documented YAML template with `yamlScalar()` quoting via `/[*{}\[\]?,:#&!|>'"%@`]/`.

**[core/](./core/)** — Programmatic API surface (`'agents-reverse-engineer/core'` package.json export): aggregates 60+ symbols from ai/, discovery/, generation/, quality/, orchestration/, config/, change-detection/, imports/ subsystems. Exports `AIService`, `discoverFiles()`, `buildFilePrompt()`, `buildDirectoryPrompt()`, `writeSumFile()`, `readSumFile()`, `writeAgentsMd()`, `writeClaudeMdPointer()`, `DocumentationOrchestrator` (aliased `GenerationOrchestrator`, `UpdateOrchestrator`), `runPool()`, `extractExports()`, `checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`, `buildInconsistencyReport()`, `formatReportForCli()`, `computeContentHash()`, `getChangedFiles()`, `loadConfig()`, `findProjectRoot()`, `extractImports()`, `nullLogger`, `consoleLogger`. `@beta` stability. Excludes CLI dependencies (ora, picocolors, process.exit()).

**[discovery/](./discovery/)** — File discovery pipeline: `walkDirectory()` wraps `fast-glob@3.3.3` with `absolute: true`, `onlyFiles: true`, `dot: true`, `followSymbolicLinks: false`, `ignore: ['**/.git/**']`. `applyFilters()` runs four-filter chain via concurrency-30 worker pool with short-circuit evaluation: gitignore (pattern matching via `ignore` library, absolute→relative conversion), vendor (partitioned Set lookup + substring match for 10+ vendor dirs), binary (extension Set fast path → `isbinaryfile()` content analysis for unknowns with 1MB size cap), custom (user patterns from config). Returns `FilterResult` with `included`/`excluded` arrays. `discoverFiles()` orchestrates pipeline, emits `discovery:start`/`discovery:end` trace events. Iterator-based pool prevents file descriptor exhaustion.

**[generation/](./generation/)** — Two-phase orchestration: phase-1 file analysis (source → `.sum` via `buildFilePrompt()` with import maps, compression directives, existing summary preservation), phase-2 directory aggregation (parallel `.sum` reads → `AGENTS.md` via `buildDirectoryPrompt()` post-order). `collectAgentsDocs()` recursively walks tree collecting `AGENTS.md` files sorted by `localeCompare()`, skips `SKIP_DIRS` (node_modules, .git, dist, build). `buildExecutionPlan()` creates dependency graph: `fileTasks` with empty `dependencies[]` (full parallelization), `directoryTasks` sorted by `getDirectoryDepth(dirB) - getDirectoryDepth(dirA)` descending with `dependencies: files.map(f => "file:${f}")` (post-order constraint). `buildFilePrompt()` injects compression directives when `compressionRatio < 0.5`: `TARGET LENGTH: ~${targetSize} chars, MAX: ${maxSize}`. `writeSumFile()` formats YAML frontmatter (`generated_at`, `content_hash`, `purpose`) + markdown. `writeAgentsMd()` preserves user content via rename → `AGENTS.local.md` + `@AGENTS.local.md` import when `GENERATED_MARKER` missing. Language detection: `langMap[extname(filePath)] ?? 'text'`. Manifest detection: `['package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml', 'pom.xml', 'build.gradle', 'Gemfile', 'composer.json', 'CMakeLists.txt', 'Makefile']`.

**[imports/](./imports/)** — Import extraction: `extractImports()` applies regex `/^[ \t]*import\s+(type\s+)?(?:\{([^}]*)\}|(\*\s+as\s+\w+)|(\w+))\s+from\s+['"]([^'"]+)['"]/gm` capturing type keyword (group 1), named symbols (group 2), namespace import (group 3), default import (group 4), module specifier (group 5). `extractDirectoryImports()` reads first 100 lines per file (optimization: imports at top), classifies relative imports as internal (`./`) or external (`../`), excludes `node:` builtins and bare specifiers. `formatImportMap()` serializes to `fileName:\n  specifier → symbol1, symbol2 (type)\n\n` format with `(type)` suffix for type-only imports. Consumed by `src/generation/prompts/builder.ts` for cross-module dependency context injection.

**[installer/](./installer/)** — Interactive installer orchestrating command template/session hook deployment to AI runtime config directories (`.claude/`, `.gemini/`, `.config/opencode/`) with TTY-aware prompts, settings.json hook registration via jsonc-parser, permission injection for Claude, version tracking, and symmetric uninstall operations. `runInstaller()` routes install/uninstall via `selectRuntime()` (Claude/OpenCode/Gemini/all) and `selectLocation()` (global `~/.claude` or local `./.claude`) TTY prompts with arrow keys via `readline.emitKeypressEvents()` + `setRawMode(true)`, ANSI rendering (`\x1b[${n}A`, `\x1b[2K`), guarantees cleanup via `cleanupRawMode()` in finally block + `process.on('exit'|'SIGINT')`. `installFilesForRuntime()` copies command templates from `getTemplatesForRuntime()` to `resolveInstallPath()`, writes hooks/plugins from `getBundledHookPath('../../hooks/dist/')`, calls `registerHooks()` (Claude: nested hooks array with `node ${runtimeDir}/hooks/${hookDef.filename}`, Gemini: flat schema with name field) and `registerPermissions()` (merges `ARE_PERMISSIONS` into settings.permissions.allow) via jsonc-parser `modify()`/`applyEdits()` preserving comments, writes `ARE-VERSION` file. `uninstallFilesForRuntime()` deletes templates/hooks/plugins, calls `unregisterHooks()`/`unregisterPermissions()` filtering via `getHookPatterns()` (current + legacy `node hooks/` formats), `cleanupAreSkillDirs()`/`cleanupLegacyGeminiFiles()`/`cleanupEmptyDirs()`, `deleteConfigFolder()` removes `.agents-reverse-engineer/` when `location === 'local'`. Hook definitions: all commented (disabled). Env var overrides: `CLAUDE_CONFIG_DIR`, `OPENCODE_CONFIG_DIR`, `XDG_CONFIG_HOME`, `GEMINI_CONFIG_DIR`.

**[integration/](./integration/)** — Environment detection and integration file generation for three AI coding assistants (Claude Code, OpenCode, Gemini CLI) via directory/file presence checks and platform-specific template rendering (markdown frontmatter, TOML). `detectEnvironments(projectRoot)` checks `.claude/` OR `CLAUDE.md` (Claude Code), `.opencode/` (OpenCode), `.aider.conf.yml` OR `.aider/` (Aider) via `existsSync()`. `generateIntegrationFiles()` orchestrates template writing via `getTemplatesForEnvironment()`, creates directories + writes files with skip-if-exists (unless `force=true`), copies session hooks from `hooks/dist/`. Platform configs: Claude (`.claude/skills/are-{command}/SKILL.md` directories with `name:` frontmatter), OpenCode (`.opencode/commands/are-{command}.md` flat files with `agent: build`), Gemini (`.gemini/commands/are-{command}.toml` TOML format). Eight commands: init, discover (interactive category filter with `AskUserQuestion` multiSelect), generate, update, specify, rebuild, clean, help (reference block with NO commentary). All background commands follow 5-step pattern: (1) read `VERSION_FILE_PATH`, display version, (2) delete `.agents-reverse-engineer/progress.log`, (3) `Bash` with `run_in_background: true`, (4) poll `.agents-reverse-engineer/progress.log` every 10-15s via Read with `offset`, check TaskOutput with `block: false`, (5) summarize completion. Category classification regex: 7 categories (test/spec, CI/CD, tool configs, migrations, fixtures/snapshots, type declarations, Docker/infra) with 30+ patterns.

**[orchestration/](./orchestration/)** — Concurrency control and pipeline orchestration: `runPool<T>(tasks, options, onComplete?)` spawns `Math.min(options.concurrency, tasks.length)` workers sharing single `tasks.entries()` iterator, each worker loops `for (const [index, task] of iterator)` pulling next when previous completes, returns sparse `TaskResult<T>[]` indexed by original position, invokes optional `onComplete(result)` callback after each task settles, supports `failFast` (sets shared `aborted` flag). `CommandRunner.run()` executes five-phase pipeline: **pre-phase-1-cache** (reads existing `.sum` into `oldSumCache` via concurrency 20), **phase-1-files** (parallel AI calls, writes `.sum`/`.annex.sum`, caches source in `sourceContentCache`), **post-phase-1-quality** (throttled `checkCodeVsDoc()` against old/new `.sum` + `checkCodeVsCode()` per directory group, concurrency 10), **phase-2-dirs** (depth-grouped post-order aggregation sorted `depthB - depthA`, sequentially by depth, concurrently within depth), **post-phase-2** (`checkPhantomPaths()` markdown link validation). Separate `executeUpdate()` runs phase-1 only. `DocumentationOrchestrator.createPlan()` nullifies `PreparedFile.content` after prompt building to free memory. `preparePlan()` performs frontmatter hash comparison, populates `filesToAnalyze`/`filesToSkip`, calls `cleanupOrphans()`, `getAffectedDirectories()` sorted by depth descending. `PlanTracker` serializes `GENERATION-PLAN.md` writes via `this.writeQueue.then(() => writeFile(...))` promise chain, `markDone()` replaces `- [ ]` with `- [x]`. `ProgressReporter` maintains sliding windows (`windowSize = 10`) for moving-average ETA. `TraceWriter` appends NDJSON to `.agents-reverse-engineer/traces/trace-{ISO8601}.ndjson`, injects base fields (`seq`, `ts`, `pid`, `elapsedMs`), 14 event types. `cleanupOldTraces(projectRoot, keepCount = 500)`.

**[output/](./output/)** — Terminal output abstraction: `Logger` interface (`info`, `file`, `excluded`, `summary`, `warn`, `error`), `createLogger` factory conditionally applies picocolors@8.1.1 via `ColorFunctions` adapter when `options.colors: true`, `createSilentLogger` (no-op for tests). Format templates: `file()` → `"  +" + path` (green), `excluded()` → `"  -" + path + " (reason: filter)"` (dim), `summary()` → `"\nDiscovered N files (M excluded)"` (bold counts), `warn()` → `"Warning: "` (yellow), `error()` → `"Error: "` (red). Used by CLI commands for serialized progress logging during worker pool execution.

**[quality/](./quality/)** — Post-generation validation: `extractExports()` via `/^[ \t]*export\s+(?:default\s+)?(?:function|class|const|let|var|type|interface|enum)\s+(\w+)/gm`, `checkCodeVsDoc()` compares extracted symbols against `.sum` summary text via case-sensitive `includes()`, `checkCodeVsCode()` flags duplicates when `exportMap.get(symbolName).length >= 2`, `checkPhantomPaths()` extracts paths via three regex patterns (markdown links `/\[(?:[^\]]*)\]\((\.[^)]+)\)/g`, backtick-quoted `/`((?:src\/|\.\.?\/)[^`]+\.[a-z]{1,4})`/g`, prose `/(?:from|in|by|via|see)\s+`?(src\/[\w\-./]+)`?/gi`), applies six exclusion patterns (`/node_modules/`, `/\.git\//`, `/^https?:/`, `/\{\{/`, `/\$\{/`, `/\*/`, `/\{[^}]*,[^}]*\}/`), resolves via dual strategy (relative to AGENTS.md directory + project root), handles `.js`→`.ts` substitution. `buildInconsistencyReport()` aggregates findings, `formatReportForCli()` emits `[ERROR]`/`[WARN]`/`[INFO]` tagged output. Severity levels: error (blocking, unused), warning (drift/duplicates/broken paths), info (advisory, unused). Invoked by `CommandRunner.run()` in post-phase-1-quality (throttled directory group checks, concurrency 10) and post-phase-2 (phantom path validation). Non-throwing: errors logged but do not abort pipeline. `validateFindability()` stub (disabled).

**[rebuild/](./rebuild/)** — AI-driven reconstruction: `readSpecFiles()` loads `specs/*.md` sorted alphabetically, `partitionSpec()` extracts Build Plan phases via `/^### Phase (\d+):\s*(.+)$/gm`, injects Architecture section + targeted Public API Surface/Data Structures/Behavioral Contracts subsections when `hasDefinesConsumes` detects `/^\*\*Defines:\*\*|^Defines:/m`, else injects full Public API Surface. `CheckpointManager.load()` validates `.rebuild-checkpoint` JSON (RebuildCheckpointSchema) with spec drift detection (SHA-256 hash comparison), returns `{manager, isResume}` + filters pending units. `executeRebuild()` groups `RebuildUnit[]` by `order` field, processes groups sequentially with concurrent `runPool()` per group, calls `buildRebuildPrompt(unit, fullSpec, builtContext)` injecting context → `AIService.call()` → `parseModuleOutput()` → writes files → `checkpoint.markDone()`. Accumulates `builtContext` from written source files (skips `.md`/`.json`/`.yml`), truncates at `BUILT_CONTEXT_LIMIT` (100,000 chars) preserving recent sections full + older sections as 20-line headers. `parseModuleOutput()` uses delimiter parser (`===FILE: path===` / `===END_FILE===` state machine requiring column-0 delimiters), fallback to fenced block extractor (`/```\w*:([^\n]+)\n([\s\S]*?)```/g`). `REBUILD_SYSTEM_PROMPT` mandates delimiter format, exact identifier matching, production-ready code, imports from "Already Built" context, prohibits column-0 delimiter text in generated code. Module status enum: `'pending' | 'done' | 'failed'`. Spec drift triggers checkpoint discard. Promise-chain serialization via `checkpoint.writeQueue.then(() => writeFile())`.

**[specify/](./specify/)** — Specification synthesis: `buildSpecPrompt(docs, annexFiles?)` injects `AgentsDocs` arrays into `SPEC_SYSTEM_PROMPT` enforcing 12-section format (Project Overview → Build Plan → Prompt Templates → File Manifest) with mandatory verbatim reproduction of regex patterns, format strings, magic constants, prompt templates, installer configs from annex files. `writeSpec(content, options)` single-file mode writes direct to `outputPath`, multi-file mode splits on `# ` headings via `/^(?=# )/m` + slugified filenames in `outputPath` directory, throws `SpecExistsError` listing conflicting `paths[]` when files exist and `force=false`, pre-validates all targets atomically before writing. Preamble → `00-preamble.md`. Build Plan validation rules: every API Surface export MUST appear in exactly one phase's "Defines:" list, every File Manifest entry MUST be referenced in a phase, each phase MUST include "Defines:" and "Consumes:" lists cross-referencing section 3. Prohibited patterns: folder-mirroring structure, directory names as headings, omitting version numbers from Dependencies, missing type signatures in API Surface, phases without Defines/Consumes lists. Verbatim reproduction mandate: regex/format/template/constant/environment variable/sentinel values in fenced blocks, NO summarization/paraphrasing/abbreviation/prose substitution. Consumed by `src/cli/specify.ts` calling `collectAgentsDocs()` → `buildSpecPrompt()` → `AIService.call()` (15-minute timeout, opus upgrade) → `writeSpec()`. Output consumed by `src/rebuild/spec-reader.ts` for reconstruction.

**[types/](./types/)** — Shared discovery types: `ExcludedFile` (`{path, reason}`), `DiscoveryResult` (`{files, excluded}`), `DiscoveryStats` (`{totalFiles, includedFiles, excludedFiles, exclusionReasons: Record<string, number>}`). Consumed by `src/discovery/walker.ts` (four-filter chain output), `src/cli/discover.ts` (CLI reporting). Aggregated metrics with exclusion reason bucketing for terminal output.

**[update/](./update/)** — Incremental update: `UpdateOrchestrator.preparePlan()` reads existing `.sum` frontmatter via `readSumFile()`, compares `content_hash` against `computeContentHash()`, populates `filesToAnalyze` on mismatch (status `'added'` if no .sum, `'modified'` if hash differs), populates `filesToSkip` on match. `cleanupOrphans()` deletes `.sum`/`.annex.sum` for deleted/renamed files via `deleteIfExists()`, invokes `cleanupEmptyDirectoryDocs()` on affected parent directories (checks `hasSourceFiles` excluding `GENERATED_FILES`, dotfiles, `.sum` suffixes, deletes `AGENTS.md` when empty), returns `CleanupResult`. `getAffectedDirectories()` collects parent directories from non-deleted `FileChange[]` via `path.dirname()` walk, sorted by depth descending. Dry-run support via boolean flag (simulates deletion without `unlink()`). `UpdateOptions` (`includeUncommitted?`, `dryRun?`), `UpdateResult` (`analyzedFiles`, `skippedFiles`, `cleanup`, `regeneratedDirs`, `baseCommit`, `currentCommit`, `dryRun`). Consumes `FileChange` type from change-detection/ containing `path`, `status`, optional `oldPath` for renames.

## Architecture

### Two-Phase Pipeline

**Phase 1 (File Analysis)**: `src/generation/orchestrator.ts` `createFileTasks()` builds `GenerationTask[]` with `buildFilePrompt()` (injects import maps, project structure, compression directives), executes via `src/orchestration/runner.ts` `runPool()` with user-configured concurrency (default: `os.availableParallelism() * 5` clamped to memory cap `min(20, floor(totalMemGB * 0.5 / 0.512), max(2, cpus * 5))`), spawns LLM subprocesses via `src/ai/subprocess.ts` `runSubprocess()` (SIGTERM at timeout, SIGKILL at timeout+5s), writes `.sum` files via `src/generation/writers/sum.ts` `writeSumFile()` with YAML frontmatter (`file_type`, `generated_at`, `content_hash`). Nullifies task content after prompt building to free memory.

**Phase 2 (Directory Aggregation)**: `createDirectoryTasks()` constructs dependency graph (child file task IDs), sorts by `getDirectoryDepth(dirB) - getDirectoryDepth(dirA)` (descending), groups by depth, executes depth-grouped sequential batches with parallel concurrency per group, `buildDirectoryPrompt()` reads child `.sum` via parallel `readSumFile()`, `src/generation/writers/agents-md.ts` `writeAgentsMd()` renames user `AGENTS.md` → `AGENTS.local.md` + injects `@AGENTS.local.md` directive, root `src/generation/writers/claude-md.ts` `writeClaudeMdPointer()` generates deterministic `CLAUDE.md` import.

### Concurrency Control

`src/orchestration/pool.ts` `runPool<T>()` spawns `Math.min(options.concurrency, tasks.length)` workers sharing single `tasks.entries()` iterator. Each worker pulls `[index, task]` pairs until exhausted or `aborted` flag set. Maintains full utilization during variable-duration tasks. Optional `onComplete?: (result) => void` callback enables serialized `src/orchestration/plan-tracker.ts` `PlanTracker.markDone()` updates to `GENERATION-PLAN.md` checkboxes via promise-chain pattern. Calculation: `concurrency = min(20, floor(totalMemGB * 0.5 / 0.512), max(2, os.availableParallelism() * 5))`.

### Update Strategy

`src/update/orchestrator.ts` `UpdateOrchestrator.preparePlan()` reads existing `.sum` YAML frontmatter via `src/generation/writers/sum.ts` `readSumFile()`, compares stored `content_hash` against `src/change-detection/detector.ts` `computeContentHash()` (SHA-256 hex digest), populates `filesToAnalyze` on mismatch, executes phase-1-files pipeline for changed files, invokes `getAffectedDirectories()` collecting parent directories sorted by depth descending, sequentially regenerates `AGENTS.md` consuming updated child `.sum`. `cleanupOrphans()` deletes `.sum`/`.annex.sum` for git-deleted files, removes AGENTS.md when no source files remain.

### Telemetry Pipeline

`src/ai/service.ts` `AIService` wraps `runSubprocess()` in `src/ai/retry.ts` `withRetry()` (exponential backoff: `min(1000 * 2^attempt, 8000) + random(500)` for RATE_LIMIT errors only, timeouts NOT retried), records `src/ai/telemetry/run-log.ts` `TelemetryEntry` (prompt/response/tokens/cache/latency/exitCode/retryCount/thinking/filesRead), optional `src/orchestration/trace.ts` `TraceWriter` emits NDJSON events (`subprocess:spawn`, `subprocess:exit`, `retry`, `worker:start`, `task:done`, `phase:start`) to `.agents-reverse-engineer/traces/trace-{ISO8601}.ndjson` when `--trace` flag set. `aiService.finalize(projectRoot)` writes `RunLog` to `.agents-reverse-engineer/logs/run-{timestamp}.json`, calls `src/ai/telemetry/cleanup.ts` `cleanupOldLogs()` enforcing `config.ai.telemetry.keepRuns` retention.

### Quality Gates

`src/orchestration/runner.ts` `CommandRunner.run()` executes five phases: **pre-phase-1-cache** (reads existing `.sum` for baseline via `runPool()` concurrency 20), **phase-1-files** (parallel AI calls), **post-phase-1-quality** (throttled directory group checks: `src/quality/inconsistency/code-vs-doc.ts` `checkCodeVsDoc()` detects undocumented exports via `/^[ \t]*export\s+(?:default\s+)?(?:function|class|const|let|var|type|interface|enum)\s+(\w+)/gm`, `src/quality/inconsistency/code-vs-code.ts` `checkCodeVsCode()` finds duplicate symbols, concurrency 10 per group), **phase-2-dirs** (post-order aggregation), **post-phase-2** (`src/quality/phantom-paths/validator.ts` `checkPhantomPaths()` validates markdown links via `/\[(?:[^\]]*)\]\((\.[^)]+)\)/g` + backtick paths + prose references with dual-resolution strategy + `.js`→`.ts` substitution). Aggregates findings via `src/quality/inconsistency/reporter.ts` `buildInconsistencyReport()`, emits severity-tagged CLI output via `formatReportForCli()`.

### Rebuild Workflow

`src/rebuild/spec-reader.ts` `readSpecFiles()` discovers `specs/*.md` → `partitionSpec()` extracts Build Plan phases via `/^### Phase (\d+):\s*(.+)$/gm` → `src/rebuild/checkpoint.ts` `CheckpointManager.load()` validates `.rebuild-checkpoint` JSON with spec drift detection (SHA-256 hash comparison) → `src/rebuild/orchestrator.ts` `executeRebuild()` groups `RebuildUnit[]` by `order` → sequential groups with concurrent `runPool()` per group → `src/rebuild/prompts.ts` `buildRebuildPrompt()` (injects Architecture + targeted subsections, accumulates `builtContext` truncated at 100KB) → `AIService.call()` → `src/rebuild/output-parser.ts` `parseModuleOutput()` (delimiter format: `===FILE: path===` / `===END_FILE===` with column-0 requirement, fallback to fenced-block parser) → writes files → `CheckpointManager.markDone()` serialized updates.

## Behavioral Contracts

### Exit Codes
- **0**: All tasks succeeded or no tasks to process
- **1**: Partial failure (some tasks failed but some succeeded)
- **2**: Total failure (all tasks failed or CLI not found)

### Concurrency Calculation
```javascript
concurrency = min(20, floor(totalMemGB * 0.5 / 0.512), max(2, os.availableParallelism() * 5))
// Constants: SUBPROCESS_HEAP_GB=0.512, MEMORY_FRACTION=0.5, MULTIPLIER=5, MIN=2, MAX=20
```

### Exponential Backoff
```javascript
delay = min(1000 * 2^attempt, 8000) + Math.random() * 500
// Defaults: baseDelayMs=1000, multiplier=2, maxDelayMs=8000, jitter=[0,500ms]
```

### Retry Policy
```javascript
isRetryable: err => err.code === 'RATE_LIMIT'
// Timeouts NOT retried (subprocess overhead on struggling systems)
```

### Rate Limit Detection
```javascript
['rate limit', '429', 'too many requests', 'overloaded'].some(pattern => stderr.toLowerCase().includes(pattern))
```

### Timeout Escalation
- SIGTERM at `options.timeoutMs` via `execFile()` timeout option
- SIGKILL at `options.timeoutMs + 5000ms` via `setTimeout(() => process.kill(-childPid, 'SIGKILL'), ...)` (process group)

### Post-Order Sort
```javascript
getDirectoryDepth(dirB) - getDirectoryDepth(dirA)  // Descending depth
// getDirectoryDepth(dir) = dir === '.' ? 0 : dir.split(path.sep).length
```

### Import Extraction
```regex
/^[ \t]*import\s+(type\s+)?(?:\{([^}]*)\}|(\*\s+as\s+\w+)|(\w+))\s+from\s+['"]([^'"]+)['"]/gm
```
Captures: group 1 (type keyword), group 2 (named symbols), group 3 (namespace import), group 4 (default import), group 5 (module specifier).

### Export Extraction
```regex
/^[ \t]*export\s+(?:default\s+)?(?:function|class|const|let|var|type|interface|enum)\s+(\w+)/gm
```
Captures identifier in group 1 after export keyword and declaration type.

### Hook Disable Mechanisms
```javascript
process.env.ARE_DISABLE_HOOK === '1'
// OR
readFileSync('.agents-reverse-engineer.yaml').includes('hook_enabled: false')
```

### Version Resolution Priority
1. Project-local: `.claude/ARE-VERSION` or `.opencode/ARE-VERSION`
2. Global: `~/.claude/ARE-VERSION` or `~/.config/opencode/ARE-VERSION`
3. Fallback: `'0.0.0'` (discovery), `'unknown'` (version.ts)

### Update Check Cache Schema
```json
{
  "update_available": false,
  "installed": "0.8.0",
  "latest": "0.8.0",
  "checked": 1738416000
}
```

### Git Change Detection
```javascript
execSync('git status --porcelain', { encoding: 'utf-8' })
// Exit if status.trim() === '' (no changes) or command throws (not a git repo)
```

### Generated File Marker
```javascript
GENERATED_MARKER = '<!-- Generated by agents-reverse-engineer -->'
```

### Compression Injection
```javascript
// Condition: compressionRatio < 0.5 && sourceFileSize > 0
targetSize = Math.round(sourceFileSize * compressionRatio)
maxSize = Math.round(targetSize * 1.2)
compressionPercentage = Math.round(compressionRatio * 100)
```