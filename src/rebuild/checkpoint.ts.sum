---
generated_at: 2026-02-09T21:30:19.573Z
content_hash: a8b023cfcf9586bee16021be8100527a1ca1fd4140c730d72a423d4436507ef7
purpose: CheckpointManager provides session continuity for rebuild operations via serialized writes of per-module completion s...
---
**CheckpointManager provides session continuity for rebuild operations via serialized writes of per-module completion status and spec file hash-based drift detection.**

## Exported Symbols

**CheckpointManager** — Main class managing rebuild checkpoint persistence with promise-chain write serialization to prevent corruption from concurrent worker updates.

### Static Factory Methods

- `static async load(outputDir: string, specFiles: Array<{ relativePath: string; content: string }>, unitNames: string[]): Promise<{ manager: CheckpointManager; isResume: boolean }>` — Loads existing checkpoint from `<outputDir>/.rebuild-checkpoint`, validates schema via `RebuildCheckpointSchema.safeParse()`, compares stored spec hashes against current hashes via `computeContentHashFromString()`, returns `isResume: true` only if checkpoint exists and no spec drift detected, otherwise creates fresh checkpoint.

- `static createFresh(outputDir: string, specFiles: Array<{ relativePath: string; content: string }>, unitNames: string[]): CheckpointManager` — Constructs new checkpoint with all modules set to `status: 'pending'`, computes spec content hashes via `computeContentHashFromString()`, initializes `RebuildCheckpoint.modules` record from `unitNames[]`, sets `createdAt`/`updatedAt` to current ISO timestamp.

### Instance Methods

- `markDone(unitName: string, filesWritten: string[]): void` — Updates `modules[unitName]` to `{ status: 'done', completedAt: ISO timestamp, filesWritten }`, updates `data.updatedAt`, queues serialized write via `queueWrite()`.

- `markFailed(unitName: string, error: string): void` — Updates `modules[unitName]` to `{ status: 'failed', error }`, updates `data.updatedAt`, queues serialized write via `queueWrite()`.

- `getPendingUnits(): string[]` — Returns array of module names with `status: 'pending'` or `'failed'` (eligible for execution).

- `isDone(unitName: string): boolean` — Returns true if `modules[unitName].status === 'done'`.

- `async flush(): Promise<void>` — Waits for `writeQueue` promise chain to complete, ensuring all pending writes finish before returning.

- `async initialize(): Promise<void>` — Creates output directory via `mkdir()` with `recursive: true`, writes initial checkpoint JSON to `<outputDir>/.rebuild-checkpoint`, swallows errors (non-critical failure).

- `getData(): RebuildCheckpoint` — Returns current checkpoint data for inspection or dry-run display.

### Private Implementation

- `private writeQueue: Promise<void>` — Promise chain for serializing concurrent writes from pool workers (same pattern as `PlanTracker` and `TraceWriter`).

- `private queueWrite(): void` — Appends serialized write to `writeQueue` via `.then()` chain, writes `JSON.stringify(this.data, null, 2)` to `checkpointPath`, swallows errors with empty catch block (non-critical).

## Data Structure

**RebuildCheckpoint** (from `./types.js`) — Validated via `RebuildCheckpointSchema` Zod schema, contains:
- `version: string` — ARE version via `getVersion()`
- `createdAt: string` / `updatedAt: string` — ISO 8601 timestamps
- `outputDir: string` — Absolute path to rebuild output directory
- `specHashes: Record<string, string>` — Map of spec file relative paths to SHA-256 content hashes (drift detection)
- `modules: Record<string, ModuleStatus>` — Per-unit completion tracking

**ModuleStatus** discriminated union:
- `{ status: 'pending' }` — Not yet processed
- `{ status: 'done', completedAt: string, filesWritten: string[] }` — Successfully completed with output file list
- `{ status: 'failed', error: string }` — Failed with error message

## Drift Detection Algorithm

1. `load()` reads checkpoint JSON from `.rebuild-checkpoint`
2. Parses and validates via `RebuildCheckpointSchema.safeParse()`, returns fresh checkpoint on failure
3. Computes `currentHashes` map via `computeContentHashFromString()` for each spec file
4. Compares hash count: if `Object.keys(checkpoint.specHashes).length !== Object.keys(currentHashes).length`, returns fresh checkpoint
5. Compares individual hashes: if any `checkpoint.specHashes[path] !== currentHashes[path]`, returns fresh checkpoint
6. Returns `isResume: true` only if all checks pass

## Concurrency Safety

Follows promise-chain serialization pattern from `PlanTracker` and `TraceWriter` modules to handle concurrent `markDone()`/`markFailed()` calls from worker pool:
- All writes queued via `this.writeQueue = this.writeQueue.then(...)` pattern
- Each `queueWrite()` appends to chain, ensuring FIFO execution order
- `flush()` awaits `writeQueue` to guarantee completion before process exit
- Non-critical failures swallowed with empty catch blocks (checkpoint corruption does not halt rebuild)

## Dependencies

- `node:fs/promises` — `writeFile()`, `readFile()`, `mkdir()`, `rm()`
- `node:path` — Path joining for `.rebuild-checkpoint` resolution
- `../change-detection/index.js` — `computeContentHashFromString()` for spec drift detection
- `./types.js` — `RebuildCheckpointSchema`, `RebuildCheckpoint` type
- `../version.js` — `getVersion()` for checkpoint version stamping

## Checkpoint File Format

**Location:** `<outputDir>/.rebuild-checkpoint`

**Content:** Pretty-printed JSON (`JSON.stringify(data, null, 2)`) with schema:
```typescript
{
  version: string,           // ARE version
  createdAt: string,        // ISO 8601 timestamp
  updatedAt: string,        // ISO 8601 timestamp
  outputDir: string,        // Absolute path
  specHashes: {             // Drift detection
    "specs/SPEC.md": "a3f5d8e9...",
    "specs/module.md": "7b2c1a4f..."
  },
  modules: {                // Per-unit tracking
    "ModuleName": { status: 'pending' | 'done' | 'failed', ... }
  }
}
```

## Usage Pattern

Constructor is private — clients must use `load()` or `createFresh()` factory methods:

```typescript
const { manager, isResume } = await CheckpointManager.load(outputDir, specFiles, unitNames);
if (!isResume) {
  await manager.initialize();
}

// In worker pool callbacks:
manager.markDone(unitName, filesWritten);
// or
manager.markFailed(unitName, errorMsg);

// Before exit:
await manager.flush();
```