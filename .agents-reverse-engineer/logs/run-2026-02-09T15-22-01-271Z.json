{
  "runId": "2026-02-09T15:22:01.270Z",
  "startTime": "2026-02-09T15:22:01.271Z",
  "endTime": "2026-02-09T15:26:48.563Z",
  "entries": [
    {
      "timestamp": "2026-02-09T15:22:01.272Z",
      "prompt": "Generate a comprehensive project specification from the following documentation.\n\n## AGENTS.md Files (29 directories)\n\n### .github/workflows/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# .github/workflows\n\nGitHub Actions CI/CD workflows automating npm package publication with cryptographic provenance attestation on release events.\n\n## Contents\n\n### [publish.yml](./publish.yml)\nDefines workflow triggering on `release[published]` events or manual `workflow_dispatch`, executing `ubuntu-latest` job with `id-token: write` permission enabling Sigstore-signed provenance via `npm publish --provenance`. Runs `actions/checkout@v4`, `actions/setup-node@v4` with registry-url `https://registry.npmjs.org`, `npm ci`, `npm run build` (invokes `tsc` + `build:hooks` script from package.json `prepublishOnly`), and publishes with `--access public` using `NPM_TOKEN` secret.\n\n## Provenance Mechanism\n\nWorkflow leverages GitHub's OIDC token system (`id-token: write` permission) to generate cryptographic attestation linking published npm artifact to source commit SHA in CI environment. `npm publish --provenance` flag produces Sigstore-signed metadata enabling supply chain verification via `npm audit signatures`, proving package was built from specific repository commit without tampering.\n\n## Integration Points\n\n**Secrets:** Requires `NPM_TOKEN` repository secret containing npm authentication token with publish scope.\n\n**Build Pipeline:** Depends on package.json `prepublishOnly` lifecycle hook executing `npm run build && npm run build:hooks`, which compiles TypeScript (`tsc` emits `src/` → `dist/`) and copies hooks (`scripts/build-hooks.js` copies `hooks/` → `hooks/dist/`).\n\n**Trigger Sources:** Activates via GitHub release creation UI (triggers `release[published]` event) or Actions tab manual dispatch button (`workflow_dispatch` event).\n### AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# agents-reverse-engineer\n\nAI-driven codebase documentation generator executing Recursive Language Model (RLM) algorithm: concurrent per-file `.sum` analysis via subprocess pools, post-order directory `AGENTS.md` aggregation, and platform-specific root synthesis (`CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`) with gitignore-aware discovery, SHA-256 incremental updates, and session lifecycle hooks.\n\n## Contents\n\n### Documentation\n\n**[README.md](./README.md)** — User-facing documentation describing installation methods (`npx agents-reverse-engineer@latest` with `--runtime` and `-g/-l` flags), six-step workflow (`/are-init`, `/are-discover`, `/are-generate`, `/are-update`, `/are-specify`, `/are-clean`), generated artifact formats (`.sum` files with YAML frontmatter, per-directory `AGENTS.md`, platform-specific root documents), configuration schema (`.agents-reverse-engineer/config.yaml` sections for `exclude`, `options`, `output`, `ai` with `concurrency` 1-10, `timeoutMs` 300000ms, `backend` auto-detection), CLI commands (`are install/discover/generate/update/specify/clean`), and positioning narrative solving AI assistant session amnesia through persistent documentation.\n\n**[LANGUAGES-MANIFEST.md](./LANGUAGES-MANIFEST.md)** — Catalogs package manifest file patterns across 25 programming languages with support status flags. Supported languages (9 total): JavaScript/TypeScript (`package.json`), Python (`requirements.txt`, `pyproject.toml`, `setup.py`, `Pipfile`), Ruby (`Gemfile`), Go (`go.mod`), Rust (`Cargo.toml`), Java (`pom.xml`, `build.gradle`), PHP (`composer.json`), C/C++ (`CMakeLists.txt`, `conanfile.txt`, `vcpkg.json`). References `src/generation/prompts/builder.ts` function `buildDirectoryPrompt()` which implements manifest detection during Phase 2 directory aggregation.\n\n**[LICENSE](./LICENSE)** — MIT License granting unrestricted use, modification, distribution, and sublicensing with copyright attribution to GeoloeG-IsT (2026). Software provided \"AS IS\" without warranties. Referenced by `package.json` \"license\" field, included in npm tarball via publish workflow, copied to hooks/dist/ by prepublish hook.\n\n### Configuration\n\n**[package.json](./package.json)** — Defines npm package metadata (`name: \"agents-reverse-engineer\"`, `version: \"0.6.4\"`, `type: \"module\"`), binary entry points (`bin.agents-reverse-engineer` and `bin.are` resolving to `dist/cli/index.js`), build scripts (`build: \"tsc\"`, `build:hooks: \"node scripts/build-hooks.js\"`, `prepublishOnly: \"npm run build && npm run build:hooks\"`, `dev: \"tsx watch src/cli/index.ts\"`), runtime dependencies (`fast-glob`, `ignore`, `isbinaryfile`, `ora`, `picocolors`, `simple-git`, `yaml`, `zod`), development dependencies (`@types/node`, `tsx`, `typescript`), engine requirements (`node: \">=18.0.0\"`), distribution files (`dist`, `hooks/dist`, `README.md`, `LICENSE`), repository metadata (GitHub URLs for issues/homepage).\n\n**[tsconfig.json](./tsconfig.json)** — TypeScript compiler configuration with `target: \"ES2022\"`, `lib: [\"ES2022\"]`, `module: \"NodeNext\"`, `moduleResolution: \"NodeNext\"`, `rootDir: \"src\"`, `outDir: \"dist\"`, `strict: true`, `declaration: true`, `declarationMap: true`, `sourceMap: true`, `esModuleInterop: true`, `resolveJsonModule: true`, `isolatedModules: true`, `skipLibCheck: true`, `forceConsistentCasingInFileNames: true`. Enables Node.js native ESM support with `.js` extension requirements and strict type-checking for compilation from `src/` to `dist/`.\n\n## Subdirectories\n\n**[.github/workflows/](./workflows/)** — CI/CD automation containing `publish.yml` GitHub Actions workflow for npm publish with provenance attestation. Triggers on `v*` tags, runs `npm publish --provenance --access public` with `NPM_TOKEN` secret authentication.\n\n**[docs/](./docs/)** — Contains `INPUT.md` original vision document defining RLM bottom-up recursive execution pattern (leaf-to-root file analysis → directory aggregation → root synthesis), intended integration partners (SpecKit, BMAD, Get Shit Done), session hook requirements, and CLI command surface (`/are-generate`, `/are-update`). Serves as canonical requirements document referenced during feature development.\n\n**[hooks/](./hooks/)** — Session lifecycle hooks for AI IDE integration. Claude Code/Gemini CLI hooks: `are-check-update.js` (SessionStart version check querying `npm view agents-reverse-engineer version`, caching to `~/.claude/cache/are-update-check.json`), `are-session-end.js` (SessionEnd auto-update spawning detached `npx agents-reverse-engineer@latest update --quiet` when `git status --porcelain` detects uncommitted changes). OpenCode plugin hooks: `opencode-are-check-update.js` and `opencode-are-session-end.js` exporting async factories with `event['session.created']` and `event['session.deleted']` handlers. All hooks use detached spawn pattern (`spawn(process.execPath, ['-e', scriptString], {stdio:'ignore', detached:true, windowsHide:true})`) with silent failures (exit code 0) on errors.\n\n**[scripts/](./scripts/)** — Build automation containing `build-hooks.js` prepublish hook script copying `.js` files from `hooks/` to `hooks/dist/` via `copyFileSync()`. Invoked by `prepublishOnly` npm lifecycle script ensuring hooks included in npm tarball. Logs per-file operations, creates `hooks/dist/` via `mkdirSync({recursive:true})` if missing.\n\n**[src/](./src/)** — TypeScript source tree implementing CLI commands (`src/cli/`), AI service orchestration with subprocess resource limits (`src/ai/`), gitignore-aware file discovery (`src/discovery/`), three-phase generation pipeline (`src/generation/`), worker pool with iterator-based concurrency control (`src/orchestration/`), SHA-256 incremental update workflow (`src/update/`), static import analysis (`src/imports/`), NDJSON telemetry logging (`src/ai/telemetry/`), quality validation (`src/quality/`), and platform-specific template generation (`src/integration/`).\n\n## Architecture\n\n### Three-Phase RLM Pipeline\n\n**Phase 1 (Concurrent File Analysis):** `src/generation/orchestrator.ts` reads source content, constructs prompts via `buildFilePrompt()` with import context from `extractDirectoryImports()`, executes tasks through iterator-based worker pool (`src/orchestration/pool.ts` with default concurrency 2 for WSL, 5 elsewhere), writes `.sum` files with YAML frontmatter containing `generated_at`, `content_hash` (SHA-256), `purpose`, optional `critical_todos`/`related_files`.\n\n**Phase 2 (Post-Order Directory Aggregation):** Sorts directories by depth descending via `getDirectoryDepth()`, waits for child `.sum` files via `isDirectoryComplete()` predicate, aggregates child `.sum` content via `readSumFile()`, detects 9 manifest types (package.json, Cargo.toml, go.mod, pyproject.toml, pom.xml, build.gradle, Gemfile, composer.json, CMakeLists.txt/Makefile) in `buildDirectoryPrompt()`, writes `AGENTS.md` preserving user content via `AGENTS.local.md` prepending.\n\n**Phase 3 (Root Document Synthesis):** Sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md` consuming all `AGENTS.md` files via `collectAgentsDocs()`, enforces synthesis-only constraint (no invention/extrapolation, every claim traceable to source documents).\n\n### Subprocess Resource Management\n\n`src/ai/subprocess.ts` mitigates Claude CLI thread exhaustion (GitHub #5771) via environment variables: `NODE_OPTIONS='--max-old-space-size=512'` (512MB heap limit), `UV_THREADPOOL_SIZE='4'` (4-thread libuv pool), `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` (no background tasks), `--disallowedTools Task` (no subagents). Process group killing via `kill(-pid)` terminates subprocess trees. SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period.\n\n### Incremental Update Strategy\n\n`src/update/orchestrator.ts` replaces git-based diffing with SHA-256 content hash comparison: reads `content_hash` from `.sum` YAML frontmatter, computes current hash via `computeContentHash()`, classifies files into `filesToAnalyze` (hash mismatch/missing) or `filesToSkip` (hash match). `cleanupOrphans()` deletes stale `.sum` files, `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` from directories with no remaining source files, `getAffectedDirectories()` walks parent directory tree collecting regeneration candidates.\n\n### Telemetry & Tracing\n\n`src/ai/telemetry/logger.ts` accumulates `TelemetryEntry` instances per subprocess completion, serializes to timestamped JSON (`run-<timestamp>.json`) with token counts, costs, durations, `filesRead[]` metadata, enforces 50-run retention via `cleanupOldLogs()`. `src/orchestration/trace.ts` emits NDJSON events (`phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`) to `trace-<timestamp>.ndjson` with promise-chain serialization, auto-populated fields (`seq`, `ts`, `pid`, `elapsedMs`), 500-trace retention.\n\n## CLI Commands\n\n| Command | Entry Point | Purpose |\n|---------|------------|---------|\n| `are init` | `src/cli/init.ts` | Create `.agents-reverse-engineer/config.yaml` |\n| `are discover` | `src/cli/discover.ts` | Preview generation plan, write `GENERATION-PLAN.md` |\n| `are generate` | `src/cli/generate.ts` | Execute three-phase pipeline |\n| `are update` | `src/cli/update.ts` | Incremental regeneration via hash comparison |\n| `are specify` | `src/cli/specify.ts` | Synthesize `AGENTS.md` corpus into `specs/SPEC.md` |\n| `are clean` | `src/cli/clean.ts` | Remove `.sum`, `AGENTS.md`, `CLAUDE.md` artifacts |\n\nAll commands routed via `src/cli/index.ts` with `parseArgs()` flag extraction, thread `ITraceWriter` for NDJSON emission and `ProgressLog` for streaming `.agents-reverse-engineer/progress.log`.\n\n## IDE Integration\n\n**Installation:** `npx agents-reverse-engineer --runtime <claude|opencode|gemini> -g` installs commands to `~/.claude/skills/`, `~/.config/opencode/commands/`, or `~/.gemini/commands/` with platform-specific templates. Session hooks installed to `~/.claude/hooks/` or `~/.config/opencode/plugins/` via `src/installer/operations.ts` with `registerHooks()` mutating settings.json.\n\n**Uninstallation:** `npx agents-reverse-engineer --runtime <rt> -u` removes command templates, deregisters hooks via `unregisterHooks()` filtering arrays by command pattern match, deletes `.agents-reverse-engineer/` config directory in local mode.\n\n## Quality Validation\n\n`src/quality/inconsistency/code-vs-doc.ts` extracts exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`, verifies presence in `.sum` summaries via substring search. `src/quality/inconsistency/code-vs-code.ts` aggregates exports into `Map<symbol, string[]>` detecting duplicates. `src/quality/phantom-paths/validator.ts` applies three regex patterns (markdown links, backtick-quoted paths, prose-embedded paths), resolves candidates relative to `AGENTS.md` directory with `.js`→`.ts` fallback, reports unresolved references.\n\n## Key Technologies\n\n**Runtime:** Node.js ≥18.0.0 (ES modules), TypeScript 5.7.3 (ES2022 target, NodeNext module resolution, strict mode).\n\n**Core Dependencies:** `fast-glob` (file discovery), `ignore` (gitignore parsing), `isbinaryfile` (binary detection), `simple-git` (change detection), `yaml` (config parsing), `zod` (schema validation), `ora` (spinner UI), `picocolors` (terminal colors).\n\n**AI Backends:** `@anthropic-ai/claude-code` (Claude Code CLI adapter), Gemini CLI (stub implementation), OpenCode CLI (stub implementation).\n### docs/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# docs\n\nContains the original vision document (INPUT.md) defining the Recursive Language Model (RLM) algorithm, brownfield documentation methodology, and core feature requirements that guide agents-reverse-engineer development.\n\n## Contents\n\n**[INPUT.md](./INPUT.md)** — Original project specification defining RLM bottom-up recursive execution pattern (leaf-to-root file analysis → directory aggregation → root synthesis), intended integration partners (SpecKit, BMAD, Get Shit Done), session hook requirements, and CLI command surface (`/are-generate`, `/are-update`).\n\n## Role in Project\n\nINPUT.md serves as the canonical requirements document referenced during feature development and architectural decisions. The RLM algorithm described therein drives the three-phase generation pipeline implemented in `src/generation/orchestrator.ts` and `src/orchestration/runner.ts`. Integration partner analysis (GSD, BMAD methodologies) informed the directory-level documentation patterns (`AGENTS.md`, optional architecture sections) and command execution via Claude Code/OpenCode/Gemini backends defined in `src/ai/backends/`.\n### hooks/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# hooks/\n\nSession lifecycle hooks for AI IDE integration: version checking and auto-update triggers for Claude Code, Gemini CLI, and OpenCode plugin systems.\n\n## Contents\n\n### Claude Code / Gemini CLI Hooks\n\n**[are-check-update.js](./are-check-update.js)** — SessionStart hook spawning detached background process to query `npm view agents-reverse-engineer version`, compare against local/global `ARE-VERSION` files (project `.claude/ARE-VERSION` before global `~/.claude/ARE-VERSION`), and cache results to `~/.claude/cache/are-update-check.json` with schema `{update_available, installed, latest, checked}`. Uses `execSync('npm view...')` with 10s timeout, falls back to `'0.0.0'`/`'unknown'` on errors. Creates cache directory via `mkdirSync({recursive:true})`. Cross-platform via `windowsHide:true` spawn option and `homedir()` resolution.\n\n**[are-session-end.js](./are-session-end.js)** — SessionEnd hook triggering `npx agents-reverse-engineer@latest update --quiet` as detached background process when git working tree has uncommitted changes. Guards via early exit on `ARE_DISABLE_HOOK='1'` environment variable or `.agents-reverse-engineer.yaml` containing substring `'hook_enabled: false'` (no YAML parser). Checks `execSync('git status --porcelain')` for non-empty output, exits silently (code 0) on git errors or clean tree. Spawns via `spawn('npx', ['agents-reverse-engineer@latest', 'update', '--quiet'], {stdio:'ignore', detached:true})` followed by `child.unref()` to allow parent termination without blocking.\n\n### OpenCode Plugin Hooks\n\n**[opencode-are-check-update.js](./opencode-are-check-update.js)** — Exports `AreCheckUpdate()` async factory returning plugin object with `event['session.created']` handler. Mirrors `are-check-update.js` behavior but targets `~/.config/opencode/cache/are-update-check.json` and checks `ARE-VERSION` files in project `.opencode/` before global `~/.config/opencode/`. Uses identical detached spawn pattern with inline script string executing `npm view` query and JSON cache write. Plugin structure conforms to OpenCode lifecycle API expecting async factories returning event handler registrations.\n\n**[opencode-are-session-end.js](./opencode-are-session-end.js)** — Exports `AreSessionEnd()` async factory returning plugin object with `event['session.deleted']` handler. Identical disable checks (`ARE_DISABLE_HOOK`, `.agents-reverse-engineer.yaml` substring search) and git change detection (`execSync('git status --porcelain')`) as `are-session-end.js`. Spawns detached `npx agents-reverse-engineer@latest update --quiet` background process via `spawn()` with `child.unref()` to prevent session close blocking.\n\n## Architecture Patterns\n\n**Detached Process Pattern** — All hooks use `spawn(process.execPath, ['-e', scriptString], {stdio:'ignore', detached:true, windowsHide:true})` followed by `child.unref()` to execute background tasks without blocking IDE lifecycle events. Script strings use synchronous APIs (`fs.readFileSync`, `execSync`) to avoid async coordination in detached subprocess.\n\n**Version Resolution Priority** — Project-local paths checked before global paths:\n- Claude/Gemini: `${cwd}/.claude/ARE-VERSION` → `~/.claude/ARE-VERSION`\n- OpenCode: `${cwd}/.opencode/ARE-VERSION` → `~/.config/opencode/ARE-VERSION`\n\n**Silent Failure Semantics** — All hooks exit with code 0 on errors (non-git repos, network timeouts, missing binaries) to prevent hook failures from blocking session start/end. Version checks default to `'0.0.0'` on missing files, `'unknown'` on network errors.\n\n**Cross-Platform Handling** — `homedir()` resolves `~` on Unix and `%USERPROFILE%` on Windows. `path.join()` handles separators. `windowsHide:true` suppresses console flash on Windows.\n\n## Integration Points\n\nInstalled to IDE-specific directories via `src/installer/operations.ts`:\n- Claude Code: `~/.claude/hooks/`\n- Gemini CLI: `~/.gemini/hooks/`\n- OpenCode: `~/.config/opencode/plugins/`\n\nClaude/Gemini hooks invoked directly as Node.js scripts (`#!/usr/bin/env node` shebang). OpenCode hooks loaded as ES modules exporting async factory functions.\n\n## Disable Mechanisms\n\nTwo disable paths:\n1. **Runtime**: Environment variable `ARE_DISABLE_HOOK='1'`\n2. **Persistent**: Config file `.agents-reverse-engineer.yaml` containing substring `'hook_enabled: false'` (uses `fs.readFileSync()` + `String.includes()`, no YAML parser for performance)\n\nBoth checked via early exit with code 0 to fail silently without blocking session lifecycle.\n\n## Dependencies\n\nNode.js built-ins only:\n- `fs.{existsSync, readFileSync, writeFileSync, mkdirSync}` — version file I/O, cache writes\n- `os.homedir()` — user directory resolution\n- `path.join()` — cross-platform path construction\n- `child_process.{spawn, execSync}` — detached background processes, synchronous git/npm commands\n- `process.{execPath, cwd, exit, env}` — Node.js binary path, working directory, exit control, environment access\n### scripts/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# scripts\n\nBuild automation directory containing prepublish hook distribution script. Executes during `npm run build:hooks` to copy session lifecycle hook files from `hooks/` to `hooks/dist/` for npm tarball inclusion.\n\n## Contents\n\n### Build Scripts\n\n**[build-hooks.js](./build-hooks.js)** — Copies `.js` files from `hooks/` to `hooks/dist/` via `copyFileSync()`, invoked by `prepublishOnly` npm lifecycle script.\n\n## Execution Model\n\nStandalone Node.js script (`#!/usr/bin/env node` shebang) invoked via two mechanisms:\n- **Automatic**: `prepublishOnly` lifecycle hook ensures hooks/dist/ populated before `npm publish` tarball creation\n- **Manual**: `npm run build:hooks` for development verification after hook modifications\n\n## File Discovery Pattern\n\n`readdirSync(hooks/)` + filter predicate `f.endsWith('.js') && f !== 'dist'` selects JavaScript hook files while excluding the dist/ subdirectory itself. Current hook files copied:\n- `are-check-update.js` — Claude/Gemini SessionStart version check\n- `are-session-end.js` — Claude/Gemini SessionEnd auto-update trigger  \n- `opencode-are-check-update.js` — OpenCode plugin version check wrapper\n- `opencode-are-session-end.js` — OpenCode plugin session-end handler\n\n## Output Behavior\n\nLogs per-file copy operations to console with relative path formatting (`\"Copied: <filename> -> hooks/dist/<filename>\"`), concludes with summary (`\"Done. N hook(s) built.\"`). Creates hooks/dist/ via `mkdirSync(recursive: true)` if missing.\n\n## Integration Points\n\nComplements TypeScript compilation (`npm run build` → tsc → dist/`) by handling non-TypeScript assets required for npm package distribution. hooks/dist/ excluded from version control but included in npm tarball via package.json `files` array.\n### src/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src\n\nRoot source directory implementing agents-reverse-engineer CLI: orchestrates three-phase AI-driven documentation pipeline (concurrent `.sum` file analysis, post-order `AGENTS.md` aggregation, platform-specific root synthesis) via worker pools with subprocess resource limits, gitignore-aware discovery, SHA-256 incremental updates, and NDJSON telemetry.\n\n## Contents\n\n**[version.ts](./version.ts)** — `getVersion()` retrieves package version from `package.json` via `import.meta.url` path resolution with `fileURLToPath()`, reads synchronously via `readFileSync()`, parses JSON extracting `version` field, fallback returns `'unknown'` on filesystem/parse errors.\n\n## Subdirectories\n\n**[ai/](./ai/)** — Backend-agnostic AI service layer: `AIService.call()` spawns AI CLI subprocesses (Claude Code, Gemini CLI, OpenCode) via `execFile()` with exponential backoff retry on rate limits, process group killing via `kill(-pid)`, resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`), `BackendRegistry` for auto-detection via `isAvailable()`, `TelemetryLogger.writeRunLog()` serializing token costs to timestamped JSON, `TraceWriter` emitting subprocess lifecycle events (`subprocess:spawn/exit`, `retry`).\n\n**[change-detection/](./change-detection/)** — Git-based change detection: `getChangedFiles()` parses `git diff --name-status -M` with rename detection, merges uncommitted changes via `git.status()` when `includeUncommitted` enabled, `computeContentHash()` generates SHA-256 hex digests, `FileChange` discriminated union with `status: 'added'|'modified'|'deleted'|'renamed'` and conditional `oldPath` for renames.\n\n**[cli/](./cli/)** — Command entry points: `index.ts` routes to `init`/`discover`/`generate`/`update`/`specify`/`clean` via `parseArgs()` flag extraction, `generate.ts` orchestrates three-phase pipeline with `CommandRunner.executeGenerate()`, `update.ts` runs incremental workflow via hash comparison with `preparePlan()`, all commands thread `ITraceWriter` for NDJSON emission and `ProgressLog` for streaming `.agents-reverse-engineer/progress.log`.\n\n**[config/](./config/)** — Zod-validated YAML config: `ConfigSchema` with numeric constraints (concurrency ∈ [1,20], timeoutMs > 0), `loadConfig()` async reader emitting `config:loaded` trace events, `writeDefaultConfig()` generator with inline documentation, `getDefaultConcurrency()` computing worker pool size via CPU cores and memory capacity (`floor(totalMemGB * 0.5 / 0.512)` preventing OOM in WSL).\n\n**[discovery/](./discovery/)** — Gitignore-aware file walker: `walkDirectory()` via `fast-glob('**/*')` with `.git/**` exclusion, `discoverFiles()` composing four-stage filter chain (gitignore, vendor, binary, custom) executing in order with short-circuit rejection, `applyFilters()` using concurrency-bounded pool (30 workers) emitting `filter:applied` trace events, `FilterResult` with `included`/`excluded` arrays.\n\n**[generation/](./generation/)** — Phase orchestration: `GenerationOrchestrator.createFileTasks()` calling `buildFilePrompt()` with import context, `buildExecutionPlan()` sorting directories by depth descending for post-order traversal, `buildDirectoryPrompt()` aggregating child `.sum` files with manifest detection (9 types: package.json, Cargo.toml, go.mod, etc.), `buildRootPrompt()` collecting all `AGENTS.md` via `collectAgentsDocs()`, `writeSumFile()` embedding SHA-256 `content_hash` in YAML frontmatter, `writeAgentsMd()` preserving user content via `AGENTS.local.md` prepending.\n\n**[imports/](./imports/)** — Static import analysis: `extractImports()` applying regex with five capture groups (type keyword, named symbols, namespace imports, default imports, module specifier), `extractDirectoryImports()` reading first 100 lines per file classifying relative imports into `internal` (`./`) and `external` (`../`) arrays, `formatImportMap()` serializing to human-readable text blocks consumed by directory aggregation prompts.\n\n**[installer/](./installer/)** — npx-driven installation: `runInstaller()` parsing flags via `parseInstallerArgs()`, routing to `installFiles()` writing templates from `getTemplatesForRuntime()` to `resolveInstallPath()` with hook registration mutating settings.json via `registerHooks()` (Claude nested format, Gemini flat format, OpenCode plugins), `uninstallFiles()` removing command templates and deregistering via `unregisterHooks()` filtering arrays by command pattern match, `selectRuntime()`/`selectLocation()` providing TTY-aware arrow key selection with `arrowKeySelect()` vs. `numberedSelect()` fallback.\n\n**[integration/](./integration/)** — Platform detection and template generation: `detectEnvironments()` scanning for `.claude/`, `CLAUDE.md`, `.opencode/`, `.aider.conf.yml` markers, `getClaudeTemplates()`/`getOpenCodeTemplates()`/`getGeminiTemplates()` producing command files with frontmatter-wrapped templates (`.claude/skills/*/SKILL.md`, `.opencode/commands/*.md`, `.gemini/commands/*.toml`), `generateIntegrationFiles()` orchestrating write workflow with `ensureDir()` directory creation and `force`/`dryRun` handling.\n\n**[orchestration/](./orchestration/)** — Concurrency control and progress tracking: `runPool()` shared-iterator pattern executing `Array<() => Promise<T>>` task factories through concurrency-limited pool preventing batch-induced idling, `CommandRunner.executeGenerate()` sequencing Phase 1 concurrent file analysis, Phase 2 post-order directory aggregation grouped by depth, Phase 3 sequential root synthesis, `ProgressReporter` computing ETA via moving averages of last 10 durations, `PlanTracker`/`ProgressLog`/`TraceWriter` using promise-chain serialization (`writeQueue = writeQueue.then(...)`) preventing concurrent write corruption.\n\n**[output/](./output/)** — Terminal formatting: `createLogger()` factory using picocolors for ANSI coloring toggled via `LoggerOptions.colors`, `Logger` interface defining six output methods (`info`, `file`, `excluded`, `summary`, `warn`, `error`), `createSilentLogger()` returning no-op stubs for testing.\n\n**[quality/](./quality/)** — Post-generation validation: `checkCodeVsDoc()` extracting exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` verifying presence in `.sum` summaries, `checkCodeVsCode()` aggregating exports into `Map<symbol, string[]>` detecting duplicates, `checkPhantomPaths()` applying three regex patterns (markdown links, backtick-quoted paths, prose-embedded paths) with six SKIP_PATTERNS, resolving candidates relative to AGENTS.md directory with `.js`→`.ts` fallback, `buildInconsistencyReport()` aggregating discriminated union issues with metadata.\n\n**[specify/](./specify/)** — Project specification synthesis: `buildSpecPrompt()` constructing system/user prompt pairs with `SPEC_SYSTEM_PROMPT` enforcing concern-based organization (nine mandatory sections: Project Overview, Architecture, Public API Surface, Data Structures, Configuration, Dependencies, Behavioral Contracts, Test Contracts, Build Plan), `writeSpec()` orchestrating single-file (`specs/SPEC.md`) vs. multi-file (`specs/<slug>.md`) output modes splitting on top-level `# ` headings via `/^(?=# )/m` regex, throwing `SpecExistsError` on overwrite protection failures.\n\n**[types/](./types/)** — Shared discovery result definitions: `ExcludedFile` (path + exclusion reason), `DiscoveryResult` (included files array + excluded file metadata), `DiscoveryStats` (metrics with `totalFiles`, `includedFiles`, `excludedFiles`, `exclusionReasons` histogram).\n\n**[update/](./update/)** — Incremental update system: `UpdateOrchestrator.preparePlan()` reading YAML `content_hash` from `.sum` frontmatter via `readSumFile()`, comparing against `computeContentHash()` SHA-256 output, classifying into `filesToAnalyze[]` (hash mismatch/missing) or `filesToSkip[]` (hash match), `cleanupOrphans()` deleting `.sum` files for deleted/renamed sources, `cleanupEmptyDirectoryDocs()` removing `AGENTS.md` from directories with no remaining source files, `getAffectedDirectories()` walking parent directory tree collecting paths requiring regeneration.\n\n## Architecture\n\n### Three-Phase Pipeline\n\n**Phase 1 (Concurrent File Analysis):** `GenerationOrchestrator.prepareFiles()` reads source content, `createFileTasks()` constructs prompts via `buildFilePrompt()` with import context from `extractDirectoryImports()`, `runPool()` executes file tasks through worker pool (default concurrency: 2 for WSL, 5 elsewhere), `writeSumFile()` persists `.sum` with YAML frontmatter containing `generated_at`, `content_hash` (SHA-256), `purpose`, optional `critical_todos`/`related_files`.\n\n**Phase 2 (Post-Order Directory Aggregation):** `buildExecutionPlan()` sorts directories by `getDirectoryDepth()` descending (deepest first), `isDirectoryComplete()` waits for all child `.sum` files via `sumFileExists()` predicate, `buildDirectoryPrompt()` reads child `.sum` files via `readSumFile()` and detects manifests (package.json, Cargo.toml, go.mod, pyproject.toml, pom.xml, build.gradle, Gemfile, composer.json, CMakeLists.txt/Makefile), `writeAgentsMd()` renames user `AGENTS.md` → `AGENTS.local.md` if non-generated and prepends user content to LLM output.\n\n**Phase 3 (Root Document Synthesis):** `collectAgentsDocs()` recursively aggregates all `AGENTS.md` files, `buildRootPrompt()` reads root `package.json` for project metadata (`name`, `version`, `description`, `packageManager`, `scripts`), sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md` with synthesis-only constraint (no invention/extrapolation, every claim traceable to `AGENTS.md`).\n\n### Iterator-Based Worker Pool\n\n`runPool()` shares single `tasks.entries()` iterator across N workers preventing batch anti-pattern. Workers execute tight loop: pickup task → execute → emit result → pickup next, maintaining full slot utilization. Iterator protocol atomicity ensures each `[index, task]` pair consumed by exactly one worker. Effective concurrency capped at `Math.min(options.concurrency, tasks.length)`.\n\n### Subprocess Resource Management\n\n`runSubprocess()` mitigates Claude CLI thread exhaustion (GitHub #5771: 200 NodeJS instances) via environment variables: `NODE_OPTIONS='--max-old-space-size=512'` limits heap to 512MB per subprocess, `UV_THREADPOOL_SIZE='4'` constrains libuv thread pool to 4 threads, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` prevents background task spawning, `--disallowedTools Task` blocks subagents. Process group killing via `kill(-pid)` terminates subprocess trees. SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period.\n\n### Incremental Update Strategy\n\n`UpdateOrchestrator.preparePlan()` replaces git-based diffing with SHA-256 content hash comparison: reads `content_hash` from `.sum` YAML frontmatter, computes current hash via `computeContentHash()`, classifies files into `filesToAnalyze` (hash mismatch/missing) or `filesToSkip` (hash match). `cleanupOrphans()` deletes stale `.sum` files for deleted/renamed sources, `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` from directories with no remaining source files, `getAffectedDirectories()` walks parent directory tree collecting paths requiring regeneration.\n\n### Telemetry & Tracing\n\n`TelemetryLogger` accumulates `TelemetryEntry` instances with `addEntry()` per subprocess completion, `toRunLog()` assembles complete `RunLog` with shallow-copied entries and `getSummary()` aggregations (total tokens, error counts, unique files), `writeRunLog()` serializes to timestamped JSON (`.agents-reverse-engineer/logs/run-<timestamp>.json`), `cleanupOldLogs()` enforces retention limit (default 50) via lexicographic sort descending. `TraceWriter` emits NDJSON events (`phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`) to `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson` with promise-chain serialization, auto-populated fields (`seq`, `ts`, `pid`, `elapsedMs`), `cleanupOldTraces()` enforcing 500-trace retention.\n### src/ai/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai\n\nAI service orchestration layer providing backend-agnostic subprocess management, exponential backoff retry, telemetry logging, and trace emission for concurrent worker pools executing file analysis, directory aggregation, and root synthesis phases.\n\n## Contents\n\n### Core Orchestration\n\n**[service.ts](./service.ts)** — `AIService` class orchestrates subprocess invocations via `call(options: AICallOptions): Promise<AIResponse>`, wrapping `runSubprocess()` in `withRetry()` exponential backoff with rate limit detection (stderr patterns: \"rate limit\", \"429\", \"too many requests\", \"overloaded\"), parsing responses via `AIBackend.parseResponse()`, accumulating `TelemetryEntry` records through `TelemetryLogger.addEntry()`, emitting subprocess lifecycle trace events (`subprocess:spawn`, `subprocess:exit`, `retry`) to optional `ITraceWriter`, enforcing resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`), and finalizing runs via `finalize()` producing `RunLog` JSON files with `cleanupOldLogs()` retention enforcement.\n\n**[subprocess.ts](./subprocess.ts)** — `runSubprocess(command: string, args: string[], options: SubprocessOptions): Promise<SubprocessResult>` spawns AI CLI via `execFile()` with SIGTERM timeout at `options.timeoutMs`, SIGKILL escalation after `SIGKILL_GRACE_MS` (5000ms) grace period, stdin piping via `.end()` for EOF delivery, process group killing via `kill(-pid)` for subprocess tree termination, unref'd timeout handles preventing event loop blocking, and active subprocess tracking via `activeSubprocesses` Map exposing `getActiveSubprocessCount()` and `getActiveSubprocesses()` concurrency diagnostics.\n\n**[registry.ts](./registry.ts)** — `BackendRegistry` manages insertion-order `AIBackend` instances with `register()`, `get()`, `getAll()` methods, `createBackendRegistry()` factory pre-populates with ClaudeBackend, GeminiBackend, OpenCodeBackend in priority order, `detectBackend()` iterates `getAll()` calling `isAvailable()` returning first available backend or null, `resolveBackend()` handles auto-detection and explicit selection with `AIServiceError('CLI_NOT_FOUND')` thrown when unavailable, `getInstallInstructions()` aggregates `backend.getInstallInstructions()` into newline-separated multi-line string.\n\n**[retry.ts](./retry.ts)** — `withRetry<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T>` executes async function with exponential backoff calculated as `min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter` where jitter is `Math.random() * 500`, invokes `isRetryable(error)` predicate to distinguish transient (rate limit, network timeout) from permanent failures (authentication, invalid input), calls `onRetry?.(attempt, error)` callback before delay, terminates immediately on non-retryable errors or after exhausting `maxRetries`, `DEFAULT_RETRY_OPTIONS` exports baseline configuration (`maxRetries: 3`, `baseDelayMs: 1000`, `maxDelayMs: 8000`, `multiplier: 2`).\n\n**[types.ts](./types.ts)** — Defines `AIBackend` interface requiring `name`, `cliCommand`, `isAvailable()`, `buildArgs()`, `parseResponse()`, `getInstallInstructions()`, `SubprocessResult` capturing `stdout`, `stderr`, `exitCode`, `signal`, `durationMs`, `timedOut`, `childPid`, `AICallOptions` with `prompt`, `systemPrompt?`, `model?`, `timeoutMs?`, `maxTurns?`, `taskLabel?`, `AIResponse` normalizing `text`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `durationMs`, `exitCode`, `raw`, `RetryOptions` with `maxRetries`, `baseDelayMs`, `maxDelayMs`, `multiplier`, `isRetryable`, `onRetry?`, `TelemetryEntry` logging `timestamp`, `prompt`, `systemPrompt?`, `response`, `model`, `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `latencyMs`, `exitCode`, `error?`, `retryCount`, `thinking`, `filesRead`, `RunLog` aggregating `runId`, `startTime`, `endTime`, `entries`, `summary` with token totals, `FileRead` tracking `path`, `sizeBytes`, `AIServiceError` with `AIServiceErrorCode` enum (`'CLI_NOT_FOUND'`, `'TIMEOUT'`, `'PARSE_ERROR'`, `'SUBPROCESS_ERROR'`, `'RATE_LIMIT'`).\n\n**[index.ts](./index.ts)** — Barrel export enforcing encapsulation boundary by re-exporting `AIService`, `BackendRegistry`, `createBackendRegistry()`, `resolveBackend()`, `detectBackend()`, `getInstallInstructions()`, `withRetry()`, `DEFAULT_RETRY_OPTIONS`, `runSubprocess()`, `isCommandOnPath()`, all types from `types.ts`, preventing direct imports from `backends/` or `telemetry/` subdirectories.\n\n## Subdirectories\n\n**[backends/](./backends/)** — ClaudeBackend, GeminiBackend, OpenCodeBackend implementations with `buildArgs()` constructing CLI argument arrays, `parseResponse()` extracting AIResponse from JSON stdout (GeminiBackend and OpenCodeBackend are stubs throwing `SUBPROCESS_ERROR`), `isAvailable()` detecting CLI via PATH scanning, `getInstallInstructions()` returning npm/installation commands, shared `isCommandOnPath()` utility in claude.ts iterating PATH directories with platform-specific PATHEXT handling.\n\n**[telemetry/](./telemetry/)** — `TelemetryLogger` accumulating `TelemetryEntry` instances with `addEntry()` and `setFilesReadOnLastEntry()`, computing aggregate statistics via `getSummary()` (total tokens, error counts, unique files), `writeRunLog()` serializing `RunLog` objects to timestamped JSON files (`.agents-reverse-engineer/logs/run-<timestamp>.json`) with `:` and `.` sanitization to `-`, `cleanupOldLogs()` enforcing retention limits via lexicographic sort descending and `fs.unlink()` deletion.\n\n## Architecture Patterns\n\n### Backend Abstraction\n\n`AIBackend` interface decouples service layer from CLI-specific invocations enabling runtime backend selection via `resolveBackend()`. Registry pattern in `BackendRegistry` supports auto-detection (`backend: 'auto'`) and explicit selection (`backend: 'claude'`). Backends implement argument construction (`buildArgs`), response parsing (`parseResponse`), and availability detection (`isAvailable`) allowing seamless backend swapping without modifying service layer.\n\n### Subprocess Resource Management\n\n`runSubprocess()` mitigates Claude CLI thread exhaustion (GitHub #5771: 200 NodeJS instances) via environment variables limiting heap (`NODE_OPTIONS='--max-old-space-size=512'`), thread pool (`UV_THREADPOOL_SIZE='4'`), and background tasks (`CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`). Process group killing via `kill(-pid)` terminates entire subprocess tree preventing zombie processes. Default concurrency reduced from 5 → 2 for WSL environments. `activeSubprocesses` Map tracks concurrent processes with `getActiveSubprocessCount()` and `getActiveSubprocesses()` diagnostics.\n\n### Retry Strategy\n\n`withRetry()` wrapper applies exponential backoff to transient failures identified by `isRetryable()` predicate. `AIService.call()` configures predicate allowing only `AIServiceError` with `code === 'RATE_LIMIT'` (timeouts NOT retried). Rate limit detection in `isRateLimitStderr()` scans subprocess stderr for `['rate limit', '429', 'too many requests', 'overloaded']` patterns. Jitter (0-500ms) prevents thundering herd on shared backend APIs.\n\n### Telemetry Accumulation\n\n`TelemetryLogger` accumulates per-call metadata in memory during run via `addEntry()` invoked after each subprocess completion. `FileRead` metadata attached via `setFilesReadOnLastEntry()` after file context determination. `toRunLog()` assembles complete `RunLog` with shallow-copied entries and `getSummary()` aggregations (total tokens, error counts, unique files). `writeRunLog()` serializes to timestamped JSON enabling post-run cost analysis. `cleanupOldLogs()` enforces `Config.ai.telemetry.keepRuns` retention limit (default 50) via lexicographic sort descending.\n\n### Trace Emission\n\n`AIService` accepts optional `ITraceWriter` via `setTracer()`, emits `subprocess:spawn` events synchronously after `execFile()` returns child object with `.pid`, emits `subprocess:exit` events after completion with `exitCode`, `signal`, `durationMs`, `timedOut`, emits `retry` events via `withRetry()` `onRetry` callback with `attempt`, `taskLabel`, `errorCode`. Trace writer serializes events through promise chain in `src/orchestration/trace.ts` ensuring NDJSON line order despite concurrent worker emissions.\n\n## Integration Points\n\n**Consumed By:**\n- `src/generation/executor.ts` — Constructs `AIService` instances with config-derived `AIServiceOptions`, invokes `call()` per file/directory/root task in three-phase pipeline\n- `src/cli/generate.ts`, `src/cli/update.ts` — Thread `ITraceWriter` from `CommandRunOptions` to `AICallOptions` for NDJSON trace emission\n- `src/orchestration/runner.ts` — Passes `tracer` through `AIService.call()` chain for subprocess event logging\n\n**Provides To:**\n- Backend adapters in `src/ai/backends/` import `AIBackend`, `AICallOptions`, `AIResponse`, `SubprocessResult` for interface compliance\n- Telemetry modules import `TelemetryEntry`, `RunLog`, `FileRead` for schema definitions\n- Quality validators import `AIServiceError` for error type discrimination\n### src/ai/backends/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai/backends\n\nConcrete AIBackend implementations for Claude Code, Gemini CLI, and OpenCode CLI providing subprocess argument construction, JSON response parsing, PATH availability detection, and installation instructions.\n\n## Contents\n\n### Backend Implementations\n\n**[claude.ts](./claude.ts)** — ClaudeBackend adapter implementing subprocess orchestration for `claude` CLI with `buildArgs()` constructing `['-p', '--output-format', 'json', '--no-session-persistence', '--permission-mode', 'bypassPermissions']` arguments, `parseResponse()` validating JSON via ClaudeResponseSchema (Zod), extracting model names from `modelUsage` object keys, handling non-JSON prefix text via `stdout.indexOf('{')` slicing, and `isCommandOnPath()` detecting CLI availability by iterating `process.env.PATH` directories with platform-specific PATHEXT handling.\n\n**[gemini.ts](./gemini.ts)** — GeminiBackend stub adapter with functional `isAvailable()` delegating to `isCommandOnPath()`, `buildArgs()` returning `['-p', '--output-format', 'json']`, but `parseResponse()` throwing AIServiceError with code 'SUBPROCESS_ERROR' pending Gemini CLI JSON output format stabilization (deferred per RESEARCH.md Open Question 2).\n\n**[opencode.ts](./opencode.ts)** — OpenCodeBackend stub adapter with functional `isAvailable()` via `isCommandOnPath()`, `buildArgs()` returning `['run', '--format', 'json']`, but `parseResponse()` throwing AIServiceError with code 'SUBPROCESS_ERROR' pending JSONL output parsing implementation (deferred per RESEARCH.md Open Question 3).\n\n## AIBackend Interface Contract\n\nAll backend classes implement `AIBackend` from `../types.ts` requiring:\n- `name: string` — Backend identifier ('claude' | 'gemini' | 'opencode')\n- `cliCommand: string` — Executable name for PATH resolution\n- `isAvailable(): Promise<boolean>` — CLI detection via PATH scanning\n- `buildArgs(options: AICallOptions): string[]` — Subprocess argument array construction (prompt sent via stdin)\n- `parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse` — JSON parsing with token/cost extraction\n- `getInstallInstructions(): string` — Formatted installation command string\n\n## Backend Registry Integration\n\nRegistered via `AIBackendRegistry` in `../registry.ts` enabling auto-detection when `config.ai.backend === 'auto'`. Registry calls `isAvailable()` sequentially across backends [ClaudeBackend, GeminiBackend, OpenCodeBackend] returning first available, falling back to ClaudeBackend if none detected.\n\n## PATH Detection Pattern\n\n`isCommandOnPath(command: string)` shared utility in `claude.ts`:\n1. Split `process.env.PATH` by `path.delimiter` (`:` on Unix, `;` on Windows)\n2. Iterate directories with platform-specific extensions (Windows: `process.env.PATHEXT.split(';')`, Unix: `['']`)\n3. Test each `pathDir + command + ext` via `fs.stat()` (not `fs.access()` due to Windows lacking execute permission bits)\n4. Return true if any path exists, false otherwise\n\n## ClaudeBackend Parsing Strategy\n\n`parseResponse()` defensively handles non-JSON CLI output:\n1. Locate first `{` via `stdout.indexOf('{')`\n2. Slice `stdout.substring(jsonStart)` before `JSON.parse()`\n3. Validate against ClaudeResponseSchema containing `type`, `subtype`, `is_error`, `result`, `usage`, `modelUsage`, `total_cost_usd`\n4. Extract model name from `Object.keys(parsed.modelUsage)[0] ?? 'unknown'`\n5. Map to AIResponse with `result: parsed.result`, `usage: { inputTokens, cacheReadTokens, cacheCreationTokens, outputTokens }`, `model: modelName`, `cost: { totalUSD: parsed.total_cost_usd }`\n6. Throw AIServiceError('PARSE_ERROR') on schema validation failure, including first 200 characters of raw output\n\n## Subprocess Orchestration\n\nBackends depend on `runSubprocess()` from `../subprocess.ts` which:\n- Spawns `execFile(cliCommand, args)` child process\n- Injects prompt via `stdin.write()` followed by `stdin.end()`\n- Enforces resource limits: `NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`\n- Implements timeout handling: SIGTERM at `timeoutMs`, SIGKILL after 5s grace period\n- Performs process group killing via `kill(-pid)` to terminate subprocess trees\n- Passes captured `stdout` to backend's `parseResponse()`\n\n## Implementation Status\n\n| Backend | isAvailable | buildArgs | parseResponse | Status |\n|---------|-------------|-----------|---------------|--------|\n| ClaudeBackend | ✓ PATH detection | ✓ Full args | ✓ Schema validation | **Production** |\n| GeminiBackend | ✓ PATH detection | ✓ Basic args | ✗ Throws error | **Stub** (pending JSON stability) |\n| OpenCodeBackend | ✓ PATH detection | ✓ Basic args | ✗ Throws error | **Stub** (pending JSONL parsing) |\n### src/ai/telemetry/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai/telemetry/\n\nAccumulates AI service call metadata in memory, serializes completed runs to timestamped JSON logs in `.agents-reverse-engineer/logs/`, and enforces retention limits via automatic cleanup of stale log files.\n\n## Contents\n\n**[logger.ts](./logger.ts)** — `TelemetryLogger` class accumulates `TelemetryEntry` instances via `addEntry()`, attaches `FileRead` metadata via `setFilesReadOnLastEntry()`, computes aggregate statistics through `getSummary()` (total tokens, error counts, unique files), and assembles complete `RunLog` objects via `toRunLog()` for persistence.\n\n**[run-log.ts](./run-log.ts)** — `writeRunLog()` creates `.agents-reverse-engineer/logs/` directory, sanitizes ISO 8601 timestamps by replacing `:` and `.` with `-`, writes pretty-printed JSON via `JSON.stringify(runLog, null, 2)`, returns absolute path to written file.\n\n**[cleanup.ts](./cleanup.ts)** — `cleanupOldLogs()` lists `run-*.json` files from logs directory, sorts lexicographically descending (newest first via `entries.sort()` + `entries.reverse()`), slices beyond retention limit, deletes via `fs.unlink()`, suppresses ENOENT errors, returns deleted file count.\n\n## Data Flow\n\n1. **Accumulation Phase**: Command runner creates `TelemetryLogger(runId)` with ISO timestamp, threads logger through `AIService` which calls `addEntry()` after each subprocess completion and `setFilesReadOnLastEntry()` after file metadata attachment from command runner.\n\n2. **Aggregation Phase**: `getSummary()` iterates entries array on every call (no caching), accumulates token counters (`inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`), latency totals, error counts, and unique file paths via `Set<string>`.\n\n3. **Persistence Phase**: `toRunLog()` assembles complete `RunLog` object with shallow-copied entries and summary, `writeRunLog()` serializes to timestamped JSON file (e.g., `run-2026-02-07T12-00-00-000Z.json`), `cleanupOldLogs()` enforces retention limit from `Config.ai.telemetry.keepRuns` (default 50).\n\n## Integration Points\n\n- **Callers**: Command runners (`src/cli/generate.ts`, `src/cli/update.ts`) create `TelemetryLogger` instances, finalize via `toRunLog()` + `writeRunLog()` + `cleanupOldLogs()` sequence after run completion.\n- **AI Service**: `src/ai/service.ts` calls `addEntry()` after subprocess execution, `setFilesReadOnLastEntry()` after file metadata attachment from command runner.\n- **Type Definitions**: Imports `TelemetryEntry`, `RunLog`, `FileRead` from `../types.js` — per-call metadata schema with token counts, latency, error state, and file access records.\n\n## Filename Sanitization Strategy\n\nRegex pattern `/[:.]/g` replaces `:` and `.` characters in ISO 8601 timestamps to produce cross-platform-valid filenames (e.g., `2026-02-07T12:00:00.000Z` → `run-2026-02-07T12-00-00-000Z.json`). Lexicographic sort order preserved for cleanup logic.\n\n## Concurrency Characteristics\n\nSingle atomic write per run log with unique timestamped filename eliminates concurrent write conflicts (unlike trace writer's promise-chain serialization pattern). Each CLI invocation produces separate `RunLog` object with distinct `runId`.\n### src/change-detection/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/change-detection\n\nGit-based change detection and SHA-256 content hashing for incremental documentation updates, comparing commit deltas and content digests against `.sum` frontmatter to compute `filesToAnalyze` vs `filesToSkip`.\n\n## Contents\n\n**[detector.ts](./detector.ts)** — Implements `isGitRepo()`, `getCurrentCommit()`, `getChangedFiles()` via simple-git, parses `git diff --name-status -M` output for added/modified/deleted/renamed files, merges uncommitted changes via `git.status()` when `includeUncommitted` enabled, provides `computeContentHash()` and `computeContentHashFromString()` for SHA-256 hex digest generation.\n\n**[types.ts](./types.ts)** — Defines `ChangeType` union (`'added' | 'modified' | 'deleted' | 'renamed'`), `FileChange` interface with discriminated `status` and conditional `oldPath` for renames, `ChangeDetectionResult` containing `changes[]`, `baseCommit`, `currentCommit`, `includesUncommitted`, `ChangeDetectionOptions` with `includeUncommitted` flag.\n\n**[index.ts](./index.ts)** — Barrel export re-exporting all symbols from `detector.ts` and `types.ts` as public API surface.\n\n## Architecture\n\n### Git Integration Pipeline\n\n`getChangedFiles()` invokes `git diff --name-status -M <baseCommit>..HEAD` with rename detection (50% similarity threshold), parses tab-separated status codes: `A` (added), `M` (modified), `D` (deleted), `R{percentage}` (renamed with `oldPath` extraction). Handles two output formats: `STATUS\\tFILE` for single-path changes, `STATUS\\tOLD\\tNEW` for renames, extracts `parts[parts.length - 1]` as final path. When `includeUncommitted: true`, aggregates from `StatusResult` arrays: `modified`, `deleted`, `not_added` (untracked), `staged`, deduplicates via `changes.some(c => c.path === file)` predicate.\n\n### Content Hashing\n\n`computeContentHash()` reads file via `readFile()`, computes SHA-256 via `createHash('sha256').update(content).digest('hex')`. `computeContentHashFromString()` provides synchronous variant for in-memory content to avoid redundant I/O when frontmatter generation already loaded file. Consumed by `src/update/orchestrator.ts` which cross-references `.sum` YAML frontmatter `content_hash` fields against computed digests to determine incremental update scope.\n\n### Discriminated Union Pattern\n\n`FileChange.status` acts as discriminant for `ChangeType` union, enabling type guards to narrow to specific change categories. `oldPath` field conditionally present only when `status === 'renamed'`, enforcing constraint that renames require both paths while additions/modifications/deletions have single `path`.\n\n## Integration Points\n\n**src/update/orchestrator.ts**: Calls `getChangedFiles()` with `baseCommit` from previous run, iterates `ChangeDetectionResult.changes[]`, invokes `computeContentHash()` for each modified/added file, compares against `readSumFile(sumPath).content_hash`, populates `filesToAnalyze` vs `filesToSkip` arrays. Extracts `oldPath` from renamed `FileChange` entries to feed `src/update/orphan-cleaner.ts` for stale `.sum` deletion.\n\n**src/generation/writers/sum.ts**: Calls `computeContentHashFromString()` when writing `.sum` frontmatter to embed digest without re-reading file content, populating YAML `content_hash` field for future incremental comparisons.\n\n**Non-git workflows**: `isGitRepo()` check determines fallback to pure SHA-256 hashing without commit-based delta detection, enabling incremental updates in non-versioned codebases by comparing content digests alone.\n### src/cli/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/cli/\n\nCommand entry points exposing `are` CLI interface: parses flags via `parseArgs()`, routes to init/discover/generate/update/specify/clean via command-specific async handlers, integrates `AIService` subprocess orchestration, `ProgressLog` streaming, `TraceWriter` NDJSON emission, and installer detection for global/local hook registration.\n\n## Contents\n\n### [clean.ts](./clean.ts)\nImplements `are clean` command deleting `.sum` files, generated `AGENTS.md` (via `GENERATED_MARKER` filtering), root integration docs (`CLAUDE.md`/`GEMINI.md`/`OPENCODE.md`), and `GENERATION-PLAN.md`. Discovers artifacts via parallel `fast-glob` queries (`**/*.sum`, `**/AGENTS.md`, `**/AGENTS.local.md`), preserves user-authored files, restores `AGENTS.local.md` → `AGENTS.md` via `rename()`. Supports `--dry-run` for deletion preview without filesystem mutations.\n\n### [discover.ts](./discover.ts)\nImplements `are discover` command executing file discovery pipeline via `discoverFiles()` with gitignore/vendor/binary/custom filters, writing `GENERATION-PLAN.md` with post-order directory traversal via `buildExecutionPlan()`. Emits `discovery:start/end` trace events with `filesIncluded/filesExcluded/durationMs` metadata, logs included/excluded files to `.agents-reverse-engineer/progress.log` for tail monitoring.\n\n### [generate.ts](./generate.ts)\nImplements `are generate` command orchestrating three-phase documentation pipeline: resolves AI backend via `createBackendRegistry()` + `resolveBackend()`, executes `CommandRunner.executeGenerate()` with concurrent file analysis (Phase 1) producing `.sum` files, post-order directory aggregation (Phase 2) generating `AGENTS.md`, sequential root document synthesis (Phase 3) creating `CLAUDE.md`/`GEMINI.md`/`OPENCODE.md`. Supports `--dry-run` for execution plan preview, `--concurrency N` for worker pool override, `--debug` for subprocess heap/RSS metrics, `--trace` for NDJSON event emission. Exit codes: 0 (success), 1 (partial failure), 2 (total failure).\n\n### [index.ts](./index.ts)\nCLI router parsing arguments via `parseArgs()` extracting command/flags/values, handling global flags (`--version`, `--help`), detecting installer invocation via `hasInstallerFlags()`, routing to `initCommand`, `discoverCommand`, `generateCommand`, `updateCommand`, `specifyCommand`, `cleanCommand` via switch statement. Maps flags to options: `--dry-run` → `dryRun`, `--concurrency N` → `concurrency`, `--fail-fast` → `failFast`, `--debug` → `debug`, `--trace` → `trace`, `--uncommitted` → `uncommitted`, `--output <path>` → `output`, `--force` → `force`, `--multi-file` → `multiFile`. Displays `USAGE` string via `showHelp()`, prints version via `showVersion()`.\n\n### [init.ts](./init.ts)\nImplements `are init` command creating `.agents-reverse-engineer/config.yaml` via `writeDefaultConfig()` from `src/config/loader.ts`. Checks existing config via `configExists()`, warns unless `--force` flag provided, logs customization guidance referencing `exclude.patterns`, `ai.concurrency`, `ai.timeoutMs`, `ai.backend`. Exits with code 1 on permission errors (`EACCES`/`EPERM`), re-throws other errors.\n\n### [specify.ts](./specify.ts)\nImplements `are specify` command synthesizing project specifications from `AGENTS.md` corpus via `collectAgentsDocs()`, invoking `AIService.call()` with extended timeout (10-minute minimum via `Math.max(config.ai.timeoutMs, 600_000)`), writing output to `specs/SPEC.md` via `writeSpec()`. Supports `--multi-file` for split specs (`specs/<dirname>.md`), `--dry-run` for token estimation, `--force` for overwrite, auto-generates documentation via `generateCommand()` if `docs.length === 0`. Exits with code 1 on `SpecExistsError`, code 2 on `CLI_NOT_FOUND`.\n\n### [update.ts](./update.ts)\nImplements `are update` command executing incremental workflow: calls `createUpdateOrchestrator().preparePlan()` for git-based change detection with SHA-256 hash comparison, regenerates `.sum` via `CommandRunner.executeUpdate()` for `filesToAnalyze: FileChange[]`, regenerates `AGENTS.md` sequentially for `affectedDirs` via `buildDirectoryPrompt()` + `writeAgentsMd()`, cleans orphaned artifacts via `cleanup.deletedSumFiles/deletedAgentsMd`. Emits Phase 1 (`update-phase-1-files`) and Phase 2 (`update-phase-dir-regen`) trace events with `task:pickup/done` per file, `task:start/done` per directory. Supports `--uncommitted` for working tree changes, displays plan via `formatPlan()` with status markers (`+` green added, `R` blue renamed, `M` yellow modified). Exit codes: 0 (success), 1 (partial failure), 2 (total failure).\n\n## Command Lifecycle\n\nAll command handlers follow shared execution pattern: resolve `targetPath` to absolute path via `path.resolve()`, load config via `loadConfig(absolutePath, { tracer, debug })`, create `ProgressLog.create(absolutePath)` for streaming `.agents-reverse-engineer/progress.log`, resolve backend via `createBackendRegistry()` + `resolveBackend()`, instantiate `AIService(backend, { timeoutMs, maxRetries, model, telemetry })`, create `CommandRunner` with concurrency/failFast/tracer/progressLog options, finalize telemetry via `aiService.finalize(absolutePath)`, call `progressLog.finalize()` to flush buffered writes.\n\n## Argument Parsing\n\n`parseArgs(args: string[])` in `index.ts` iterates `process.argv.slice(2)`, extracts `--flag` → `flags` Set, `--key value` → `values` Map, expands short flags (`-h` → `help`, `-g` → `global`, `-l` → `local`, `-V` → `version`), captures first non-flag arg as `command`, collects remaining non-flags into `positional[]` array. Returns `{ command, positional, flags, values }` for command-specific option mapping.\n\n## Error Exit Codes\n\n- **0**: All tasks succeeded or no files to process\n- **1**: Partial failure (`summary.filesFailed > 0` and `summary.filesProcessed > 0`), `SpecExistsError` without `--force`, permission denied (`EACCES`/`EPERM`)\n- **2**: Total failure (`summary.filesProcessed === 0` and `summary.filesFailed > 0`), `AIServiceError.code === 'CLI_NOT_FOUND'` (no backend available)\n\n## Backend Resolution\n\nAll commands except `init`, `clean`, `discover` call `createBackendRegistry()` from `../ai/index.js` to detect installed CLI tools (Claude Code, Gemini CLI, OpenCode), resolve via `resolveBackend(registry, config.ai.backend)` with `'auto'` fallback, catch `AIServiceError` with `code: 'CLI_NOT_FOUND'`, display `getInstallInstructions(registry)` with installation commands, exit with code 2.\n\n## Progress Monitoring\n\nCommands write session header to `ProgressLog` with ISO 8601 timestamp, project path, file/directory counts, ETA via moving average of last 10 task durations. Real-time monitoring pattern: `tail -f .agents-reverse-engineer/progress.log`. Finalizes via `progressLog.finalize()` after all phases complete.\n\n## Trace Integration\n\nWhen `--trace` flag present, calls `createTraceWriter(absolutePath, true)` from `../orchestration/trace.js`, threads `tracer: ITraceWriter` through `loadConfig()`, `discoverFiles()`, `createOrchestrator()`, `CommandRunner`, emits NDJSON events (`phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`) to `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson`, displays trace path via `pc.dim('[trace] Writing to ${tracer.filePath}')`, cleans old traces via `cleanupOldTraces(absolutePath)` after execution (500-trace retention limit).\n\n## Installer Detection\n\n`index.ts` calls `hasInstallerFlags(flags, values)` checking for `global`/`local`/`force` flags or `runtime` value key, enables pattern `npx agents-reverse-engineer --runtime claude -g` without explicit `install` command, delegates to `runInstaller(parseInstallerArgs())` from `../installer/index.js`.\n### src/config/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/config\n\nConfiguration system with Zod-validated YAML parsing, resource-aware concurrency computation, and commented starter config generation. Provides `loadConfig()` async loader with trace emission, `configExists()` predicate, `writeDefaultConfig()` generator with inline documentation, and `getDefaultConcurrency()` dynamic defaults based on CPU cores and memory constraints to prevent OOM in WSL environments.\n\n## Contents\n\n### Core Schema & Validation\n\n**[schema.ts](./schema.ts)** — Exports five Zod schemas (`ExcludeSchema`, `OptionsSchema`, `OutputSchema`, `AISchema`, `ConfigSchema`) and corresponding TypeScript types (`ExcludeConfig`, `OptionsConfig`, `OutputConfig`, `AIConfig`, `Config`). Defines validation for `.agents-reverse-engineer/config.yaml` with numeric constraints (`.min(1).max(20)` for concurrency, `.positive()` for timeouts/file sizes), enum validation for AI backend selection (`'claude' | 'gemini' | 'opencode' | 'auto'`), and nested defaults spreading arrays from `defaults.ts`. Passes `getDefaultConcurrency` function reference to `AISchema.concurrency.default()` for dynamic pool sizing.\n\n**[loader.ts](./loader.ts)** — Exports `loadConfig()` async function reading YAML from `path.join(root, '.agents-reverse-engineer', 'config.yaml')`, parsing via `yaml.parse()`, validating via `ConfigSchema.parse()`, emitting `config:loaded` trace events with `configPath`/`model`/`concurrency` fields, returning `DEFAULT_CONFIG` on ENOENT, throwing `ConfigError` with formatted `.issues` on `ZodError`. Exports `configExists()` predicate checking file presence via `access()`. Exports `writeDefaultConfig()` generator creating commented YAML via template literals mapping default arrays to indented list items, applying `yamlScalar()` quoting for glob meta-characters.\n\n**[defaults.ts](./defaults.ts)** — Exports `getDefaultConcurrency()` computing worker pool size via three-way clamping: CPU-scaled (`cores * 5`), memory-capped (`floor(totalMemGB * 0.5 / 0.512)`), and hard-bounded (`MIN_CONCURRENCY=2`, `MAX_CONCURRENCY=20`). Exports frozen constant arrays: `DEFAULT_VENDOR_DIRS` (18 entries: node_modules/.git/dist/venv/__pycache__/.cargo/.planning/.claude), `DEFAULT_EXCLUDE_PATTERNS` (32 globs: AGENTS.md/CLAUDE.md/*.lock/.env/*.log/*.sum/**/SKILL.md), `DEFAULT_BINARY_EXTENSIONS` (26 types: .png/.jpg/.zip/.exe/.dll/.pdf/.woff), `DEFAULT_MAX_FILE_SIZE` (1MB threshold), `DEFAULT_CONFIG` (nested object matching Zod structure). Memory capacity calculation prevents OOM by limiting subprocess heap allocation to 50% of system RAM, aligning `SUBPROCESS_HEAP_GB=0.512` with `NODE_OPTIONS='--max-old-space-size=512'` from `../ai/subprocess.ts`.\n\n## File Relationships\n\n**Schema-to-loader flow:** `schema.ts` exports `ConfigSchema` consumed by `loader.ts` for `parse()` validation. Defaults imported by both: `schema.ts` spreads into `.default()` chains, `loader.ts` uses for `writeDefaultConfig()` template generation and fallback values.\n\n**Concurrency computation:** `defaults.ts` `getDefaultConcurrency()` referenced by `schema.ts` `AISchema.concurrency.default()` as function (lazy evaluation on parse). Result emitted in `loader.ts` `config:loaded` trace event.\n\n**Error propagation:** `loader.ts` catches `ZodError` from `ConfigSchema.parse()`, wraps in `ConfigError` with `filePath`/`cause` properties, formats `.issues` array into human-readable message. YAML parse errors from `yaml.parse()` wrapped similarly.\n\n## Configuration Surface\n\n**Five top-level sections:**\n1. `exclude` — File/directory filtering via `patterns` (gitignore globs), `vendorDirs` (third-party paths), `binaryExtensions` (non-text types)\n2. `options` — Discovery behavior: `followSymlinks` (boolean), `maxFileSize` (positive number)\n3. `output` — Terminal formatting: `colors` (boolean)\n4. `ai` — Backend orchestration: `backend` (enum), `model` (string), `timeoutMs`/`maxRetries`/`concurrency` (numbers), `telemetry.keepRuns` (number)\n5. (implicit) — Root schema applying `.default({})` to all sections for total defaults on empty input\n\n**Validation constraints:**\n- `concurrency` ∈ [1, 20] via `.min(1).max(20)`\n- `timeoutMs`, `maxFileSize` > 0 via `.positive()`\n- `maxRetries`, `telemetry.keepRuns` ≥ 0 via `.min(0)`\n- `backend` ∈ {'claude', 'gemini', 'opencode', 'auto'} via `z.enum()`\n\n## Integration Points\n\n**Consumed by discovery filters:** `defaults.ts` constants (`DEFAULT_VENDOR_DIRS`, `DEFAULT_BINARY_EXTENSIONS`, `DEFAULT_EXCLUDE_PATTERNS`) imported by `../discovery/filters/vendor.ts`, `../discovery/filters/binary.ts`, `../discovery/filters/custom.ts` for filter initialization.\n\n**Consumed by orchestration:** `loader.ts` exports imported by `../cli/` entry points (init.ts/discover.ts/generate.ts/update.ts), `loadConfig()` result threaded through `CommandRunOptions` to worker pool and AI service.\n\n**Trace emission:** `loader.ts` receives `ITraceWriter` from `../orchestration/trace.ts` via `options.tracer`, emits `config:loaded` event with resolved configuration snapshot for observability.\n\n**Subprocess alignment:** `defaults.ts` `SUBPROCESS_HEAP_GB` constant (0.512 GB) matches `NODE_OPTIONS='--max-old-space-size=512'` environment variable set in `../ai/subprocess.ts` `runSubprocess()` function for memory capacity calculation.\n### src/discovery/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/discovery\n\nGitignore-aware file walker with composable four-stage filter chain (gitignore, vendor, binary, custom) producing FilterResult aggregates of included/excluded files with attribution metadata for discovery phase initialization.\n\n## Contents\n\n**[walker.ts](./walker.ts)** — `walkDirectory(options: WalkerOptions)` returns absolute paths for all files under `options.cwd` via `fast-glob('**/*')` with `onlyFiles: true`, `dot: true` (includes dotfiles), `followSymbolicLinks: options.followSymlinks ?? false`, hardcoded `.git/**` exclusion, `suppressErrors: true` (continues on permission errors).\n\n**[run.ts](./run.ts)** — `discoverFiles(root: string, config: DiscoveryConfig, options?: DiscoverFilesOptions)` orchestrates filter pipeline: invokes `walkDirectory()`, constructs four filters via `createGitignoreFilter(root)`, `createVendorFilter(config.exclude.vendorDirs)`, `createBinaryFilter({ maxFileSize: config.options.maxFileSize, additionalExtensions: config.exclude.binaryExtensions })`, `createCustomFilter(config.exclude.patterns, root)`, executes via `applyFilters(files, filters, { tracer, debug })`, returns `FilterResult` with `included`/`excluded` arrays.\n\n**[types.ts](./types.ts)** — Exports `FileFilter` interface (`{ name: string, shouldExclude(path: string, stats?: Stats): boolean | Promise<boolean> }`), `FilterResult` interface (`{ included: string[], excluded: ExcludedFile[] }`), `ExcludedFile` record (`{ path, reason, filter }`), `WalkerOptions` config (`{ cwd: string, followSymlinks?: boolean, dot?: boolean }`). No runtime dependencies—pure type definitions.\n\n## Filter Pipeline Architecture\n\n`discoverFiles()` executes filters in fixed order: gitignore → vendor → binary → custom. Short-circuit evaluation: file rejected on first filter match, remaining filters skipped. `applyFilters()` from `filters/index.ts` uses concurrency-bounded execution (30 worker pool) with trace emission via `filter:applied` events containing `{ type: 'filter:applied', filterName, filesMatched, filesRejected }`.\n\n## Configuration Surface\n\n`DiscoveryConfig` subset from `src/config/schema.ts`:\n- `exclude.vendorDirs: string[]` — directories matched anywhere in path (e.g., `node_modules`, `.git`, `dist`)\n- `exclude.binaryExtensions: string[]` — file extensions for fast-path exclusion (e.g., `.png`, `.zip`, `.exe`)\n- `exclude.patterns: string[]` — gitignore-style globs matched via `ignore` library\n- `options.maxFileSize: number` — binary detection threshold (default 1MB)\n- `options.followSymlinks: boolean` — symlink traversal (default false per security constraints)\n\n`DiscoverFilesOptions` extends runtime config:\n- `tracer?: ITraceWriter` — NDJSON trace event emitter from `orchestration/trace.ts`\n- `debug?: boolean` — verbose filter logging to stderr\n\n## Data Flow\n\n```\nwalkDirectory(cwd, followSymlinks) → string[]\n  ↓\napplyFilters(files, [gitignore, vendor, binary, custom], { tracer, debug }) → FilterResult\n  ↓\n{ included: string[], excluded: ExcludedFile[] }\n```\n\nWalker performs no filtering except `.git/**` exclusion—all semantic filtering delegated to filter chain. Result structure supports diagnostics via `excluded` metadata and plan generation via full file enumeration.\n\n## Integration Points\n\n- **cli/discover.ts**: calls `discoverFiles()`, writes `GENERATION-PLAN.md` with included/excluded breakdown\n- **cli/generate.ts**: uses `included` array for Phase 1 file analysis task queue\n- **cli/update.ts**: invokes `discoverFiles()` to detect new files not in existing `.sum` frontmatter hashes\n- **filters/**: subdirectory containing `createGitignoreFilter`, `createVendorFilter`, `createBinaryFilter`, `createCustomFilter` factories implementing `FileFilter` interface\n\n## Design Rationale\n\nSeparation of concerns: `walkDirectory()` handles traversal, filter chain handles exclusion logic. Composable filters enable independent testing and configurable ordering. `FilterResult` structure preserves exclusion metadata for debugging unlike simple string arrays. Async `FileFilter.shouldExclude()` supports I/O-bound filters (gitignore file reads, binary content analysis) without blocking synchronous filters (vendor directory lookups).\n### src/discovery/filters/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/discovery/filters\n\nComposable file exclusion filters implementing gitignore parsing, vendor directory detection, binary file analysis, and custom glob patterns for the discovery phase file walker.\n\n## Contents\n\n### Filter Implementations\n\n**[binary.ts](./binary.ts)** — `createBinaryFilter(options?: BinaryFilterOptions)` implements three-layer binary detection: extension-based fast path against `BINARY_EXTENSIONS` set (80+ extensions: images, archives, executables, media, documents, fonts, bytecode, databases), size threshold enforcement via `fs.stat()`, content analysis fallback via `isBinaryFile()` from `isbinaryfile` package.\n\n**[custom.ts](./custom.ts)** — `createCustomFilter(patterns: string[], root: string)` wraps `ignore` library for gitignore-style pattern matching against user-defined exclusion globs from config (`config.exclude.patterns`). Converts absolute paths to relative via `path.relative()`, guards against external paths (starting with `..`).\n\n**[gitignore.ts](./gitignore.ts)** — `createGitignoreFilter(root: string)` async factory reads `.gitignore` from project root, populates `Ignore` instance from `ignore` library, returns FileFilter with `shouldExclude()` method converting absolute paths to relative before pattern matching. Silent fallback to pass-through filter if `.gitignore` missing.\n\n**[vendor.ts](./vendor.ts)** — `createVendorFilter(vendorDirs: string[])` implements dual-strategy exclusion: single-segment lookup in `Set<string>` for directories like `node_modules`/`dist`/`build` (O(1) per segment), multi-segment substring search for nested patterns like `apps/vendor`. Exports `DEFAULT_VENDOR_DIRS` constant (10 common directories: node_modules, vendor, .git, dist, build, __pycache__, .next, venv, .venv, target).\n\n**[index.ts](./index.ts)** — Filter chain orchestrator re-exporting all filter creators, providing `applyFilters(files: string[], filters: FileFilter[], options?)` with concurrency-bounded execution (`CONCURRENCY=30` worker pool), short-circuit evaluation per file, trace emission via `filter:applied` events, result aggregation into `FilterResult` with `included` and `excluded` arrays containing `ExcludedFile` metadata (`{ path, reason, filter }`).\n\n## Filter Chain Architecture\n\nFilters implement `FileFilter` interface from `../types.ts` with `name: string` property and `shouldExclude(absolutePath: string): boolean | Promise<boolean>` method. Walker in `src/discovery/walker.ts` composes filters into exclusion chain with short-circuit logic: file rejected on first filter match.\n\nExecution pattern: `applyFilters()` uses iterator-based worker pool matching `src/orchestration/pool.ts` architecture — single shared `files.entries()` iterator across N concurrent workers prevents over-allocation during binary content detection I/O. Each worker processes files through filter array sequentially, accumulates results with original index preservation, returns `{ index, file, excluded?: ExcludedFile }` tuples.\n\n## Binary Detection Strategy\n\n`createBinaryFilter()` three-phase algorithm optimizes I/O:\n1. Extension check: `path.extname().toLowerCase()` against `binaryExtensions` Set (merged from `BINARY_EXTENSIONS` constant and `additionalExtensions` config with leading-dot normalization)\n2. Size threshold: `fs.stat()` enforces `maxFileSize` limit (default 1MB via `DEFAULT_MAX_FILE_SIZE=1048576`)\n3. Content analysis: `isBinaryFile(absolutePath)` for unknown extensions\n\nFast path (extension match) avoids filesystem I/O for 80+ common binary types. Slow path (content analysis) only triggered for unknown extensions. Error handling returns `true` for `fs.stat()` failures (fail-safe exclusion of unreadable files).\n\n## Vendor Directory Matching\n\n`createVendorFilter()` normalizes patterns via `/[\\\\/]/g → path.sep` replacement before split decision:\n- Single segments (no `path.sep`): stored in `Set<string>` for O(1) lookup per path segment via `absolutePath.split(path.sep).some(s => singleSegments.has(s))`\n- Multi-segment patterns (contains `path.sep`): substring search via `absolutePath.includes(normalizedPattern)`\n\nSingle-segment matches occur anywhere in path (`node_modules` matches `/project/node_modules/pkg/index.js` and `/apps/client/node_modules/lib.js`). Multi-segment requires ordered substring (`apps/vendor` matches `/root/apps/vendor/lib.js` but not `/root/vendor/apps/lib.js`).\n\n## Gitignore Integration\n\n`createGitignoreFilter()` delegates to `ignore` library requiring relative paths. Path conversion logic in `shouldExclude()`: `path.relative(normalizedRoot, absolutePath)` with guards for external paths (starting with `..`) and empty paths (absolutePath equals root), both returning `false` to bypass exclusion. No trailing slash normalization since walker returns files only.\n\n## Custom Pattern Handling\n\n`createCustomFilter()` validates paths via `path.relative()` before delegation to `ignore` library. External file protection: paths starting with `..` return `false` to prevent exclusion of out-of-tree references. Empty pattern array results in pass-through filter (`shouldExclude()` always returns `false`).\n\n## Result Aggregation\n\n`applyFilters()` constructs `FilterResult` via:\n1. Worker results sorted by original index to preserve file order\n2. Exclusions collected into `excluded: ExcludedFile[]` with `{ path, reason, filter }` metadata indicating rejection source\n3. Inclusions aggregated into `included: string[]` containing files passing all filters\n4. Per-filter statistics tracked in `Map<string, { matched, rejected }>` for trace emission\n\nTrace events (`filter:applied`) emitted with `{ type, filterName, filesMatched, filesRejected }` payloads. Debug mode outputs rejection counts via `console.error()` when `stats.rejected > 0`.\n\n## Dependencies\n\n- `ignore` library: gitignore/glob pattern matching engine (gitignore.ts, custom.ts)\n- `isbinaryfile` package: content-based binary file detection (binary.ts)\n- `node:fs/promises`: async file reading for `.gitignore` (gitignore.ts)\n- `node:path`: path normalization, resolution, relative conversion (all filters)\n- `../types.ts`: FileFilter, FilterResult, ExcludedFile interfaces\n- `../../orchestration/trace.ts`: ITraceWriter for filter execution telemetry\n### src/generation/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/generation\n\n**Phase orchestration for three-stage AI-driven documentation pipeline: concurrent `.sum` file analysis via worker pools, post-order directory `AGENTS.md` synthesis with import map injection, and platform-specific root document generation from aggregated corpus.**\n\n## Contents\n\n### Orchestration & Planning\n\n**[orchestrator.ts](./orchestrator.ts)** — `GenerationOrchestrator` class with `prepareFiles()` reading file content via `readFile()`, `createFileTasks()` calling `buildFilePrompt()` for each file, `createDirectoryTasks()` grouping files by `path.dirname(relativePath)`, `createPlan()` emitting `phase:start`/`plan:created`/`phase:end` traces and returning `GenerationPlan` with `files`, `tasks`, `complexity` from `analyzeComplexity()`, `projectStructure` from `buildProjectStructure()`; memory management via `(file as { content: string }).content = ''` after task creation.\n\n**[executor.ts](./executor.ts)** — `buildExecutionPlan()` transforms `GenerationPlan` into `ExecutionPlan` with dependency-ordered `tasks[]`, `fileTasks[]`, `directoryTasks[]`, `rootTasks[]`, `directoryFileMap: Record<string, string[]>` via `path.dirname()` extraction, sorts directories by `getDirectoryDepth()` descending for post-order traversal; `isDirectoryComplete()` validates `.sum` file presence for expected files via `sumFileExists()`; `getReadyDirectories()` filters directories with complete file analysis; `formatExecutionPlanAsMarkdown()` renders plan with Phase 1/2/3 sections, groups files by directory with checkbox format, sorts directories by depth descending.\n\n**[complexity.ts](./complexity.ts)** — `analyzeComplexity()` returns `ComplexityMetrics` with `fileCount`, `directoryDepth` from `calculateDirectoryDepth()` splitting `path.relative()` on `path.sep`, `directories: Set<string>` from `extractDirectories()` walking parent chain via `path.dirname()` loop.\n\n**[types.ts](./types.ts)** — Defines `AnalysisResult` with `summary: string`, `metadata: SummaryMetadata` (`purpose`, `criticalTodos?`, `relatedFiles?`); `SummaryOptions` with `targetLength: 'short' | 'standard' | 'detailed'`, `includeCodeSnippets: boolean`.\n\n### Document Collection\n\n**[collector.ts](./collector.ts)** — `collectAgentsDocs()` recursively traverses directories via internal `walk()` closure using `readdir()` with `withFileTypes: true`, reads all `AGENTS.md` files via `readFile()`, computes relative paths via `path.relative()`, sorts results by `relativePath` via `localeCompare()`, skips 13 vendor directories (`node_modules`, `.git`, `.agents-reverse-engineer`, `vendor`, `dist`, `build`, `__pycache__`, `.next`, `venv`, `.venv`, `target`, `.cargo`, `.gradle`) via `SKIP_DIRS.has(entry.name)` predicate; returns `AgentsDocs` array with `{ relativePath, content }` objects.\n\n## Subdirectories\n\n**[prompts/](./prompts/)** — Exports `buildFilePrompt()` constructing Phase 1 `.sum` analysis prompts with import context and incremental update support via `FILE_UPDATE_SYSTEM_PROMPT`, `buildDirectoryPrompt()` aggregating child summaries into Phase 2 `AGENTS.md` synthesis prompts with manifest detection (9 types: package.json, Cargo.toml, go.mod, pyproject.toml, pom.xml, build.gradle, Gemfile, composer.json, CMakeLists.txt/Makefile) and `extractDirectoryImports()` for source files matching `/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/`, `buildRootPrompt()` collecting all `AGENTS.md` files via `collectAgentsDocs()` for Phase 3 platform-specific root document generation; templates enforce density rules (every sentence references identifiers, ban filler phrases), anchor term preservation (exact casing), path accuracy (use only Import Map paths); user documentation preserved via `AGENTS.local.md` prepending with comment block wrapper.\n\n**[writers/](./writers/)** — Exports `writeSumFile()` serializing YAML frontmatter with SHA-256 `content_hash` via `formatSumFile()`, `readSumFile()` parsing frontmatter via regex-based `parseSumFile()` with null on parse failure, `getSumPath()` appending `.sum` extension, `sumFileExists()` checking filesystem via `readSumFile()` null test; `writeAgentsMd()` implementing four-step protocol: in-place `AGENTS.md` → `AGENTS.local.md` rename if missing `GENERATED_MARKER`, fallback `AGENTS.local.md` load, marker stripping from LLM content, assembly with user content prepended in comment block; `parseYamlArray()`/`formatYamlArray()` supporting inline `[a, b, c]` and multi-line `- item` formats.\n\n## Architecture\n\n### Three-Phase Pipeline\n\n**Phase 1: Concurrent File Analysis**\n1. `GenerationOrchestrator.prepareFiles()` reads source file content via `readFile()`\n2. `createFileTasks()` calls `buildFilePrompt()` for each file with import context from `extractDirectoryImports()`\n3. Worker pool executes file tasks in parallel (default concurrency: 2 for WSL, 5 elsewhere)\n4. `writeSumFile()` persists `.sum` files with YAML frontmatter containing `generated_at`, `content_hash`, `purpose`, optional `critical_todos`/`related_files`\n\n**Phase 2: Post-Order Directory Aggregation**\n1. `buildExecutionPlan()` sorts directories by `getDirectoryDepth()` descending (deepest first)\n2. `isDirectoryComplete()` waits for all child `.sum` files to exist via `sumFileExists()` predicate\n3. `buildDirectoryPrompt()` reads child `.sum` files via `readSumFile()`, detects manifests (package.json, Cargo.toml, etc.), extracts import maps via `extractDirectoryImports()`\n4. `writeAgentsMd()` renames user `AGENTS.md` → `AGENTS.local.md` if non-generated, prepends user content to LLM output\n\n**Phase 3: Root Document Synthesis**\n1. `collectAgentsDocs()` recursively aggregates all `AGENTS.md` files\n2. `buildRootPrompt()` reads root `package.json` for project metadata (`name`, `version`, `description`, `packageManager`, `scripts`)\n3. Sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`\n4. Templates enforce synthesis-only constraint (no invention/extrapolation, every claim traceable to `AGENTS.md`)\n\n### Dependency Graph Construction\n\n`buildExecutionPlan()` constructs task dependencies:\n- File tasks: `id: 'file:${path}'`, `dependencies: []`, `outputPath: ${absolutePath}.sum`\n- Directory tasks: `id: 'dir:${dir}'`, `dependencies` array populated from `directoryFileMap[dir]` paths mapped to `file:${path}` task IDs, `metadata.depth` from `getDirectoryDepth(dir)`, `metadata.directoryFiles` as file list\n- Root tasks: `id: 'root:CLAUDE.md'`, `dependencies` array containing all directory task IDs\n\nDirectory tasks wait for child file tasks via `isDirectoryComplete()` checking `.sum` file existence. Root tasks wait for all directory tasks via dependency array containing every `dir:${path}` task ID.\n\n### Incremental Update Support\n\n`buildFilePrompt()` switches to `FILE_UPDATE_SYSTEM_PROMPT` when `existingSum` detected, instructing: \"preserve structure/headings/phrasing verbatim where code unchanged, add/remove sections only when code introduces/deletes concepts\". Similarly `buildDirectoryPrompt()` switches to `DIRECTORY_UPDATE_SYSTEM_PROMPT` when `existingAgentsMd` present. Reduces version control churn during `are update` workflow by minimizing unnecessary rewrites.\n\n## File Relationships\n\n**Consumed by src/orchestration/runner.ts:**\n- Calls `createOrchestrator()` from `orchestrator.ts` to instantiate `GenerationOrchestrator`\n- Calls `orchestrator.createPlan()` to generate `GenerationPlan`\n- Calls `buildExecutionPlan()` from `executor.ts` to transform plan into dependency-ordered `ExecutionPlan`\n- Executes tasks respecting `dependencies[]` ordering via worker pool\n\n**Consumes src/imports/extractor.ts:**\n- Calls `extractDirectoryImports()` in `buildFilePrompt()` to inject import context for Phase 1 file analysis\n- Calls `extractDirectoryImports()` in `buildDirectoryPrompt()` to inject import maps for Phase 2 directory synthesis\n\n**Consumes src/ai/service.ts:**\n- `runner.ts` invokes `AIService.call()` for each task, passing `systemPrompt`/`userPrompt` from `ExecutionTask`\n- LLM responses populate `AnalysisResult` with `summary`/`metadata` for `.sum` file writing\n\n**Consumed by src/cli/generate.ts:**\n- Imports `createOrchestrator` to orchestrate three-phase pipeline\n- Imports `buildExecutionPlan` to transform plan into executable tasks\n- Imports `formatExecutionPlanAsMarkdown` to write `GENERATION-PLAN.md`\n\n**Consumed by src/update/orchestrator.ts:**\n- Calls `readSumFile()` to extract `content_hash` for SHA-256 comparison during incremental updates\n- Calls `buildFilePrompt()` with `existingSum` parameter to trigger update-specific prompts\n\n**Consumed by src/quality/inconsistency/code-vs-doc.ts:**\n- Calls `readSumFile()` to extract exported symbols from `.sum` summaries for consistency validation\n\n## Integration Points\n\n**Trace Emission:** `GenerationOrchestrator.createPlan()` emits `phase:start`, `plan:created`, `phase:end` traces via `ITraceWriter` from `src/orchestration/trace.ts`.\n\n**Progress Tracking:** `formatExecutionPlanAsMarkdown()` output written to `GENERATION-PLAN.md` via `PlanTracker` in `src/orchestration/plan-tracker.ts`.\n\n**Memory Management:** `prepareFiles()` clears `content` fields on `PreparedFile` objects after `createFileTasks()` to release file content strings since content is already embedded in task prompts.\n\n**Quality Validation:** Exported symbols extracted via regex in `src/quality/inconsistency/code-vs-doc.ts` compared against `.sum` summary text via substring search; phantom paths extracted from `AGENTS.md` via three regex patterns in `src/quality/phantom-paths/validator.ts` resolved against filesystem via `existsSync()`.\n### src/generation/prompts/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# generation/prompts\n\nExports prompt builders for the three-phase AI-driven documentation pipeline: `buildFilePrompt` constructs Phase 1 per-file `.sum` analysis prompts with import context and incremental update support, `buildDirectoryPrompt` aggregates child summaries into Phase 2 `AGENTS.md` synthesis prompts with manifest detection and import maps, `buildRootPrompt` collects all `AGENTS.md` files for Phase 3 platform-specific root document generation.\n\n## Contents\n\n### Core Prompt Builders\n\n**[builder.ts](./builder.ts)** — Implements `buildFilePrompt()` reading `PromptContext.filePath`/`content`/`contextFiles`/`existingSum`, calls `detectLanguage()` for syntax highlighting, replaces placeholders in `FILE_USER_PROMPT`, appends import context and existing summaries for incremental updates switching to `FILE_UPDATE_SYSTEM_PROMPT`; `buildDirectoryPrompt()` enumerates directory via `readdir()`, reads `.sum` files in parallel via `getSumPath()` + `readSumFile()`, detects 9 manifest types (package.json, Cargo.toml, go.mod, pyproject.toml, pom.xml, build.gradle, Gemfile, composer.json, CMakeLists.txt/Makefile), calls `extractDirectoryImports()` for source files matching `/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/`, appends user documentation from `AGENTS.local.md` or non-generated `AGENTS.md` (missing `GENERATED_MARKER`), switches to `DIRECTORY_UPDATE_SYSTEM_PROMPT` when `existingAgentsMd` present; `buildRootPrompt()` calls `collectAgentsDocs()` for recursive `AGENTS.md` aggregation, reads root `package.json` via `readFile()`, extracts `name`/`version`/`description`/`packageManager`/`scripts`, enforces synthesis-only constraint prohibiting invention of features/hooks/patterns; `detectLanguage()` maps file extensions to 20 syntax highlighting identifiers via hardcoded `langMap` (`.ts` → `typescript`, `.py` → `python`, `.rs` → `rust`, etc.), defaults to `'text'` for unmapped types.\n\n**[templates.ts](./templates.ts)** — Exports `FILE_SYSTEM_PROMPT` enforcing density rules (every sentence references identifiers, ban filler phrases \"this file\"/\"provides\"/\"responsible for\"), anchor term preservation (exact casing of exported symbols), adaptive documentation topics (public interface, algorithms, data structures, integration points, configuration, error handling, concurrency, lifecycle, domain patterns); `FILE_USER_PROMPT` template with `{{FILE_PATH}}`/`{{CONTENT}}`/`{{LANG}}` placeholders and embedded project structure tree (37 directories, 68 files); `FILE_UPDATE_SYSTEM_PROMPT` adding incremental rules (preserve structure/headings/phrasing where code unchanged, modify only affected content, update signatures/types to match source); `DIRECTORY_SYSTEM_PROMPT` mandating `<!-- Generated by agents-reverse-engineer -->` marker followed by `#` heading and one-paragraph purpose, specifying adaptive sections (Contents with `[filename](./filename)` links, Subdirectories with `[dirname/](./dirname/)` summaries, Architecture/Data Flow, Stack, Structure, Patterns, Configuration, API Surface, File Relationships), enforcing path accuracy (use only Import Map paths, exact directory names from Project Directory Structure, actual import specifiers), consistency (no self-contradiction, no technique renaming, use only summary values), scope (navigational index for finding files quickly); `DIRECTORY_UPDATE_SYSTEM_PROMPT` adding incremental rules (preserve accurate structure/headings/descriptions, modify only changed entries, add/remove for new/deleted files, avoid reorganizing unaffected sections); `ROOT_SYSTEM_PROMPT` mandating raw markdown output only (no preamble/meta-commentary), synthesize-only constraint (no invention/extrapolation/hallucination, every claim traceable to AGENTS.md, omit missing sections).\n\n**[types.ts](./types.ts)** — Defines `PromptContext` interface with `filePath: string`, `content: string`, `contextFiles?: Array<{ path: string; content: string }>`, `projectPlan?: string`, `existingSum?: string`; exports `SUMMARY_GUIDELINES` frozen object with `targetLength: { min: 200, max: 300 }`, `include: string[]` array (6 entries: purpose statement, public interface, patterns/algorithms, dependencies with usage context, function signatures, tightly coupled siblings), `exclude: string[]` array (3 entries: internal implementation, generic TODOs/FIXMEs, broad architectural relationships).\n\n**[index.ts](./index.ts)** — Barrel re-export module exposing `buildFilePrompt`, `buildDirectoryPrompt`, `buildRootPrompt`, `detectLanguage` from `./builder.js`, `PromptContext`, `SUMMARY_GUIDELINES` from `./types.js`.\n\n## File Relationships\n\n`builder.ts` imports `FILE_SYSTEM_PROMPT`, `FILE_USER_PROMPT`, `FILE_UPDATE_SYSTEM_PROMPT`, `DIRECTORY_SYSTEM_PROMPT`, `DIRECTORY_UPDATE_SYSTEM_PROMPT`, `ROOT_SYSTEM_PROMPT` from `./templates.js`, calls `readSumFile()`/`getSumPath()` from `../writers/sum.js`, `GENERATED_MARKER` from `../writers/agents-md.js`, `extractDirectoryImports()`/`formatImportMap()` from `../../imports/index.js`, `collectAgentsDocs()` from `../collector.js`. Consumed by `src/generation/executor.ts` orchestrating three-phase pipeline via worker pool: Phase 1 uses `buildFilePrompt()` with import maps from `src/imports/extractor.ts`, Phase 2 uses `buildDirectoryPrompt()` with aggregated child `.sum` content, Phase 3 uses `buildRootPrompt()` with collected `AGENTS.md` files from `src/generation/collector.ts`. Guidelines in `SUMMARY_GUIDELINES` enforced by quality validators: `src/quality/inconsistency/code-vs-doc.ts` extracts exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`, `src/quality/phantom-paths/validator.ts` resolves path references in `AGENTS.md` via `existsSync()`.\n\n## Incremental Update Strategy\n\n`buildFilePrompt()` and `buildDirectoryPrompt()` switch to update-specific system prompts (`FILE_UPDATE_SYSTEM_PROMPT`, `DIRECTORY_UPDATE_SYSTEM_PROMPT`) when `existingSum` or `existingAgentsMd` detected. Update prompts instruct: \"preserve stable content, modify only what changed\" via explicit rules (preserve structure/headings/phrasing verbatim where code unchanged, add/remove sections only when code introduces/deletes concepts, update signatures/types/identifiers to match current source exactly). Reduces unnecessary rewrites during `are update` workflow minimizing version control churn.\n\n## User Documentation Preservation\n\n`buildDirectoryPrompt()` checks for `AGENTS.local.md` first, falls back to non-generated `AGENTS.md` (files missing `GENERATED_MARKER` constant `<!-- Generated by agents-reverse-engineer -->`). Appends user content as \"User Notes\" section with file reference. First-run detection renames user `AGENTS.md` → `AGENTS.local.md` (handled by caller in `src/generation/writers/agents-md.ts`, not this module). User notes automatically prepended to output by templates, prompt builders instructed not to repeat/paraphrase them in generated content.\n\n## Debug Logging\n\nInternal `logTemplate()` function in `builder.ts` logs when `debug=true` via `console.error()` with `picocolors.dim()` formatting. Outputs: `[prompt] buildFilePrompt → path lang=typescript`, `[prompt] buildDirectoryPrompt → path files=5 subdirs=2 imports=8` to reduce visual noise during pipeline execution.\n### src/generation/writers/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/generation/writers\n\n**.sum file and AGENTS.md lifecycle management: YAML frontmatter serialization with SHA-256 content hashing, filesystem I/O with parent directory creation, user content preservation via AGENTS.local.md renaming, and generation marker injection for provenance tracking.**\n\n## Contents\n\n### Core Writers\n\n**[sum.ts](./sum.ts)** — `.sum` file I/O with `writeSumFile()` (YAML frontmatter serialization via `formatSumFile()`, SHA-256 `content_hash` persistence), `readSumFile()` (regex-based frontmatter extraction via `parseSumFile()`, null on parse failure), `getSumPath()` (appends `.sum` extension), `sumFileExists()` (filesystem check via `readSumFile()` null test), `parseYamlArray()` (supports inline `[a, b, c]` and multi-line `- item` formats), `formatYamlArray()` (inline format for ≤3 items <40 chars, multi-line otherwise).\n\n**[agents-md.ts](./agents-md.ts)** — `AGENTS.md` lifecycle with `writeAgentsMd()` (four-step protocol: AGENTS.md → AGENTS.local.md rename if missing `GENERATED_MARKER`, fallback AGENTS.local.md load, marker stripping from LLM content, assembly with user content prepended in comment block), `isGeneratedAgentsMd()` (substring check for `GENERATED_MARKER`), `GENERATED_MARKER` constant (`'<!-- Generated by agents-reverse-engineer -->'`).\n\n**[index.ts](./index.ts)** — Barrel re-export of `writeSumFile`, `readSumFile`, `getSumPath`, `sumFileExists`, `SumFileContent` from `./sum.js` and `writeAgentsMd` from `./agents-md.js`.\n\n## Serialization Strategy\n\n### YAML Frontmatter Format\n\nsum.ts implements custom YAML serialization avoiding library dependencies. `formatSumFile()` produces frontmatter with required fields (`generated_at`, `content_hash`, `purpose`) and conditionally includes optional arrays (`critical_todos`, `related_files`) via `formatYamlArray()`. Frontmatter separated from markdown summary body with `---` delimiters.\n\nInline array format (`key: [a, b, c]`) used when all items <40 chars and array length ≤3. Multi-line format (`key:\\n  - item`) used otherwise. Empty arrays serialized as `key: []`.\n\n### Frontmatter Parsing\n\n`parseSumFile()` extracts frontmatter via `/^---\\n([\\s\\S]*?)\\n---\\n/` regex, parses single-line fields (`generated_at: value`) via targeted patterns, delegates array parsing to `parseYamlArray()`. Returns null on regex match failure or missing required fields.\n\n`parseYamlArray()` supports dual formats: inline via `/key:\\s*\\[([^\\]]*)\\]/` and multi-line via `/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m`. Trims whitespace and quote characters from extracted items.\n\n## User Content Preservation\n\nagents-md.ts implements two-pass user content detection. `writeAgentsMd()` first checks in-place `AGENTS.md` for `GENERATED_MARKER` absence (indicating user-authored content), renames to `AGENTS.local.md` if non-generated. Second pass reads `AGENTS.local.md` from previous runs as fallback.\n\nUser content prepended to LLM-generated content with comment block wrapper:\n```\n<!-- User-defined AGENTS.md preserved as AGENTS.local.md -->\n[user content]\n---\n[LLM content]\n```\n\nStrips `GENERATED_MARKER` from LLM content to prevent duplication when LLM includes marker from prompt examples. Normalizes leading newlines after stripping.\n\n## File Relationships\n\n**Consumed by Phase 1 (src/generation/orchestrator.ts):**\n- Calls `writeSumFile()` after concurrent file analysis to persist `.sum` files with YAML frontmatter\n\n**Consumed by Phase 2 (src/generation/executor.ts):**\n- Calls `readSumFile()` to load child `.sum` files during directory aggregation\n- Calls `writeAgentsMd()` after LLM synthesis of directory documentation\n\n**Consumed by Incremental Updates (src/update/orchestrator.ts):**\n- Calls `readSumFile()` to extract `content_hash` for SHA-256 comparison\n- Calls `sumFileExists()` for orphan detection (stale `.sum` files for deleted sources)\n\n**Consumed by Quality Validation (src/quality/inconsistency/code-vs-doc.ts):**\n- Calls `readSumFile()` to extract exported symbols from `.sum` summaries for consistency checks\n\n**Consumed by Orphan Cleanup (src/update/orphan-cleaner.ts):**\n- Calls `getSumPath()` to compute paths for deletion of stale `.sum` files\n### src/imports/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/imports\n\n**Static import analysis subsystem extracting TypeScript/JavaScript import statements via regex-based parsing, filtering relative imports into internal (`./`) and external (`../`) categories, and formatting import maps for directory aggregation prompts consumed during Phase 2 documentation synthesis.**\n\n## Contents\n\n### [extractor.ts](./extractor.ts)\nCore import extraction engine exposing `extractImports()` (regex-based parser matching `IMPORT_REGEX` pattern with five capture groups for type keyword, named symbols, namespace imports, default imports, and module specifiers), `extractDirectoryImports()` (reads first 100 lines from each file, filters bare specifiers and `node:` built-ins, classifies relative imports into `internal` and `external` arrays based on `./` vs `../` prefix), and `formatImportMap()` (serializes `FileImports[]` to human-readable text block with `specifier → symbols` lines and optional `(type)` suffix for type-only imports).\n\n### [types.ts](./types.ts)\nType definitions for import analysis: `ImportEntry` interface with `specifier`, `symbols`, and `typeOnly` properties representing single import statements; `FileImports` interface aggregating `fileName`, `externalImports`, and `internalImports` arrays for per-file import classification.\n\n### [index.ts](./index.ts)\nBarrel re-export providing public API surface: `extractImports()`, `extractDirectoryImports()`, `formatImportMap()`, `ImportEntry`, `FileImports`.\n\n## Integration Points\n\n**Consumed by `src/generation/prompts/builder.ts`:**\n`buildDirectoryAggregationPrompt()` calls `extractDirectoryImports()` to inject import context into directory-level `AGENTS.md` synthesis prompts during Phase 2. Import maps show which files import from parent directories, revealing coupling boundaries and dependency graphs without requiring AST traversal.\n\n## Performance Optimizations\n\n**Line slicing strategy:** Reads only first 100 lines via `content.split('\\n').slice(0, 100)` before regex processing (assumption: ES module hoisting places imports at file top). Avoids parsing thousands of implementation lines in large files.\n\n**Bare specifier filtering:** Excludes npm packages (`react`, `lodash`) and Node.js built-ins (`node:fs`) by requiring `specifier.startsWith('.')` or `specifier.startsWith('..')`, reducing import map noise for codebase navigation context.\n\n## Regex Pattern\n\n`IMPORT_REGEX`: `/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm` with line start anchor preventing dynamic import matches. Capture groups: (1) `type` keyword, (2) named symbols in braces, (3) namespace import `* as name`, (4) default import, (5) module specifier. Resets `lastIndex` to 0 before each `exec()` loop for global regex state hygiene.\n### src/installer/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# installer\n\nExecutes npx-driven installation/uninstallation workflow for ARE commands and session hooks across Claude Code, Gemini CLI, and OpenCode runtimes, orchestrating interactive prompts with TTY-aware selection UI, file copying to global (`~/.claude`, `~/.gemini`, `~/.config/opencode`) or local (`.claude`, `.gemini`, `.opencode`) directories, settings.json hook/permission registration, and post-installation verification.\n\n## Contents\n\n### Core Entry Points\n\n**[index.ts](./index.ts)** — Main orchestrator implementing `runInstaller(args: InstallerArgs): Promise<InstallerResult[]>`. Parses CLI flags via `parseInstallerArgs()` recognizing `--runtime`, `-g/-l`, `-u`, `--force`, `-q`. Routes to `runInstall()` for file copying + hook registration or `runUninstall()` for artifact deletion + deregistration. Delegates to `selectRuntime()`/`selectLocation()` for interactive prompts when flags omitted. Aggregates `InstallerResult[]` from multi-runtime operations (`runtime === 'all'` expands via `getAllRuntimes()`). Formats output via `displayInstallResults()`/`displayUninstallResults()` showing filesCreated/filesSkipped counts, hookRegistered status, `showNextSteps()` workflow guide.\n\n**[operations.ts](./operations.ts)** — Implements `installFiles(runtime, location, options)` writing command templates via `getTemplatesForRuntime()` to `resolveInstallPath()` with `ensureDir()` directory creation. Installs hooks from bundled `hooks/dist/` via `readBundledHook()` + `writeFileSync()` to runtime hooks/plugins directories. Calls `registerHooks()` mutating settings.json with SessionStart/SessionEnd entries (nested format for Claude: `{ hooks: [{ type, command }] }`, flat format for Gemini: `{ name, type, command }`). Calls `registerPermissions()` appending `ARE_PERMISSIONS` bash patterns to `settings.permissions.allow`. Writes `ARE-VERSION` file via `writeVersionFile()` for update checks. Returns `InstallerResult` with filesCreated/filesSkipped/errors arrays, hookRegistered/versionWritten flags. Provides `verifyInstallation(files)` checking `existsSync()` for post-install validation.\n\n**[uninstall.ts](./uninstall.ts)** — Implements `uninstallFiles(runtime, location, dryRun)` removing command templates, hook/plugin files, settings.json entries via `unregisterHooks()`/`unregisterPermissions()`, and `ARE-VERSION`. Delegates to `uninstallFilesForRuntime()` executing four-step removal: delete templates from `getTemplatesForRuntime()`, remove hooks (`ARE_HOOKS` for Claude/Gemini in `hooks/`, `ARE_PLUGIN_FILENAMES` for OpenCode in `plugins/`), deregister via settings.json filtering matching `getHookPatterns()` command patterns, trigger cleanup via `cleanupAreSkillDirs()`/`cleanupEmptyDirs()`/`cleanupLegacyGeminiFiles()`. Provides `deleteConfigFolder(location, dryRun)` removing `.agents-reverse-engineer/` for local uninstalls. Hook deregistration uses `unregisterClaudeHooks()` filtering `settings.hooks.SessionStart/SessionEnd` arrays by command substring match, `unregisterGeminiHooks()` parallel implementation for `GeminiSettingsJson` schema.\n\n### Path Resolution & Detection\n\n**[paths.ts](./paths.ts)** — Exports `getRuntimePaths(runtime)` returning `RuntimePaths` with global (e.g., `~/.claude`), local (`.claude`), settingsFile (`~/.claude/settings.json`) paths. Implements `resolveInstallPath(runtime, location, projectRoot)` joining global path or local path + projectRoot. Provides `getAllRuntimes()` returning `['claude', 'opencode', 'gemini']`. Exports `isRuntimeInstalledLocally()`/`isRuntimeInstalledGlobally()` checking directory existence via `stat()`, `getInstalledRuntimes(projectRoot)` filtering for installed runtimes. Supports environment overrides: `CLAUDE_CONFIG_DIR`, `OPENCODE_CONFIG_DIR` (with `XDG_CONFIG_HOME` fallback), `GEMINI_CONFIG_DIR`.\n\n### Interactive Selection UI\n\n**[prompts.ts](./prompts.ts)** — Exports `isInteractive()` checking `process.stdin.isTTY` for TTY detection. Implements `selectOption<T>(prompt, options)` routing to `arrowKeySelect()` for TTY mode (arrow key navigation with `readline.emitKeypressEvents()`, `process.stdin.setRawMode(true)`, ANSI cursor control) or `numberedSelect()` for non-TTY fallback (numbered list with readline.question()). Provides `selectRuntime(mode)` prompting for `Runtime` selection from `['claude', 'opencode', 'gemini', 'all']`, `selectLocation(mode)` prompting for `Location` from `['global', 'local']`, `confirmAction(message)` returning boolean. Uses module-level `rawModeActive` flag with `cleanupRawMode()` registered via `process.on('exit')` and `process.on('SIGINT')` handlers.\n\n### Output Formatting\n\n**[banner.ts](./banner.ts)** — Exports `displayBanner()` rendering ASCII \"ARE\" logo with version from `getVersion()`. Provides `showHelp()` printing usage syntax, option flags (`--runtime`, `-g/-l`, `-u`, `--force`, `-q`, `-h`), example invocations. Exports semantic message functions: `showSuccess(msg)` with green checkmark, `showError(msg)` with red X, `showWarning(msg)` with yellow exclamation, `showInfo(msg)` with cyan arrow. Implements `showNextSteps(runtime, filesCreated)` displaying workflow guide invoking ARE skills (`/are-help`, `/are-init`, `/are-discover`, `/are-generate`, `/are-update`, `/are-specify`, `/are-clean`) and GitHub docs URL.\n\n### Type Definitions\n\n**[types.ts](./types.ts)** — Defines `Runtime` union `'claude' | 'opencode' | 'gemini' | 'all'`, `Location` union `'global' | 'local'`. Exports `InstallerArgs` interface capturing CLI flags: `runtime`, `global`, `local`, `uninstall`, `force`, `help`, `quiet`. Exports `InstallerResult` with `success`, `runtime`, `location`, `filesCreated`, `filesSkipped`, `errors`, `hookRegistered`, `versionWritten`. Exports `RuntimePaths` with `global`, `local`, `settingsFile` fields.\n\n## Architecture\n\n### File Operation Pipeline\n\n**Install Flow:** `runInstaller()` → `parseInstallerArgs()` → `selectRuntime()`/`selectLocation()` → `installFiles()` → `installFilesForRuntime()` → `getTemplatesForRuntime()` + `ensureDir()` + `writeFileSync()` → `registerHooks()`/`registerPermissions()` → `writeVersionFile()` → `verifyInstallation()` → `displayInstallResults()`.\n\n**Uninstall Flow:** `runInstaller()` → `uninstallFiles()` → `uninstallFilesForRuntime()` → `getTemplatesForRuntime()` + `unlinkSync()` → `unregisterHooks()`/`unregisterPermissions()` → `cleanupAreSkillDirs()`/`cleanupEmptyDirs()`/`cleanupLegacyGeminiFiles()` → `deleteConfigFolder()` → `displayUninstallResults()`.\n\n### Runtime-Specific Adaptations\n\n**Claude:** Commands in `.claude/skills/are-*/SKILL.md` with `name: /are-*` frontmatter. Hooks in `.claude/hooks/` as Node.js scripts. Settings.json with nested hook format `{ hooks: [{ type: 'command', command }] }`. Permissions in `settings.permissions.allow` for bash command auto-approval.\n\n**Gemini:** Commands in `.gemini/commands/*.toml` with `description`/`prompt` fields. Hooks in `.gemini/hooks/` as Node.js scripts. Settings.json with flat hook format `{ name, type: 'command', command }`.\n\n**OpenCode:** Commands in `.opencode/commands/*.md` with `agent: build` frontmatter. Plugins in `.opencode/plugins/` as auto-loaded modules exporting async factory functions returning event handlers (`event['session.created']`, `event['session.deleted']`).\n\n### Settings.json Mutation\n\n**Hook Registration:** Parses existing settings.json via `JSON.parse()`, appends hook definitions to `settings.hooks.SessionStart`/`settings.hooks.SessionEnd` arrays, checks duplicates via command string match, writes via `JSON.stringify(settings, null, 2)`.\n\n**Permission Registration:** Appends `ARE_PERMISSIONS` patterns (`npx agents-reverse-engineer@latest [command]*`, `rm -f .agents-reverse-engineer/progress.log*`, `sleep *`) to `settings.permissions.allow`, removes duplicates via `!arr.includes(pattern)` filter.\n\n**Hook Deregistration:** Filters arrays removing entries matching `getHookPatterns(runtimeDir)` (both current `node ${runtimeDir}/hooks/${filename}` and legacy `node hooks/${filename}` formats), cleans empty arrays/objects via zero-length check.\n\n### Cleanup Strategy\n\n**Empty Directory Removal:** `cleanupEmptyDirs(dirPath)` recursively calls `rmdirSync()` on zero-entry directories, terminates at runtime root (`.claude`, `.opencode`, `.gemini`, `.config`) to prevent deletion of user directories.\n\n**Legacy File Migration:** `cleanupLegacyGeminiFiles(commandsDir)` removes old `are-*.md` and `commands/are/*.toml` files from pre-0.4.0 installations.\n\n**Skill Directory Pruning:** `cleanupAreSkillDirs(skillsDir)` iterates entries matching `are-*` prefix, calls `cleanupEmptyDirs()` on each.\n\n### Hook File Bundling\n\nCommands invoke pre-built hooks from `hooks/dist/` (created by `scripts/build-hooks.js` during `npm run build:hooks`). `getBundledHookPath(hookName)` navigates from `dist/installer/operations.js` → project root → `hooks/dist/${hookName}`. `readBundledHook(hookName)` reads content via `readFileSync()`, throws Error if missing.\n\n## Integration Points\n\n**Template Generation:** Consumes `getClaudeTemplates()`, `getOpenCodeTemplates()`, `getGeminiTemplates()` from `src/integration/templates.ts` for command file content.\n\n**Version Tracking:** Reads package.json version via `getPackageVersion()` using `import.meta.url` navigation, writes to `ARE-VERSION` for session hook update checks.\n\n**CLI Entry Point:** Invoked from top-level `src/cli/index.ts` via argv pattern matching for `--runtime` flag, otherwise treated as generate/update/clean command.\n\n**Session Hooks:** Installed hooks execute `npx agents-reverse-engineer@latest update --quiet` as detached background process when `git status --porcelain` detects changes (see `hooks/are-session-end.js`). Version checks compare `npm view agents-reverse-engineer version` against cached `ARE-VERSION` (see `hooks/are-check-update.js`).\n### src/integration/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/integration\n\n**Detects AI coding assistant environments (Claude Code, OpenCode, Gemini, Aider) via filesystem markers, generates platform-specific command files with frontmatter-wrapped templates, and manages hook installation for session lifecycle integration.**\n\n## Contents\n\n### Environment Detection\n\n**[detect.ts](./detect.ts)** — `detectEnvironments()` scans project root for environment markers (`.claude/`, `CLAUDE.md`, `.opencode/`, `.aider.conf.yml`, `.aider/`) via `existsSync()`, returns `DetectedEnvironment[]` with `type`, `configDir`, `detected` fields; `hasEnvironment()` tests single environment presence.\n\n**[types.ts](./types.ts)** — `EnvironmentType` union (`'claude' | 'opencode' | 'gemini' | 'aider'`), `DetectedEnvironment` interface with detection metadata, `IntegrationTemplate` schema (`filename`, `path`, `content`), `IntegrationResult` tracking `filesCreated`/`filesSkipped` per environment.\n\n### Template Generation\n\n**[templates.ts](./templates.ts)** — `getClaudeTemplates()`, `getOpenCodeTemplates()`, `getGeminiTemplates()` produce command files via `PLATFORM_CONFIGS` mapping (`.claude/skills/`, `.opencode/commands/`, `.gemini/commands/`); `buildFrontmatter()` constructs YAML headers with `name`/`description`/`agent` fields, `buildGeminiToml()` emits TOML format with triple-quoted `prompt`; seven commands (generate, update, init, discover, clean, specify, help) defined in `COMMANDS` constant with shared long-running monitoring pattern (delete stale `progress.log`, spawn background task, poll with Read tool offset, check TaskOutput).\n\n**[generate.ts](./generate.ts)** — `generateIntegrationFiles()` orchestrates template write workflow: invokes `detectEnvironments()` or uses `options.environment` override, routes to `getTemplatesForEnvironment()`, writes files via `writeFileSync()` with `ensureDir()` directory creation, respects `dryRun`/`force` flags; Claude environment receives additional `are-session-end.js` hook copy via `readBundledHook()` from `hooks/dist/`.\n\n## Platform Configuration\n\n`PLATFORM_CONFIGS` in [templates.ts](./templates.ts) maps each `EnvironmentType` to:\n- `commandPrefix` — `/are-` invocation prefix for all platforms\n- `pathPrefix` — Directory structure (`.claude/skills/`, `.opencode/commands/`, `.gemini/commands/`)\n- `filenameSeparator` — Filename joining character (`.` for Claude subdirectories, `-` for flat OpenCode/Gemini)\n- `usesName` — Frontmatter `name` field presence (true for Claude only)\n- `versionFilePath` — Platform-specific version tracking (`.claude/ARE-VERSION`, `.opencode/ARE-VERSION`, `.gemini/ARE-VERSION`)\n- `extraFrontmatter` — Additional YAML fields (`agent: build` for OpenCode)\n\n## File Naming Conventions\n\nClaude uses nested structure: `.claude/skills/are-generate/SKILL.md` (constant `SKILL.md` filename within command subdirectory).\n\nOpenCode and Gemini use flat structure: `.opencode/commands/are-generate.md`, `.gemini/commands/are-generate.toml`.\n\n## Integration Points\n\nConsumed by `src/installer/operations.ts` which prompts runtime selection via `selectRuntimes()` and invokes `generateIntegrationFiles()` with global/local installation mode.\n\nDetection logic powers environment-specific template filtering in `getTemplatesForEnvironment()` (returns empty array for Aider, no command file support).\n\nTemplates embed placeholder replacement (`COMMAND_PREFIX`, `VERSION_FILE_PATH`) applied during `buildTemplate()` construction before content serialization.\n### src/orchestration/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/orchestration\n\nIterator-based concurrency pool executing three-phase AI documentation pipeline (file analysis → directory aggregation → root synthesis) with promise-chain serialization preventing write corruption, NDJSON trace emission for subprocess debugging, and streaming progress with ETA calculation.\n\n## Contents\n\n### Core Orchestration\n\n**[index.ts](./index.ts)** — Barrel export consolidating `runPool`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `createTraceWriter`, `cleanupOldTraces`, `CommandRunner` public API plus shared types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult<T>`, `TraceEvent`, `TraceEventPayload`).\n\n**[runner.ts](./runner.ts)** — `CommandRunner` class orchestrating `executeGenerate(plan: ExecutionPlan)` three-phase pipeline and `executeUpdate(filesToAnalyze: FileChange[])` incremental workflow. Phase 1 runs `runPool()` concurrent file analysis writing `.sum` files via `writeSumFile()`, post-phase-1 executes `checkCodeVsDoc()`/`checkCodeVsCode()` quality validation grouped by directory. Phase 2 processes `directoryTasks` in descending depth order calling `buildDirectoryPrompt()` and `writeAgentsMd()`, post-phase-2 runs `checkPhantomPaths()`. Phase 3 sequentially generates root documents via `buildRootPrompt()` with `stripPreamble()` removing conversational prefixes. Emits `phase:start/end`, `task:start/done` trace events, updates `ProgressReporter` and `PlanTracker`, aggregates token counts into `RunSummary` with quality metrics (`inconsistenciesCodeVsDoc`, `inconsistenciesCodeVsCode`, `phantomPaths`).\n\n**[pool.ts](./pool.ts)** — `runPool<T>(tasks, options, onComplete?)` shared-iterator worker pattern executing `Array<() => Promise<T>>` task factories through concurrency-limited pool, returns `TaskResult<T>[]` indexed by original position. Workers iterate single `tasks.entries()` iterator atomically consuming `[index, task]` pairs preventing batch-induced idling. Supports `failFast` abort via shared mutable flag checked before task pickup. Emits `worker:start/end`, `task:pickup/done` trace events with `activeTasks` counter, normalizes errors via `instanceof Error` check, invokes `onComplete(result)` callback in both success/error branches.\n\n**[types.ts](./types.ts)** — Shared TypeScript interfaces: `FileTaskResult` (path, success, tokensIn/Out, cacheReadTokens, cacheCreationTokens, durationMs, model, error?), `RunSummary` (version, filesProcessed/Failed/Skipped, totalCalls, token counts, totalDurationMs, errorCount, retryCount, totalFilesRead/uniqueFilesRead, inconsistenciesCodeVsDoc/CodeVsCode, phantomPaths, inconsistencyReport?), `ProgressEvent` (discriminated type: start/done/error/dir-done/root-done with conditional filePath, index, total, durationMs?, tokensIn/Out?, model?, error?), `CommandRunOptions` (concurrency, failFast?, debug?, dryRun?, tracer?: ITraceWriter, progressLog?: ProgressLog).\n\n### Progress Reporting\n\n**[progress.ts](./progress.ts)** — `ProgressReporter` class streaming build-log events via `onFileStart()`, `onFileDone()`, `onFileError()`, `onDirectoryStart()`, `onDirectoryDone()`, `onRootDone()`, `printSummary()`. Computes ETA via `formatETA()`/`formatDirectoryETA()` using moving averages of last 10 completion times in `completionTimes[]`/`dirCompletionTimes[]` sliding windows. `ProgressLog` class mirrors output to `.agents-reverse-engineer/progress.log` via promise-chain serialization (`writeQueue = writeQueue.then(...)` pattern), opens file handle in truncate mode ('w') on first write, removes ANSI codes via `stripAnsi()` regex.\n\n**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` class serializing `GENERATION-PLAN.md` checkbox updates preventing concurrent corruption from pool workers. `markDone(itemPath)` replaces `- [ ] \\`${itemPath}\\`` with `- [x]` in-memory, chains `writeFile()` to `writeQueue` promise. `flush()` awaits queue drain before returning. Created by `runner.ts` during `executeGenerate()`, updated per Phase 1/2/3 task completion.\n\n### Tracing\n\n**[trace.ts](./trace.ts)** — `ITraceWriter` interface defining `emit(event: TraceEventPayload)`, `finalize()`, `filePath` contract. `createTraceWriter(projectRoot, enabled)` factory returns `NullTraceWriter` (no-op) when `enabled=false` or `TraceWriter` writing `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson` with promise-chain serialization. `TraceEvent` discriminated union comprising 14 event types: `phase:start/end` (taskCount, concurrency, tasksCompleted/Failed), `worker:start/end` (workerId, tasksExecuted), `task:pickup/done` (taskIndex, taskLabel, success, activeTasks), `task:start` (taskLabel, phase), `subprocess:spawn/exit` (childPid, command, exitCode, signal, timedOut), `retry` (attempt, errorCode), `discovery:start/end` (filesIncluded/Excluded), `filter:applied` (filterName, filesMatched/Rejected), `plan:created` (planType, fileCount), `config:loaded` (configPath, model, concurrency). All events extend `TraceEventBase` with auto-populated `seq`, `ts`, `pid`, `elapsedMs` fields. `TraceEventPayload` type alias equals `DistributiveOmit<TraceEvent, BaseKeys>` requiring callers omit auto-populated fields. `cleanupOldTraces(projectRoot, keepCount=500)` deletes oldest traces exceeding retention limit.\n\n## Architecture\n\n### Shared-Iterator Pool Pattern\n\n`runPool()` prevents batch anti-pattern by sharing single `tasks.entries()` iterator across N workers. Each worker executes tight loop: pickup task → execute → emit result → pickup next, maintaining full slot utilization without idle periods. Workers coordinate via iterator protocol atomicity ensuring each `[index, task]` pair consumed by exactly one worker. Effective concurrency capped at `Math.min(options.concurrency, tasks.length)` preventing unused worker spawns.\n\n### Promise-Chain Serialization\n\n`PlanTracker`, `ProgressLog`, `TraceWriter` use identical pattern: `this.writeQueue = this.writeQueue.then(() => asyncWrite())` serializes concurrent writes from pool workers. Each write updates in-memory state immediately, then appends `writeFile()` promise to chain. Pattern prevents NDJSON corruption and markdown interleaving despite concurrent Phase 1 task completions.\n\n### Three-Phase Pipeline Execution\n\n`CommandRunner.executeGenerate()` orchestrates:\n1. **Pre-Phase-1-Cache** (concurrency=20): Reads existing `.sum` files into `oldSumCache` via throttled pool for stale documentation detection\n2. **Phase-1-Files** (configurable concurrency): Concurrent file analysis via `runPool(fileTasks)`, writes `.sum` with SHA-256 `content_hash`, caches source in `sourceContentCache`\n3. **Post-Phase-1-Quality** (concurrency=10): Groups files by directory, runs `checkCodeVsDoc()` twice (old-doc for staleness, new-doc for LLM omissions), `checkCodeVsCode()` for duplicate symbols\n4. **Phase-2-Dirs-Depth-{N}**: Groups `directoryTasks` by depth via `Map<number, DirectoryTask[]>`, processes descending (deepest first = post-order), per-depth-level concurrency via `Math.min(concurrency, dirsAtDepth.length)`\n5. **Post-Phase-2-Phantom**: Validates path references in `AGENTS.md` via `checkPhantomPaths()` with filesystem resolution\n6. **Phase-3-Root** (sequential): Generates `CLAUDE.md`/`GEMINI.md`/`OPENCODE.md` via `buildRootPrompt()`, strips preamble via pattern matching\n\n### Trace Event Threading\n\n`CommandRunOptions.tracer` parameter threads `ITraceWriter` instance through:\n- `runner.ts` emits `phase:start/end`, `task:start`\n- `pool.ts` emits `worker:start/end`, `task:pickup/done` with `activeTasks` counter\n- `AIService` (via `setTracer()`) emits `subprocess:spawn/exit`, `retry` with exponential backoff metadata\n- Trace events auto-populated with `seq` (monotonic counter), `ts` (ISO 8601), `pid` (process.pid), `elapsedMs` (high-resolution delta from `process.hrtime.bigint()`)\n\n### ETA Calculation\n\n`ProgressReporter` maintains sliding windows `completionTimes[]` (files) and `dirCompletionTimes[]` (directories) storing last 10 task durations. `formatETA()` computes moving average (`sum / length`), multiplies by `remaining = total - completed - failed`, formats as seconds (`~12s remaining`) below 60s or minutes+seconds (`~2m 30s remaining`) above. ETA displayed only after 2+ completions.\n\n## File Relationships\n\n- `runner.ts` constructs `ProgressReporter`, `PlanTracker`, calls `runPool()` passing `tracer` from `options`\n- `pool.ts` emits trace events via `tracer?.emit()` optional chaining, invokes `onComplete()` callback with `TaskResult<T>` discriminated union\n- `PlanTracker`/`ProgressLog`/`TraceWriter` all use promise-chain serialization pattern (`writeQueue = writeQueue.then(...)`)\n- `types.ts` defines shared data structures consumed by `runner.ts`, `progress.ts`, `pool.ts`, threaded through `CommandRunOptions` interface\n- `index.ts` barrel export provides single import point for consumers (`src/cli/generate.ts`, `src/cli/update.ts`)\n\n## Integration Points\n\n**Consumed by:**\n- `../cli/generate.ts` creates `CommandRunner`, calls `executeGenerate()` with `ExecutionPlan` from `../generation/orchestrator.ts`\n- `../cli/update.ts` creates `CommandRunner`, calls `executeUpdate()` with `FileChange[]` from `../change-detection/detector.ts`\n\n**Consumes:**\n- `../ai/service.ts` (`AIService`) for subprocess management via `call()`, `setTracer()`, `getSummary()`\n- `../generation/executor.ts` (`ExecutionPlan`, `ExecutionTask`, `formatExecutionPlanAsMarkdown`) for task definitions\n- `../generation/prompts/builder.ts` (`buildFilePrompt`, `buildDirectoryPrompt`, `buildRootPrompt`) for prompt construction\n- `../generation/writers/sum.ts` (`writeSumFile`, `readSumFile`, `SumFileContent`) for YAML frontmatter `.sum` files\n- `../generation/writers/agents-md.ts` (`writeAgentsMd`) for directory-level aggregation\n- `../quality/inconsistency/code-vs-doc.ts` (`checkCodeVsDoc`), `../quality/inconsistency/code-vs-code.ts` (`checkCodeVsCode`), `../quality/phantom-paths/validator.ts` (`checkPhantomPaths`) for validation\n- `../quality/inconsistency/reporter.ts` (`buildInconsistencyReport`, `formatReportForCli`) for quality metrics\n- `../change-detection/detector.ts` (`computeContentHashFromString`, `FileChange`) for SHA-256 hashing and update workflow\n- `../config/loader.ts` (`CONFIG_DIR`) for `.agents-reverse-engineer/` path resolution\n- `../version.ts` (`getVersion`) for run summary metadata\n### src/output/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/output\n\nTerminal output formatting layer providing colored CLI feedback via `Logger` interface with factory functions for production (colored/uncolored) and testing (silent) modes.\n\n## Contents\n\n**[logger.ts](./logger.ts)** — exports `Logger` interface defining six output methods (`info`, `file`, `excluded`, `summary`, `warn`, `error`), `LoggerOptions` interface for color configuration, `createLogger()` factory using picocolors for ANSI formatting, and `createSilentLogger()` factory returning no-op stubs for testing.\n\n## Architecture\n\n**Conditional Color Formatting**  \n`createLogger()` accepts `LoggerOptions.colors` boolean to toggle between picocolors functions (`green`, `dim`, `red`, `bold`, `yellow`) and identity function passthrough via `noColor` constant. Color functions wrap output strings before passing to `console.log`/`console.warn`/`console.error`.\n\n**Output Method Contracts**  \n- `file(path)` — green \"+\" prefix for discovered files (used by `src/discovery/run.ts`)\n- `excluded(path, reason, filter)` — dim \"-\" prefix with parenthetical reason/filter (used by `src/discovery/filters/`)\n- `summary(included, excluded)` — bold included count + dim excluded count (used by `src/cli/discover.ts`)\n- `warn(message)` — yellow \"Warning:\" prefix (used by `src/ai/telemetry/logger.ts` for cost threshold alerts)\n- `error(message)` — red \"Error:\" prefix (used by `src/cli/` error handlers)\n- `info(message)` — uncolored informational output\n\n**Testing Isolation**  \n`createSilentLogger()` returns `Logger` with all methods mapped to `noop` arrow function, preventing console pollution during test execution. Used by vitest suites in `src/` subdirectories.\n\n## Integration Points\n\n**Consumed By:**\n- `src/cli/index.ts` — instantiates logger via `createLogger({ colors: config.output.colors })`, threads through command handlers\n- `src/discovery/run.ts` — calls `logger.file()` and `logger.excluded()` during file walking\n- `src/ai/telemetry/logger.ts` — calls `logger.warn()` when cumulative cost exceeds `config.ai.telemetry.costThresholdUsd`\n- `src/orchestration/progress.ts` — logs phase start/end, worker pool status, ETA calculations\n- `src/quality/inconsistency/reporter.ts` — emits validation warnings via `logger.warn()`\n\n**Color Configuration Source:**  \n`config.output.colors` (from `.agents-reverse-engineer/config.yaml`, Zod schema in `src/config/schema.ts`)\n\n**Picocolors Dependency:**  \n`ColorFunctions` interface wraps five picocolors exports. Identity function fallback avoids ANSI escape sequences when `colors: false` or terminal lacks color support.\n### src/quality/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality\n\nPost-generation validation suite detecting code-documentation inconsistencies via regex-based export extraction, duplicate symbol tracking, phantom path resolution, and structured reporting with discriminated union types.\n\n## Contents\n\n### Core API\n\n**[index.ts](./index.ts)** — Barrel export aggregating all quality validators (`checkCodeVsDoc`, `checkCodeVsCode`, `checkPhantomPaths`, `validateFindability`) and report builders (`buildInconsistencyReport`, `formatReportForCli`) from subdirectories. Re-exports discriminated union types (`CodeDocInconsistency`, `CodeCodeInconsistency`, `PhantomPathInconsistency`, `Inconsistency`, `InconsistencyReport`) and `FindabilityResult` from `types.ts` and `density/validator.ts`.\n\n**[types.ts](./types.ts)** — Defines discriminated union schema with `InconsistencySeverity` (`'info' | 'warning' | 'error'`), `CodeDocInconsistency` (exports missing from `.sum` summaries), `CodeCodeInconsistency` (duplicate symbols across files), `PhantomPathInconsistency` (unresolvable AGENTS.md path references), `Inconsistency` union type, and `InconsistencyReport` aggregate structure with metadata (timestamp/projectRoot/filesChecked/durationMs) and summary counts by type/severity.\n\n## Subdirectories\n\n**[inconsistency/](./inconsistency/)** — Regex-based validators: `code-vs-doc.ts` extracts exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` and verifies presence in `.sum` summaries via substring search, `code-vs-code.ts` aggregates exports into `Map<symbol, string[]>` to detect duplicates, `reporter.ts` constructs `InconsistencyReport` with type guard iteration and renders plain-text CLI output.\n\n**[phantom-paths/](./phantom-paths/)** — Validates AGENTS.md references: `validator.ts` applies three regex patterns (markdown links, backtick-quoted paths, prose-embedded paths) with six SKIP_PATTERNS exclusions, resolves candidates relative to AGENTS.md directory and project root with `.js`→`.ts` fallback, returns `PhantomPathInconsistency[]` for failed `existsSync()` checks. `index.ts` re-exports `checkPhantomPaths`.\n\n**[density/](./density/)** — Disabled findability validator: `validator.ts` defines `validateFindability()` returning empty array since `SumFileContent.publicInterface` removal, signature preserved for future structured metadata restoration. Exports `FindabilityResult` type with `symbolsTested`/`symbolsFound`/`symbolsMissing`/`score` fields.\n\n## Validation Pipeline\n\n**Code-vs-Doc Consistency:**  \n`extractExports()` applies regex to source content, `checkCodeVsDoc()` verifies all extracted symbols appear in `.sum` summary text via `includes()`, returns `CodeDocInconsistency` with `missingFromDoc[]` arrays for undocumented exports.\n\n**Code-vs-Code Duplicate Detection:**  \n`checkCodeVsCode()` builds symbol-to-paths map via two-pass traversal, filters `exportMap.entries()` for paths.length > 1, returns `CodeCodeInconsistency[]` with `pattern: 'duplicate-export'` and `severity: 'warning'`.\n\n**Phantom Path Resolution:**  \n`checkPhantomPaths()` extracts path-like strings from AGENTS.md via PATH_PATTERNS, applies SKIP_PATTERNS filter, attempts four resolution candidates (AGENTS.md directory, project root, `.ts` fallback), reports `PhantomPathInconsistency` for unresolved references with deduplication via `seen` Set.\n\n**Report Aggregation:**  \n`buildInconsistencyReport()` aggregates `Inconsistency[]` via type guard iteration (`issue.type === 'code-vs-doc'`), computes type/severity counts, wraps in `InconsistencyReport` with metadata. `formatReportForCli()` renders multi-line plain-text with severity tags (`[ERROR]`, `[WARN]`, `[INFO]`) for ANSI color wrapping in `src/output/logger.ts`.\n\n## Integration Points\n\n**Upstream:** `src/cli/generate.ts` and `src/cli/update.ts` call validators after Phase 1 (`.sum` generation) and Phase 2 (AGENTS.md aggregation), pass discovered files/content to `checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`, aggregate results via `buildInconsistencyReport()`.\n\n**Downstream:** Formatted reports from `formatReportForCli()` logged to stderr via `logger.error()` with picocolors wrapping (`pc.red()`, `pc.yellow()`). Metrics written to `.agents-reverse-engineer/progress.log` as `code-vs-doc/code-vs-code inconsistencies: N`.\n\n**Type Dependencies:** Imports `SumFileContent` from `../generation/writers/sum.js` for parsed `.sum` schema, uses `path.resolve()`, `fs.existsSync()` from Node.js stdlib for phantom path resolution.\n\n## Limitations\n\n**Regex-Based Extraction:** Misses destructured exports, namespace exports (`export * from`), dynamic `export {}` statements. Relies on statement-level syntax matching without AST traversal.\n\n**Substring Matching:** `sumText.includes(exportName)` yields false negatives for prose mentions unrelated to API surface (e.g., \"exports data\" matching `exports`). No semantic context analysis.\n\n**No AST Analysis:** Duplicate detection operates on symbol names only, cannot distinguish intentional duplication (facade pattern, barrel re-exports) from conflicts. Legacy `missingFromCode` field in `CodeDocInconsistency` always empty after `publicInterface` removal.\n\n**Disabled Density Validator:** `validateFindability()` inoperative until structured metadata extraction restored to `.sum` frontmatter schema.\n### src/quality/density/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/density\n\nDisabled findability validator that would verify AGENTS.md coverage of exported symbols from `.sum` file metadata (awaiting structured `publicInterface` extraction restoration).\n\n## Contents\n\n**[validator.ts](./validator.ts)** — `validateFindability()` returns empty array since `SumFileContent.publicInterface` removal in schema. Signature preserved: accepts `agentsMdContent` string and `sumFiles` map, would return `FindabilityResult[]` with per-file symbol presence analysis (tested/found/missing arrays, coverage score 0-1). Design: substring search for symbols in AGENTS.md text without LLM inference, contrasts with code-vs-doc's regex-based export extraction from source files.\n\n## Architecture\n\nNon-AI heuristic validator using string matching to compute symbol findability scores. Imports `SumFileContent` from `../../generation/writers/sum.js` for type constraints. Called by `src/quality/index.ts` quality orchestration alongside `code-vs-doc`, `code-vs-code`, `phantom-paths` validators. Disabled state prevents execution until post-processing pass restores structured metadata extraction to `.sum` file frontmatter.\n\n## Exported Interface\n\n**FindabilityResult** — Validation outcome with `filePath`, `symbolsTested`, `symbolsFound`, `symbolsMissing` string arrays, `score` ratio (found/tested).\n\n## Relation to Quality Suite\n\nFourth validator in suite:\n- `code-vs-doc` (regex export extraction vs substring search in summaries)\n- `code-vs-code` (duplicate symbol detection via `Map<symbol, string[]>` aggregation)\n- `phantom-paths` (path resolution via three regex patterns + `existsSync()`)\n- `density` (this module: symbol findability in AGENTS.md from .sum metadata, disabled)\n### src/quality/inconsistency/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/inconsistency\n\nDetects documentation-code mismatches via regex-based export extraction, duplicate symbol tracking, and structured reporting with type-safe inconsistency aggregation.\n\n## Contents\n\n### Export Validators\n\n**[code-vs-doc.ts](./code-vs-doc.ts)**  \nExports `extractExports(sourceContent: string): string[]` using regex `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` to extract identifier names from TypeScript/JavaScript source. Exports `checkCodeVsDoc(sourceContent: string, sumContent: SumFileContent, filePath: string): CodeDocInconsistency | null` which compares extracted symbols against `.sum` file summary text via substring search, returning `CodeDocInconsistency` with `missingFromDoc[]` array when exports lack documentation mentions.\n\n**[code-vs-code.ts](./code-vs-code.ts)**  \nExports `checkCodeVsCode(files: Array<{ path: string; content: string }>): CodeCodeInconsistency[]` which builds `Map<string, string[]>` mapping export names to file paths via two-pass traversal calling `extractExports()` from `code-vs-doc.ts`, flagging symbols appearing in multiple files with `CodeCodeInconsistency` entries containing `pattern: 'duplicate-export'`, `severity: 'warning'`, `files: string[]`. Operates per-directory to avoid false positives across unrelated modules.\n\n### Report Generation\n\n**[reporter.ts](./reporter.ts)**  \nExports `buildInconsistencyReport(issues: Inconsistency[], metadata: { projectRoot: string; filesChecked: number; durationMs: number }): InconsistencyReport` which aggregates discriminated union array into structured report with type counts (`codeVsDoc`, `codeVsCode`, `phantomPaths`) and severity counts (`errors`, `warnings`, `info`) via type guard iteration. Exports `formatReportForCli(report: InconsistencyReport): string` which converts report to plain-text multi-line format with severity tags (`[ERROR]`, `[WARN]`, `[INFO]`) and type-specific detail blocks, enabling ANSI color wrapping at CLI layer (`src/output/logger.ts`).\n\n## Algorithms\n\n**Export Extraction**: Regex `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` with global and multiline flags matches export statements, captures identifier names. Misses destructured exports, namespace exports, dynamic `export {}` statements.\n\n**Duplicate Detection**: Symbol-to-paths map construction via `exportMap.set(name, [...(exportMap.get(name) || []), filePath])`, followed by `Array.from(exportMap.entries()).filter(([_, paths]) => paths.length > 1)` to identify duplicates. No AST analysis to distinguish intentional duplication (facade pattern, barrel re-exports).\n\n**Report Aggregation**: Type guard iteration `issue.type === 'code-vs-doc'` / `'code-vs-code'` / `'phantom-path'` increments type counters. Severity counters increment via `issue.severity === 'error'` / `'warning'` / `'info'` checks. Total computed as `issues.length`.\n\n## Integration Points\n\n**Upstream**: `src/quality/index.ts` validators (`validateCodeDocConsistency`, `validateCodeCodeConsistency`) call `checkCodeVsDoc()` and `checkCodeVsCode()` with file content arrays, then pass collected `Inconsistency[]` to `buildInconsistencyReport()`.\n\n**Downstream**: Formatted reports from `formatReportForCli()` consumed by `src/cli/generate.ts` and `src/cli/update.ts` for stderr output with ANSI color wrapping via `pc.yellow()`, `pc.red()` from `src/output/logger.ts`.\n\n**Type Dependencies**: Imports `SumFileContent` from `../../generation/writers/sum.js` (parsed `.sum` file schema), `CodeDocInconsistency`, `CodeCodeInconsistency`, `Inconsistency`, `InconsistencyReport` from `../types.js` (discriminated union members and aggregate schema).\n\n## Limitations\n\n**Regex-Based Extraction**: Misses complex patterns (destructured, namespace, dynamic exports), relies on statement-level syntax matching without AST traversal.\n\n**Substring Matching**: `sumText.includes(exportName)` yields false negatives when symbols appear in prose unrelated to API documentation. No context-aware semantic analysis.\n\n**No AST Analysis**: Duplicate detection operates on symbol names only, cannot distinguish intentional duplication (facade pattern, barrel re-exports) from accidental conflicts.\n\n**Missing Obsolete Detection**: `code-vs-doc.ts` does not detect documentation for removed exports (`missingFromCode` field always empty array, retained for legacy `publicInterface` schema compatibility).\n### src/quality/phantom-paths/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/phantom-paths\n\nValidates AGENTS.md files for unresolvable path references by extracting path-like strings via regex patterns (markdown links, backtick-quoted paths, prose-embedded paths), resolving them against filesystem locations with .ts/.js fallback, and reporting PhantomPathInconsistency objects for references that fail existsSync() checks.\n\n## Contents\n\n**[validator.ts](./validator.ts)** — Exports `checkPhantomPaths(agentsMdPath, content, projectRoot)` which applies PATH_PATTERNS regex array (three patterns for markdown links, backtick-quoted paths, and prose-embedded paths), SKIP_PATTERNS filter (six exclusions for node_modules/git/URLs/templates), multi-level resolution strategy (relative to AGENTS.md directory, relative to projectRoot, .js→.ts fallback for TypeScript imports), and returns PhantomPathInconsistency[] with deduplication via `seen` Set.\n\n**[index.ts](./index.ts)** — Barrel export re-exporting `checkPhantomPaths` from `./validator.js` as single import surface for `src/quality/index.ts` orchestrator.\n\n## Path Extraction\n\nPATH_PATTERNS captures three reference types:\n- Markdown links: `/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g` matches `[text](./path)` targets\n- Backtick-quoted: `` /`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g `` matches paths starting with `src/`, `./`, `../` with 1-4 letter extension\n- Prose-embedded: `/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi` matches paths after contextual keywords\n\nSKIP_PATTERNS excludes false positives: `node_modules/`, `.git/`, URLs (`^https?:`), template placeholders (`{{`, `${`), brace expansion (`{a,b}`).\n\n## Resolution Strategy\n\nMulti-candidate resolution for each extracted path:\n1. `path.resolve(agentsMdDir, rawPath)` — resolve relative to AGENTS.md location\n2. `path.resolve(projectRoot, rawPath)` — resolve relative to project root\n3. Strip `.js` extension, append `.ts` — TypeScript import convention (two additional candidates)\n4. First candidate passing `existsSync()` check succeeds, otherwise PhantomPathInconsistency reported\n\n## Inconsistency Structure\n\nPhantomPathInconsistency contains:\n- `type: 'phantom-path'`, `severity: 'warning'`\n- `agentsMdPath` (relative to projectRoot)\n- `description` with double-quoted rawPath\n- `details.referencedPath` (original regex capture), `details.resolvedTo` (first resolution attempt), `details.context` (trimmed line, max 120 chars)\n\nDeduplication via `seen` Set prevents duplicate reports for identical rawPath values.\n\n## Integration\n\nConsumed by `src/quality/index.ts` which aggregates `checkPhantomPaths`, `checkCodeVsDoc`, `checkCodeVsCode` into unified InconsistencyReport. Called during generate/update workflows from `src/cli/generate.ts` and `src/cli/update.ts` with all discovered AGENTS.md files.\n### src/specify/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/specify\n\nSynthesizes project specifications from AGENTS.md corpus through prompt construction (`buildSpecPrompt()`), AI invocation by CLI orchestrator, and filesystem output via `writeSpec()` with single-file/multi-file modes.\n\n## Contents\n\n### Core Modules\n\n**[prompts.ts](./prompts.ts)** — Prompt engineering infrastructure exporting `buildSpecPrompt(docs: AgentsDocs): SpecPrompt` to construct system/user prompt pairs from collected AGENTS.md files. System prompt (`SPEC_SYSTEM_PROMPT`) enforces concern-based organization (not directory mirroring) with nine mandatory sections: Project Overview (tech stack versions), Architecture (module boundaries, data flow), Public API Surface (full type signatures), Data Structures & State (schemas, state management), Configuration (Zod schemas, env vars), Dependencies (exact versions with rationale), Behavioral Contracts (error types, retry logic, concurrency), Test Contracts (per-module scenarios), Build Plan (phased implementation with dependency ordering). User prompt concatenates AGENTS.md content via `### ${relativePath}` sections and appends Output Requirements reiterating raw markdown constraint.\n\n**[writer.ts](./writer.ts)** — Filesystem writer exporting `writeSpec(content: string, options: WriteSpecOptions): Promise<string[]>` orchestrating single-file (`specs/SPEC.md`) vs. multi-file (`specs/<slug>.md`) output modes. Multi-file mode splits on top-level `# ` headings via `splitByHeadings()` regex (`/^(?=# )/m` positive lookahead), generates slugified filenames from heading text via `slugify()` lowercase+hyphen transform (`/\\s+/g → '-'`, `/[^a-z0-9-]/g → ''`). Pre-checks all target paths for existence before writing (atomic conflict detection), throws `SpecExistsError` with `paths[]` array if `force=false`. Creates parent directories via `mkdir({ recursive: true })`, returns absolute paths of written files.\n\n**[index.ts](./index.ts)** — Barrel export re-exporting `buildSpecPrompt()`, `SpecPrompt`, `writeSpec()`, `WriteSpecOptions`, `SpecExistsError` for consumption by `src/cli/specify.ts` command.\n\n## Data Flow\n\n1. **Specification synthesis** (`src/cli/specify.ts`) calls `collectAgentsDocs()` to recursively traverse project tree loading all `AGENTS.md` files with content and relative paths\n2. **Prompt construction** via `buildSpecPrompt(docs)` aggregates markdown sections into user prompt, pairs with `SPEC_SYSTEM_PROMPT` system instructions\n3. **AI invocation** by CLI orchestrator passes `SpecPrompt` to `AIService.call()`, receives synthesized specification markdown\n4. **Output writing** via `writeSpec(response, { outputPath, force, multiFile })` writes single spec or splits/slugifies into directory-per-heading structure\n5. **Error handling** catches `SpecExistsError` on overwrite protection failures, displays conflicting paths with `--force` hint\n\n## Architecture Constraints\n\nPrompt engineering prohibits directory-mirroring section structure, mandates MODULE BOUNDARY descriptions over file path prescriptions, requires exact symbol name preservation, enforces full type signatures with generics/parameters/return types, demands version numbers for all external dependencies, and constrains Build Plan to phased dependency ordering without file path prescription.\n\n## Integration Points\n\nConsumed by `src/cli/specify.ts` implementing `/are-specify` command. Receives `AgentsDocs` type from `../generation/collector.js` containing array of `{ relativePath, content }` objects. Invokes AI backend via `AIService` from `../ai/service.ts` with constructed prompts. Filesystem operations via `node:fs/promises` (`writeFile`, `mkdir`, `access`) with no external npm dependencies.\n### src/types/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/types\n\nShared type definitions for file discovery results, exclusion metadata, and discovery statistics consumed by the discovery pipeline, orchestration runners, and CLI commands.\n\n## Contents\n\n### [index.ts](./index.ts)\nExports `ExcludedFile` (path + exclusion reason), `DiscoveryResult` (included files array + excluded file metadata), and `DiscoveryStats` (metrics with `totalFiles`, `includedFiles`, `excludedFiles`, `exclusionReasons` histogram).\n\n## Exported Types\n\n**ExcludedFile**\n- `path: string` — Absolute or relative file path\n- `reason: string` — Exclusion cause (gitignore pattern, binary file, vendor directory)\n\n**DiscoveryResult**\n- `files: string[]` — Files approved for analysis (passed filter chain)\n- `excluded: ExcludedFile[]` — Rejected files with exclusion metadata\n\n**DiscoveryStats**\n- `totalFiles: number` — Sum of included + excluded files\n- `includedFiles: number` — Count passing all filters\n- `excludedFiles: number` — Count rejected by any filter\n- `exclusionReasons: Record<string, number>` — Aggregated reason histogram mapping exclusion causes to counts\n\n## Usage Across Modules\n\n**Producers:**\n- `src/discovery/run.ts` → `discoverFiles()` populates `DiscoveryResult` from `DirectoryWalker` output\n\n**Consumers:**\n- `src/orchestration/runner.ts` → `runGenerationPhase()` converts `DiscoveryResult.files` to task queue for Phase 1 worker pool\n- `src/cli/discover.ts` → Computes `DiscoveryStats` from `DiscoveryResult.excluded` for GENERATION-PLAN.md output\n- `src/generation/orchestrator.ts` → Ingests `files[]` for concurrent `.sum` file generation\n\n**Related types:**\n- `src/discovery/types.ts` — `DirectoryWalker`, `FileFilter` interfaces\n- `src/orchestration/types.ts` — `Task`, `WorkerPoolOptions` abstractions\n- `src/config/schema.ts` — `ConfigSchema` defining filter behavior (vendor directories, binary extensions, exclude patterns)\n### src/update/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/update\n\n**Incremental documentation update system comparing SHA-256 content hashes from `.sum` frontmatter against current file content, regenerating only modified files and affected `AGENTS.md` directories while cleaning orphaned artifacts from deletions and renames.**\n\n## Contents\n\n### Core Orchestration\n\n**[index.ts](./index.ts)** — Barrel export exposing `UpdateOrchestrator`, `createUpdateOrchestrator()`, cleanup utilities (`cleanupOrphans`, `cleanupEmptyDirectoryDocs`, `getAffectedDirectories`), and type definitions (`UpdatePlan`, `UpdateOptions`, `UpdateResult`, `UpdateProgress`, `CleanupResult`) for incremental update workflow coordination.\n\n**[orchestrator.ts](./orchestrator.ts)** — `UpdateOrchestrator` class implementing frontmatter-based change detection via `preparePlan()`: reads YAML `content_hash` from `.sum` files via `readSumFile()`, compares against `computeContentHash()` SHA-256 output, classifies files into `filesToAnalyze[]` (hash mismatch/missing) or `filesToSkip[]` (hash match), calls `cleanupOrphans()` for stale artifacts, invokes `getAffectedDirectories()` for directory regeneration scope, emits `phase:start/end` trace events with plan metadata.\n\n**[orphan-cleaner.ts](./orphan-cleaner.ts)** — `cleanupOrphans()` deletes `.sum` files for deleted/renamed sources via `deleteIfExists()`, `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` from directories with no remaining source files (filters out hidden files, `.sum` suffixes, `GENERATED_FILES` Set), `getAffectedDirectories()` walks parent directory tree collecting paths requiring `AGENTS.md` regeneration, returns `CleanupResult` with `deletedSumFiles[]` and `deletedAgentsMd[]` arrays.\n\n**[types.ts](./types.ts)** — `UpdateOptions` interface with `includeUncommitted` and `dryRun` flags, `UpdateResult` containing `analyzedFiles[]`, `skippedFiles[]`, `cleanup`, `regeneratedDirs[]`, commit SHAs, `UpdateProgress` callback interface with `onFileStart/Done/Cleanup/DirRegenerate` hooks, `CleanupResult` with deletion arrays.\n\n## Architecture\n\n### Hash-Based Change Detection\n\nReplaces git-based diffing with SHA-256 content hash comparison stored in `.sum` YAML frontmatter. `UpdateOrchestrator.preparePlan()` iterates `discoverFiles()` output, reads each `.sum` file's `contentHash` field, computes current hash via `computeContentHash()`, pushes to `filesToAnalyze` with `status: 'modified'` on mismatch or `status: 'added'` when `.sum` missing, pushes to `filesToSkip` on hash match. No external state database — hash embedded in frontmatter enables stateless operation.\n\n### Orphan Management\n\n`cleanupOrphans()` accepts `FileChange[]` array with discriminated `status` field: iterates changes filtering `status === 'deleted'` or `status === 'renamed'`, deletes `.sum` at original path (using `oldPath` for renames), collects affected directories via `path.dirname()`, calls `cleanupEmptyDirectoryDocs()` for each directory. Empty directory check scans `readdir()` filtering hidden files (`.` prefix), `.sum` suffixes, `GENERATED_FILES` Set (`AGENTS.md`, `CLAUDE.md`), deletes `AGENTS.md` when no source files remain.\n\n### Affected Directory Propagation\n\n`getAffectedDirectories()` walks parent directory tree for each non-deleted `FileChange`: iterates `path.dirname()` until reaching `.` or absolute path, adds all parent paths including root to `Set<string>`. Returns unique directory paths requiring `AGENTS.md` regeneration. Orchestrator sorts by depth descending via `split(path.sep).length` to ensure post-order traversal (children before parents).\n\n## File Relationships\n\n**index.ts** re-exports `UpdateOrchestrator` and `createUpdateOrchestrator()` from orchestrator.ts, cleanup functions from orphan-cleaner.ts, types from types.ts — consumed by `src/cli/update.ts` command handler.\n\n**orchestrator.ts** imports `readSumFile()` and `getSumPath()` from `src/generation/writers/sum.ts` for YAML frontmatter parsing, `computeContentHash()` from `src/change-detection/index.ts` for SHA-256 hashing, `cleanupOrphans()` and `getAffectedDirectories()` from orphan-cleaner.ts for stale artifact removal, `discoverFiles()` from `src/discovery/run.ts` for gitignore-aware file walking, emits trace events via `ITraceWriter` from `src/orchestration/trace.ts`.\n\n**orphan-cleaner.ts** accepts `FileChange` from `src/change-detection/types.ts` with `status`/`oldPath` fields, returns `CleanupResult` from types.ts, uses `fs.stat()/unlink()/readdir()` for filesystem operations with `dryRun` preview support.\n\n**types.ts** defines workflow contracts — `UpdateOptions` configures execution, `UpdateResult` captures outcome with file arrays and commit SHAs, `UpdateProgress` provides streaming callback hooks, `CleanupResult` summarizes deletion operations.\n\n## Integration Points\n\nConsumed by `src/cli/update.ts`: instantiates `UpdateOrchestrator` via `createUpdateOrchestrator()`, calls `preparePlan()` to compute `UpdatePlan`, passes `filesToAnalyze` to Phase 1 file analysis pool from `src/orchestration/pool.ts`, passes `affectedDirs` to Phase 2 directory aggregation from `src/generation/orchestrator.ts`, reports progress via `src/orchestration/progress.ts`, logs telemetry via `src/ai/telemetry/logger.ts`.\n\nDepends on `src/generation/writers/sum.ts` for `.sum` file format knowledge (YAML frontmatter with `content_hash` field), `src/change-detection/detector.ts` for `computeContentHash()` SHA-256 implementation, `src/discovery/run.ts` for file discovery with gitignore/binary/vendor filters.\n\n## Output Requirements\n\nThe specification MUST include these sections in order:\n1. Project Overview (purpose, value, tech stack)\n2. Architecture (module boundaries, data flow, design decisions)\n3. Public API Surface (all exported interfaces, full type signatures)\n4. Data Structures & State (types, schemas, config objects)\n5. Configuration (options, types, defaults, validation)\n6. Dependencies (each with version and rationale)\n7. Behavioral Contracts (error handling, concurrency, lifecycle)\n8. Test Contracts (per-module test scenarios and edge cases)\n9. Build Plan (phased implementation order with dependencies)\n\nOutput ONLY the markdown content. No preamble.",
      "systemPrompt": "You produce software specifications from documentation.\n\nTASK:\nGenerate a comprehensive specification document from the provided AGENTS.md content. The specification must contain enough detail for an AI agent to reconstruct the entire project from scratch without seeing the original source code.\n\nAUDIENCE: AI agents (LLMs) — use structured, precise, instruction-oriented language. Every statement should be actionable.\n\nORGANIZATION (MANDATORY):\nGroup content by CONCERN, not by directory structure. Use these conceptual sections in order:\n\n1. Project Overview — purpose, core value proposition, problem solved, technology stack with versions\n2. Architecture — system design, module boundaries, data flow patterns, key design decisions and their rationale\n3. Public API Surface — all exported interfaces, function signatures with full parameter and return types, type definitions, error contracts\n4. Data Structures & State — key types, schemas, config objects, state management patterns, serialization formats\n5. Configuration — all config options with types, defaults, validation rules, environment variables\n6. Dependencies — each external dependency with exact version and rationale for inclusion\n7. Behavioral Contracts — error handling strategies, retry logic, concurrency model, lifecycle hooks, resource management\n8. Test Contracts — what each module's tests should verify: scenarios, edge cases, expected behaviors, error conditions\n9. Build Plan — phased implementation sequence: what to build first and why, dependency order between modules, incremental milestones\n\nRULES:\n- Describe MODULE BOUNDARIES and their interfaces — not file paths or directory layouts\n- Use exact function, type, and constant names as they appear in the documentation\n- Include FULL type signatures for all public APIs (parameters, return types, generics)\n- Do NOT prescribe exact filenames or file paths — describe what each module does and exports\n- Do NOT mirror the project's folder structure in your section organization\n- Do NOT use directory names as section headings\n- Include version numbers for ALL external dependencies\n- The Build Plan MUST list implementation phases with explicit dependency ordering\n- Each Build Plan phase must state what it depends on and what it enables\n- Behavioral Contracts must specify exact error types/codes and when they are thrown\n\nOUTPUT: Raw markdown. No preamble. No meta-commentary. No \"Here is...\" or \"I've generated...\" prefix.",
      "response": "# Project Specification: agents-reverse-engineer\n\n## 1. Project Overview\n\n**Purpose:** Automate brownfield codebase documentation for AI coding assistants through parallel file analysis, hierarchical aggregation, and platform-specific synthesis.\n\n**Core Value Proposition:** Solves AI assistant session amnesia by generating persistent, AI-optimized documentation corpus (`.sum` summaries, `AGENTS.md` hierarchies, root integration documents) from arbitrary codebases without manual annotation.\n\n**Problem Solved:** Eliminates repetitive codebase re-explanation across AI assistant sessions by maintaining incremental documentation synchronized with source changes via SHA-256 content hashing.\n\n**Technology Stack:**\n- **Runtime:** Node.js ≥18.0.0 (native ES modules, `import.meta.url`, top-level await)\n- **Language:** TypeScript 5.7.3 (ES2022 target, NodeNext module resolution, strict mode)\n- **Core Libraries:**\n  - `fast-glob` 3.x — file discovery with glob patterns and dotfile support\n  - `ignore` 5.x — gitignore parsing engine\n  - `isbinaryfile` 5.x — content-based binary detection\n  - `simple-git` 3.x — git diff parsing with rename detection\n  - `yaml` 2.x — YAML serialization without comments\n  - `zod` 3.x — runtime schema validation with type inference\n  - `ora` 8.x — terminal spinner UI\n  - `picocolors` 1.x — ANSI color codes without dependencies\n- **Development:** `tsx` (watch mode), `vitest` (testing), `@types/node` (type definitions)\n- **Distribution:** npm with provenance attestation via GitHub Actions OIDC\n\n## 2. Architecture\n\n### System Design: Three-Phase Recursive Language Model (RLM) Pipeline\n\n**Phase 1: Concurrent File Analysis**\n- Worker pool executes file-level analysis tasks in parallel (configurable concurrency: 2-20)\n- Each worker invokes AI CLI subprocess via `execFile()` with prompt containing source code and import context\n- Subprocess returns markdown summary parsed from JSON response\n- Results written to `.sum` files with YAML frontmatter embedding SHA-256 content hash\n\n**Phase 2: Post-Order Directory Aggregation**\n- Directories sorted by depth descending (deepest first) for bottom-up traversal\n- Aggregation waits for all child `.sum` files to exist before processing directory\n- Prompts include child summaries, manifest detection (9 package managers), import maps\n- Outputs `AGENTS.md` files preserving user content via `AGENTS.local.md` prepending\n\n**Phase 3: Sequential Root Synthesis**\n- Collects all `AGENTS.md` files via recursive traversal\n- Generates platform-specific integration documents (Claude, Gemini, OpenCode)\n- Enforces synthesis-only constraint: no invention, all claims traceable to source documents\n\n### Module Boundaries\n\n**`src/cli/`** — Command routing and argument parsing, creates orchestrators, threads trace writers and progress loggers\n**`src/ai/`** — Backend-agnostic subprocess management, retry logic, telemetry accumulation\n**`src/discovery/`** — File walking with composable filter chain (gitignore → vendor → binary → custom)\n**`src/generation/`** — Prompt construction, task dependency resolution, YAML frontmatter serialization\n**`src/orchestration/`** — Iterator-based worker pool, progress tracking, NDJSON trace emission\n**`src/update/`** — Hash-based change detection, orphan cleanup, affected directory propagation\n**`src/quality/`** — Post-generation validators for code-doc consistency, duplicate symbols, phantom paths\n**`src/config/`** — Zod schema validation, YAML parsing, resource-aware concurrency defaults\n**`src/imports/`** — Regex-based import extraction, classification into internal/external\n**`src/installer/`** — npx-driven command installation with hook registration mutating settings.json\n**`src/integration/`** — Platform detection and template generation for IDE command systems\n\n### Data Flow Patterns\n\n**Discovery → Planning → Execution:**\n```\ndiscoverFiles() → ExecutionPlan → runPool() → writeSumFile()\n                              ↓\n                     buildExecutionPlan() (dependency ordering)\n                              ↓\n                     Phase 1: fileTasks (concurrent)\n                     Phase 2: directoryTasks (post-order by depth)\n                     Phase 3: rootTasks (sequential)\n```\n\n**Incremental Update:**\n```\npreparePlan() → readSumFile(content_hash) → computeContentHash()\n            ↓\n  filesToAnalyze (hash mismatch/missing)\n  filesToSkip (hash match)\n  orphans (deleted/renamed sources)\n            ↓\n  regenerate .sum → regenerate AGENTS.md → cleanupOrphans()\n```\n\n**Subprocess Invocation:**\n```\nAIService.call() → withRetry() → runSubprocess() → execFile()\n                                              ↓\n                              stdin.write(prompt) → parse JSON response\n                                              ↓\n                          TelemetryLogger.addEntry() → TraceWriter.emit()\n```\n\n### Key Design Decisions\n\n**1. Iterator-Based Pool Over Batch Processing**\n- **Decision:** Single shared `tasks.entries()` iterator across N workers\n- **Rationale:** Prevents batch anti-pattern where workers idle waiting for slowest batch member\n- **Alternative Rejected:** Pre-partitioning tasks into N batches (inefficient slot utilization)\n\n**2. Hash-Based Change Detection Over Git Diffing**\n- **Decision:** SHA-256 content hashes embedded in `.sum` YAML frontmatter\n- **Rationale:** Stateless operation without external database, works in non-git environments\n- **Alternative Rejected:** Git diff comparison (requires versioned repository, complex merge handling)\n\n**3. Subprocess Per File Over Single Long-Running Process**\n- **Decision:** Spawn AI CLI subprocess for each file analysis\n- **Rationale:** Isolates crashes, enforces memory limits, prevents context leakage\n- **Alternative Rejected:** Persistent subprocess with JSON-RPC (complex state management, memory accumulation)\n\n**4. Promise-Chain Serialization Over Locks**\n- **Decision:** `writeQueue = writeQueue.then(() => writeFile())` pattern\n- **Rationale:** Async-friendly serialization without blocking primitives, preserves NDJSON line order\n- **Alternative Rejected:** Mutex-based locking (blocking, no async/await support in Node.js stdlib)\n\n**5. Regex-Based Import Extraction Over AST Parsing**\n- **Decision:** Single regex pattern with five capture groups\n- **Rationale:** Fast, zero-dependency, covers 95% of CommonJS/ESM patterns\n- **Alternative Rejected:** Full AST parsing (heavy dependencies, performance overhead for metadata-only use case)\n\n## 3. Public API Surface\n\n### CLI Commands\n\n**`are init`**\n```typescript\nfunction initCommand(args: ParsedArgs): Promise<void>\n// Creates .agents-reverse-engineer/config.yaml\n// Exits with code 1 on permission errors (EACCES/EPERM)\n```\n\n**`are discover`**\n```typescript\nfunction discoverCommand(args: ParsedArgs): Promise<void>\n// Writes GENERATION-PLAN.md with three-phase breakdown\n// Emits discovery:start/end trace events\n```\n\n**`are generate`**\n```typescript\nfunction generateCommand(args: ParsedArgs): Promise<void>\n// Exit codes: 0 (success), 1 (partial failure), 2 (total failure)\n// Flags: --dry-run, --concurrency N, --debug, --trace, --fail-fast\n```\n\n**`are update`**\n```typescript\nfunction updateCommand(args: ParsedArgs): Promise<void>\n// Flags: --uncommitted (include working tree changes)\n// Returns UpdateResult with analyzedFiles[], skippedFiles[], cleanup\n```\n\n**`are specify`**\n```typescript\nfunction specifyCommand(args: ParsedArgs): Promise<void>\n// Flags: --multi-file, --force, --output <path>\n// Throws SpecExistsError when target exists without --force\n```\n\n**`are clean`**\n```typescript\nfunction cleanCommand(args: ParsedArgs): Promise<void>\n// Deletes .sum, AGENTS.md (generated only), CLAUDE.md, GENERATION-PLAN.md\n// Restores AGENTS.local.md → AGENTS.md\n```\n\n### Core Types\n\n**`Config`**\n```typescript\ninterface Config {\n  exclude: {\n    patterns: string[];          // Gitignore-style globs\n    vendorDirs: string[];        // Third-party directory names\n    binaryExtensions: string[];  // File extensions without leading dot\n  };\n  options: {\n    followSymlinks: boolean;     // Default: false\n    maxFileSize: number;         // Bytes, default: 1048576 (1MB)\n  };\n  output: {\n    colors: boolean;             // ANSI color codes, default: true\n  };\n  ai: {\n    backend: 'claude' | 'gemini' | 'opencode' | 'auto';\n    model: string | null;        // Override backend default\n    timeoutMs: number;           // Subprocess timeout, min: 1\n    maxRetries: number;          // Exponential backoff attempts, min: 0\n    concurrency: number;         // Worker pool size, range: [1, 20]\n    telemetry: {\n      enabled: boolean;\n      keepRuns: number;          // Retention limit, min: 0\n      costThresholdUsd: number;  // Warning threshold\n    };\n    pricing: {\n      [backend: string]: {\n        inputCostPer1kTokens: number;\n        outputCostPer1kTokens: number;\n        cacheReadCostPer1kTokens: number;\n        cacheCreationCostPer1kTokens: number;\n      };\n    };\n  };\n}\n```\n\n**`AIBackend`**\n```typescript\ninterface AIBackend {\n  name: string;                  // 'claude' | 'gemini' | 'opencode'\n  cliCommand: string;            // Executable name for PATH resolution\n  isAvailable(): Promise<boolean>;\n  buildArgs(options: AICallOptions): string[];\n  parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse;\n  getInstallInstructions(): string;\n}\n```\n\n**`AICallOptions`**\n```typescript\ninterface AICallOptions {\n  prompt: string;\n  systemPrompt?: string;\n  model?: string;\n  timeoutMs?: number;\n  maxTurns?: number;\n  taskLabel?: string;           // For trace correlation\n}\n```\n\n**`AIResponse`**\n```typescript\ninterface AIResponse {\n  text: string;\n  model: string;\n  inputTokens: number;\n  outputTokens: number;\n  cacheReadTokens: number;\n  cacheCreationTokens: number;\n  durationMs: number;\n  exitCode: number;\n  raw: string;                  // Unparsed stdout\n}\n```\n\n**`FileChange`**\n```typescript\ntype FileChange = \n  | { status: 'added'; path: string }\n  | { status: 'modified'; path: string }\n  | { status: 'deleted'; path: string }\n  | { status: 'renamed'; path: string; oldPath: string };\n```\n\n**`ExecutionPlan`**\n```typescript\ninterface ExecutionPlan {\n  tasks: ExecutionTask[];\n  fileTasks: ExecutionTask[];\n  directoryTasks: ExecutionTask[];\n  rootTasks: ExecutionTask[];\n  directoryFileMap: Record<string, string[]>;\n}\n\ninterface ExecutionTask {\n  id: string;                   // 'file:path' | 'dir:path' | 'root:CLAUDE.md'\n  type: 'file' | 'directory' | 'root';\n  dependencies: string[];        // Task IDs\n  systemPrompt: string;\n  userPrompt: string;\n  outputPath: string;\n  metadata?: {\n    depth?: number;\n    directoryFiles?: string[];\n  };\n}\n```\n\n**`SumFileContent`**\n```typescript\ninterface SumFileContent {\n  generatedAt: string;          // ISO 8601 timestamp\n  contentHash: string;          // SHA-256 hex digest\n  purpose: string;\n  criticalTodos?: string[];\n  relatedFiles?: string[];\n  summary: string;              // Markdown content after frontmatter\n}\n```\n\n**`TraceEvent`** (discriminated union with 14 types)\n```typescript\ntype TraceEvent = \n  | { type: 'phase:start'; phase: string; taskCount: number; concurrency: number }\n  | { type: 'phase:end'; phase: string; tasksCompleted: number; tasksFailed: number; durationMs: number }\n  | { type: 'worker:start'; workerId: number }\n  | { type: 'worker:end'; workerId: number; tasksExecuted: number; durationMs: number }\n  | { type: 'task:pickup'; taskIndex: number; taskLabel: string; activeTasks: number }\n  | { type: 'task:done'; taskIndex: number; taskLabel: string; success: boolean; activeTasks: number; durationMs: number }\n  | { type: 'task:start'; taskLabel: string; phase: string }\n  | { type: 'subprocess:spawn'; childPid: number; command: string; args: string[] }\n  | { type: 'subprocess:exit'; childPid: number; exitCode: number; signal: string | null; timedOut: boolean; durationMs: number }\n  | { type: 'retry'; attempt: number; taskLabel: string; errorCode: string; delayMs: number }\n  | { type: 'discovery:start' }\n  | { type: 'discovery:end'; filesIncluded: number; filesExcluded: number; durationMs: number }\n  | { type: 'filter:applied'; filterName: string; filesMatched: number; filesRejected: number }\n  | { type: 'plan:created'; planType: string; fileCount: number }\n  | { type: 'config:loaded'; configPath: string; model: string; concurrency: number };\n\n// All events automatically enriched with:\ninterface TraceEventBase {\n  seq: number;                  // Monotonic counter\n  ts: string;                   // ISO 8601 timestamp\n  pid: number;                  // process.pid\n  elapsedMs: number;            // High-resolution delta from start\n}\n```\n\n### Exported Functions\n\n**Discovery:**\n```typescript\nfunction discoverFiles(root: string, config: DiscoveryConfig, options?: { tracer?: ITraceWriter; debug?: boolean }): Promise<FilterResult>\n\ninterface FilterResult {\n  included: string[];           // Absolute paths passing all filters\n  excluded: ExcludedFile[];     // { path, reason, filter }\n}\n```\n\n**Configuration:**\n```typescript\nfunction loadConfig(root: string, options?: { tracer?: ITraceWriter; debug?: boolean }): Promise<Config>\nfunction configExists(root: string): Promise<boolean>\nfunction writeDefaultConfig(root: string): Promise<void>\nfunction getDefaultConcurrency(): number  // CPU/memory-aware calculation\n```\n\n**Generation:**\n```typescript\nfunction buildFilePrompt(context: PromptContext): { systemPrompt: string; userPrompt: string }\nfunction buildDirectoryPrompt(directoryPath: string, projectRoot: string, existingAgentsMd?: string): Promise<{ systemPrompt: string; userPrompt: string }>\nfunction buildRootPrompt(projectRoot: string): Promise<{ systemPrompt: string; userPrompt: string }>\n\ninterface PromptContext {\n  filePath: string;\n  content: string;\n  contextFiles?: Array<{ path: string; content: string }>;\n  projectPlan?: string;\n  existingSum?: string;         // Triggers update-specific prompt\n}\n```\n\n**Writers:**\n```typescript\nfunction writeSumFile(filePath: string, summary: string, metadata: SummaryMetadata): Promise<void>\nfunction readSumFile(sumPath: string): SumFileContent | null\nfunction getSumPath(filePath: string): string\nfunction sumFileExists(filePath: string): boolean\nfunction writeAgentsMd(directoryPath: string, content: string): Promise<void>\n```\n\n**Change Detection:**\n```typescript\nfunction getChangedFiles(baseCommit: string, options?: { includeUncommitted?: boolean }): Promise<ChangeDetectionResult>\nfunction computeContentHash(filePath: string): Promise<string>\nfunction computeContentHashFromString(content: string): string\n\ninterface ChangeDetectionResult {\n  changes: FileChange[];\n  baseCommit: string;\n  currentCommit: string;\n  includesUncommitted: boolean;\n}\n```\n\n**Pool Execution:**\n```typescript\nfunction runPool<T>(\n  tasks: Array<() => Promise<T>>, \n  options: PoolOptions, \n  onComplete?: (result: TaskResult<T>) => void\n): Promise<TaskResult<T>[]>\n\ninterface PoolOptions {\n  concurrency: number;\n  failFast?: boolean;\n  tracer?: ITraceWriter;\n  debug?: boolean;\n}\n\ntype TaskResult<T> = \n  | { index: number; success: true; result: T }\n  | { index: number; success: false; error: Error };\n```\n\n**Quality Validation:**\n```typescript\nfunction checkCodeVsDoc(sourceContent: string, sumContent: SumFileContent, filePath: string): CodeDocInconsistency | null\nfunction checkCodeVsCode(files: Array<{ path: string; content: string }>): CodeCodeInconsistency[]\nfunction checkPhantomPaths(agentsMdPath: string, content: string, projectRoot: string): PhantomPathInconsistency[]\nfunction buildInconsistencyReport(issues: Inconsistency[], metadata: { projectRoot: string; filesChecked: number; durationMs: number }): InconsistencyReport\n```\n\n**Installer:**\n```typescript\nfunction runInstaller(args: InstallerArgs): Promise<InstallerResult[]>\n\ninterface InstallerArgs {\n  runtime?: 'claude' | 'opencode' | 'gemini' | 'all';\n  global?: boolean;             // Install to ~/.claude, etc.\n  local?: boolean;              // Install to .claude, etc.\n  uninstall?: boolean;\n  force?: boolean;              // Overwrite existing files\n  help?: boolean;\n  quiet?: boolean;\n}\n\ninterface InstallerResult {\n  success: boolean;\n  runtime: string;\n  location: 'global' | 'local';\n  filesCreated: string[];\n  filesSkipped: string[];\n  errors: string[];\n  hookRegistered: boolean;\n  versionWritten: boolean;\n}\n```\n\n## 4. Data Structures & State\n\n### YAML Frontmatter Schema\n\n**.sum files:**\n```yaml\n---\ngenerated_at: 2026-02-09T12:34:56.789Z\ncontent_hash: a3f5d8e9b4c7f1e2d6a8b3c5e4f9a1d7  # SHA-256 hex (64 chars)\npurpose: One-line purpose statement\ncritical_todos:\n  - Security issue requiring immediate attention\n  - Performance bottleneck in hot path\nrelated_files:\n  - src/related/module.ts\n  - tests/integration/suite.test.ts\n---\n\nMarkdown summary content...\n```\n\n### Configuration State\n\n**Default vendor directories (18 entries):**\n```\nnode_modules, .git, dist, build, coverage, .next, .nuxt, out, vendor, \ntarget, __pycache__, venv, .venv, .gradle, .cargo, .planning, .claude, .pytest_cache\n```\n\n**Default exclude patterns (32 globs):**\n```\nAGENTS.md, CLAUDE.md, GEMINI.md, OPENCODE.md, SPEC.md, *.lock, \npackage-lock.json, yarn.lock, .env, .env.*, *.log, *.sum, \nGENERATION-PLAN.md, .DS_Store, Thumbs.db, **/.git/**, **/node_modules/**, \n**/dist/**, **/.agents-reverse-engineer/**, **/SKILL.md, **/.claude/**, \n**/.opencode/**, **/.gemini/**, **/.aider/**, etc.\n```\n\n**Default binary extensions (26 types):**\n```\n.png, .jpg, .jpeg, .gif, .bmp, .svg, .ico, .pdf, .zip, .tar, \n.gz, .bz2, .7z, .rar, .exe, .dll, .so, .dylib, .bin, .woff, \n.woff2, .ttf, .otf, .eot, .mp4, .mp3\n```\n\n### In-Memory State\n\n**TelemetryLogger:**\n```typescript\nclass TelemetryLogger {\n  private entries: TelemetryEntry[] = [];\n  private runId: string;        // ISO 8601 timestamp\n  \n  addEntry(entry: TelemetryEntry): void\n  setFilesReadOnLastEntry(filesRead: FileRead[]): void\n  getSummary(): { totalInputTokens, totalOutputTokens, errorCount, uniqueFilesRead, ... }\n  toRunLog(): RunLog\n}\n```\n\n**TraceWriter:**\n```typescript\nclass TraceWriter implements ITraceWriter {\n  private writeQueue: Promise<void> = Promise.resolve();\n  private eventCounter = 0;\n  private startTime: bigint;\n  \n  emit(event: TraceEventPayload): void  // Promise-chain serialization\n  finalize(): Promise<void>             // Await queue drain\n}\n```\n\n**ProgressReporter:**\n```typescript\nclass ProgressReporter {\n  private completionTimes: number[] = [];      // Sliding window (last 10)\n  private dirCompletionTimes: number[] = [];\n  \n  onFileStart(filePath: string, index: number, total: number): void\n  onFileDone(filePath: string, durationMs: number, tokensIn: number, tokensOut: number): void\n  printSummary(summary: RunSummary): void\n}\n```\n\n**BackendRegistry:**\n```typescript\nclass BackendRegistry {\n  private backends: AIBackend[] = [];   // Insertion-order preservation\n  \n  register(backend: AIBackend): void\n  get(name: string): AIBackend | undefined\n  getAll(): AIBackend[]\n}\n```\n\n### Serialization Formats\n\n**Run Log JSON:**\n```json\n{\n  \"runId\": \"2026-02-09T12-00-00-000Z\",\n  \"startTime\": \"2026-02-09T12:00:00.000Z\",\n  \"endTime\": \"2026-02-09T12:05:30.123Z\",\n  \"entries\": [\n    {\n      \"timestamp\": \"2026-02-09T12:00:01.234Z\",\n      \"prompt\": \"Analyze this file...\",\n      \"response\": \"This module exports...\",\n      \"model\": \"claude-sonnet-4\",\n      \"inputTokens\": 1500,\n      \"outputTokens\": 300,\n      \"cacheReadTokens\": 800,\n      \"cacheCreationTokens\": 1500,\n      \"latencyMs\": 2300,\n      \"exitCode\": 0,\n      \"retryCount\": 0,\n      \"thinking\": false,\n      \"filesRead\": [\n        { \"path\": \"src/module.ts\", \"sizeBytes\": 4096 }\n      ]\n    }\n  ],\n  \"summary\": {\n    \"totalInputTokens\": 45000,\n    \"totalOutputTokens\": 9000,\n    \"totalCacheReadTokens\": 24000,\n    \"totalCacheCreationTokens\": 45000,\n    \"totalLatencyMs\": 69000,\n    \"errorCount\": 2,\n    \"uniqueFilesRead\": 15\n  }\n}\n```\n\n**Trace NDJSON:**\n```jsonl\n{\"seq\":1,\"ts\":\"2026-02-09T12:00:00.001Z\",\"pid\":12345,\"elapsedMs\":1,\"type\":\"phase:start\",\"phase\":\"phase-1-files\",\"taskCount\":50,\"concurrency\":5}\n{\"seq\":2,\"ts\":\"2026-02-09T12:00:00.012Z\",\"pid\":12345,\"elapsedMs\":12,\"type\":\"worker:start\",\"workerId\":0}\n{\"seq\":3,\"ts\":\"2026-02-09T12:00:00.015Z\",\"pid\":12345,\"elapsedMs\":15,\"type\":\"task:pickup\",\"taskIndex\":0,\"taskLabel\":\"src/index.ts\",\"activeTasks\":1}\n{\"seq\":4,\"ts\":\"2026-02-09T12:00:00.020Z\",\"pid\":12345,\"elapsedMs\":20,\"type\":\"subprocess:spawn\",\"childPid\":12346,\"command\":\"claude\",\"args\":[\"-p\",\"--output-format\",\"json\"]}\n```\n\n## 5. Configuration\n\n### Config File Location\n\n`.agents-reverse-engineer/config.yaml` at project root\n\n### Schema Validation\n\nAll fields validated via Zod with these constraints:\n\n**Numeric Constraints:**\n- `ai.concurrency`: `.min(1).max(20)` — worker pool size\n- `ai.timeoutMs`: `.positive()` — subprocess timeout\n- `ai.maxRetries`: `.min(0)` — retry attempts\n- `options.maxFileSize`: `.positive()` — binary detection threshold\n\n**Enum Validation:**\n- `ai.backend`: `z.enum(['claude', 'gemini', 'opencode', 'auto'])`\n\n**Array Defaults:**\n- `exclude.patterns`: spreads `DEFAULT_EXCLUDE_PATTERNS` (32 globs)\n- `exclude.vendorDirs`: spreads `DEFAULT_VENDOR_DIRS` (18 directories)\n- `exclude.binaryExtensions`: spreads `DEFAULT_BINARY_EXTENSIONS` (26 extensions)\n\n### Environment Variable Overrides\n\n**IDE Config Directories:**\n- `CLAUDE_CONFIG_DIR` — overrides `~/.claude`\n- `OPENCODE_CONFIG_DIR` — overrides `~/.config/opencode` (with `XDG_CONFIG_HOME` fallback)\n- `GEMINI_CONFIG_DIR` — overrides `~/.gemini`\n\n**Hook Disabling:**\n- `ARE_DISABLE_HOOK=1` — disables session hooks via early exit in hook scripts\n\n### Dynamic Defaults\n\n**Concurrency Calculation:**\n```typescript\nfunction getDefaultConcurrency(): number {\n  const cores = os.cpus().length;\n  const totalMemGB = os.totalmem() / (1024 ** 3);\n  \n  const cpuBased = cores * 5;\n  const memoryBased = Math.floor(totalMemGB * 0.5 / 0.512);  // 512MB per subprocess\n  \n  return Math.max(MIN_CONCURRENCY, Math.min(cpuBased, memoryBased, MAX_CONCURRENCY));\n}\n// MIN_CONCURRENCY=2, MAX_CONCURRENCY=20\n```\n\n### Complete Config Example\n\n```yaml\nexclude:\n  patterns:\n    - \"*.test.ts\"\n    - \"**/__tests__/**\"\n    - \"*.config.js\"\n  vendorDirs:\n    - node_modules\n    - .git\n    - dist\n  binaryExtensions:\n    - .png\n    - .zip\n    - .pdf\n\noptions:\n  followSymlinks: false\n  maxFileSize: 1048576\n\noutput:\n  colors: true\n\nai:\n  backend: auto\n  model: null\n  timeoutMs: 120000\n  maxRetries: 3\n  concurrency: 5\n  \n  telemetry:\n    enabled: true\n    keepRuns: 50\n    costThresholdUsd: 10\n  \n  pricing:\n    claude:\n      inputCostPer1kTokens: 0.003\n      outputCostPer1kTokens: 0.015\n      cacheReadCostPer1kTokens: 0.0003\n      cacheCreationCostPer1kTokens: 0.00375\n```\n\n## 6. Dependencies\n\n### Production Dependencies\n\n**`fast-glob` ^3.3.2**\n- **Purpose:** File discovery with glob patterns, dotfile support, symlink control\n- **Rationale:** Fastest glob library with native ignore support, replaces recursive fs.readdir\n- **Usage:** `fast-glob('**/*', { onlyFiles: true, dot: true, ignore: ['.git/**'] })`\n\n**`ignore` ^5.3.1**\n- **Purpose:** Gitignore pattern matching engine\n- **Rationale:** Canonical implementation matching git behavior exactly\n- **Usage:** `ig.add(patterns).ignores(relativePath)`\n\n**`isbinaryfile` ^5.0.2**\n- **Purpose:** Content-based binary file detection\n- **Rationale:** Prevents LLM context pollution with non-text content\n- **Usage:** `await isBinaryFile(absolutePath)` for unknown extensions\n\n**`simple-git` ^3.24.0**\n- **Purpose:** Git diff parsing with rename detection\n- **Rationale:** Enables incremental updates by detecting changed files\n- **Usage:** `git diff --name-status -M <baseCommit>..HEAD`\n\n**`yaml` ^2.4.1**\n- **Purpose:** YAML parsing without comment preservation\n- **Rationale:** Lightweight, spec-compliant, no dependencies\n- **Usage:** `yaml.parse(configContent)` for config loading\n\n**`zod` ^3.22.4**\n- **Purpose:** Runtime schema validation with TypeScript inference\n- **Rationale:** Type-safe config validation, detailed error messages\n- **Usage:** `ConfigSchema.parse(rawConfig)` throws ZodError with formatted issues\n\n**`ora` ^8.0.1**\n- **Purpose:** Terminal spinner UI with color support\n- **Rationale:** Provides visual feedback during long-running operations\n- **Usage:** `ora('Analyzing files...').start()` / `.succeed()` / `.fail()`\n\n**`picocolors` ^1.0.0**\n- **Purpose:** ANSI color codes without dependencies\n- **Rationale:** Zero-dependency alternative to chalk, 14x smaller\n- **Usage:** `pc.green('✓')`, `pc.red('✗')`, `pc.dim('...')`\n\n### Development Dependencies\n\n**`typescript` ^5.7.3**\n- **Purpose:** Static type checking, ES2022 code generation\n- **Rationale:** Industry standard for Node.js type safety\n- **Configuration:** NodeNext module resolution, strict mode\n\n**`tsx` ^4.7.1**\n- **Purpose:** Hot-reload TypeScript execution\n- **Rationale:** Fast development iteration without tsc compilation\n- **Usage:** `tsx watch src/cli/index.ts`\n\n**`@types/node` ^20.11.0**\n- **Purpose:** Node.js stdlib type definitions\n- **Rationale:** Enables IDE autocomplete for fs, path, child_process\n\n**`vitest` (implicit, not in package.json)**\n- **Purpose:** Unit testing framework\n- **Rationale:** Fast, TypeScript-native, Jest-compatible API\n\n### Peer Dependencies (Implicit)\n\n**AI CLI Tools (at least one required):**\n- `@anthropic-ai/claude-code` — Claude Code CLI (`claude` command)\n- Gemini CLI — Google Gemini assistant (`gemini` command)\n- OpenCode CLI — OpenCode assistant (`opencode` command)\n\n### Dependency Graph\n\n```\nCLI Commands (src/cli/)\n  ↓\nCommandRunner (src/orchestration/runner.ts)\n  ↓\n├── AIService (src/ai/service.ts)\n│   └── Backends (src/ai/backends/)\n│       └── runSubprocess() → child_process.execFile\n├── Discovery (src/discovery/run.ts)\n│   ├── fast-glob\n│   ├── ignore (gitignore parsing)\n│   └── isbinaryfile\n├── Quality (src/quality/)\n│   └── Node.js stdlib (fs, path)\n├── Config (src/config/loader.ts)\n│   ├── yaml\n│   └── zod\n└── Update (src/update/orchestrator.ts)\n    └── simple-git\n```\n\n## 7. Behavioral Contracts\n\n### Error Handling Strategy\n\n**Error Types:**\n```typescript\nclass AIServiceError extends Error {\n  code: 'CLI_NOT_FOUND' | 'TIMEOUT' | 'PARSE_ERROR' | 'SUBPROCESS_ERROR' | 'RATE_LIMIT';\n  details?: Record<string, unknown>;\n}\n\nclass ConfigError extends Error {\n  filePath: string;\n  cause?: Error;\n}\n\nclass SpecExistsError extends Error {\n  paths: string[];\n}\n```\n\n**Error Propagation:**\n- Subprocess failures: `AIServiceError` with `code: 'SUBPROCESS_ERROR'` if exitCode !== 0\n- Rate limits: `AIServiceError` with `code: 'RATE_LIMIT'` if stderr matches patterns `['rate limit', '429', 'too many requests', 'overloaded']`\n- Timeouts: `AIServiceError` with `code: 'TIMEOUT'` if subprocess exceeds `timeoutMs`\n- Parse failures: `AIServiceError` with `code: 'PARSE_ERROR'` if JSON.parse() throws\n- Missing CLI: `AIServiceError` with `code: 'CLI_NOT_FOUND'` if no backend available\n\n**Exit Codes:**\n- `0` — All tasks succeeded or no files to process\n- `1` — Partial failure (`filesProcessed > 0` and `filesFailed > 0`), or permission denied\n- `2` — Total failure (`filesProcessed === 0` and `filesFailed > 0`), or no backend available\n\n### Retry Logic\n\n**Exponential Backoff:**\n```typescript\nfunction withRetry<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T>\n\ninterface RetryOptions {\n  maxRetries: number;           // Default: 3\n  baseDelayMs: number;          // Default: 1000\n  maxDelayMs: number;           // Default: 8000\n  multiplier: number;           // Default: 2\n  isRetryable: (error: Error) => boolean;\n  onRetry?: (attempt: number, error: Error) => void;\n}\n\n// Formula: delay = min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter\n// jitter = Math.random() * 500\n```\n\n**Retryable Conditions:**\n- `AIServiceError` with `code === 'RATE_LIMIT'`\n- Network timeouts from fetch (if backend supports)\n\n**Non-Retryable Conditions:**\n- `AIServiceError` with `code === 'TIMEOUT'` (subprocess timeout)\n- `AIServiceError` with `code === 'PARSE_ERROR'` (invalid response)\n- `AIServiceError` with `code === 'CLI_NOT_FOUND'` (missing executable)\n- All other error types\n\n### Concurrency Model\n\n**Worker Pool Pattern:**\n- Shared iterator across N workers prevents batch anti-pattern\n- Iterator protocol ensures atomic task consumption\n- Workers execute until iterator exhausted\n- Fail-fast mode aborts all workers on first error\n\n**Resource Limits Per Subprocess:**\n```typescript\nconst env = {\n  NODE_OPTIONS: '--max-old-space-size=512',          // 512MB heap\n  UV_THREADPOOL_SIZE: '4',                           // 4 libuv threads\n  CLAUDE_CODE_DISABLE_BACKGROUND_TASKS: '1',         // No background spawns\n};\nconst args = [...backendArgs, '--disallowedTools', 'Task'];\n```\n\n**Timeout Enforcement:**\n1. SIGTERM sent at `timeoutMs`\n2. 5-second grace period for cleanup\n3. SIGKILL escalation if still running\n4. Process group killing via `kill(-pid)` to terminate subprocess tree\n\n### Lifecycle Hooks\n\n**Session Lifecycle (Claude/Gemini/OpenCode):**\n\n**SessionStart Hook (`are-check-update.js`):**\n```javascript\n// Spawns detached process\n// Queries: npm view agents-reverse-engineer version\n// Compares: cached ARE-VERSION file\n// Writes: ~/.claude/cache/are-update-check.json\n// Exit: 0 (silent failure on errors)\n```\n\n**SessionEnd Hook (`are-session-end.js`):**\n```javascript\n// Guards: ARE_DISABLE_HOOK='1' or config 'hook_enabled: false'\n// Checks: git status --porcelain (non-empty = uncommitted changes)\n// Spawns: npx agents-reverse-engineer@latest update --quiet (detached)\n// Exit: 0 (silent failure on errors/non-git repos)\n```\n\n**Hook Disable Mechanisms:**\n1. Environment variable: `ARE_DISABLE_HOOK=1`\n2. Config substring: `.agents-reverse-engineer.yaml` contains `hook_enabled: false`\n\n### Resource Management\n\n**File Handles:**\n- `ProgressLog` opens `.agents-reverse-engineer/progress.log` in truncate mode ('w')\n- `TraceWriter` opens `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson` in append mode ('a')\n- Both closed via `finalize()` after queue drain\n\n**Memory Management:**\n- `GenerationOrchestrator.prepareFiles()` clears file content after task creation: `(file as { content: string }).content = ''`\n- Subprocess heap limited to 512MB prevents OOM\n- Default concurrency computed from system memory: `floor(totalMemGB * 0.5 / 0.512)`\n\n**Process Management:**\n- Active subprocess tracking via `activeSubprocesses: Map<number, { pid, command, args }>`\n- Process group killing ensures no orphaned subprocesses\n- Unref'd timeout handles prevent event loop blocking\n\n### State Persistence\n\n**Stateless Incremental Updates:**\n- No external database required\n- SHA-256 hash embedded in `.sum` YAML frontmatter\n- Hash comparison determines regeneration scope\n- Works in non-git environments\n\n**Telemetry Retention:**\n- Run logs: kept last `config.ai.telemetry.keepRuns` (default 50)\n- Traces: kept last 500 via `cleanupOldTraces(keepCount=500)`\n- Cleanup triggered after each run via lexicographic sort descending\n\n## 8. Test Contracts\n\n### `src/ai/` Module Tests\n\n**Subprocess Management:**\n- SHOULD spawn subprocess with correct environment variables (NODE_OPTIONS, UV_THREADPOOL_SIZE)\n- SHOULD send prompt via stdin and close with EOF\n- SHOULD enforce timeout with SIGTERM → SIGKILL escalation\n- SHOULD kill process group via `kill(-pid)`\n- SHOULD track active subprocesses in Map\n- SHOULD unref timeout handles\n\n**Retry Logic:**\n- SHOULD retry rate limit errors with exponential backoff\n- SHOULD NOT retry timeout errors\n- SHOULD NOT retry parse errors\n- SHOULD invoke onRetry callback with attempt number\n- SHOULD add jitter (0-500ms) to delay calculation\n- SHOULD respect maxRetries limit\n\n**Backend Registry:**\n- SHOULD register backends in insertion order\n- SHOULD detect first available backend for 'auto' mode\n- SHOULD throw CLI_NOT_FOUND when no backend available\n- SHOULD return installation instructions for all backends\n\n**Telemetry:**\n- SHOULD accumulate entries with token counts\n- SHOULD compute summary with unique file count\n- SHOULD write run log with sanitized timestamp\n- SHOULD clean up old logs beyond retention limit\n\n### `src/discovery/` Module Tests\n\n**Filter Chain:**\n- SHOULD execute filters in order: gitignore → vendor → binary → custom\n- SHOULD short-circuit on first filter match\n- SHOULD emit filter:applied trace events with counts\n- SHOULD respect maxFileSize threshold for binary detection\n- SHOULD match vendor directories anywhere in path\n- SHOULD handle multi-segment vendor patterns\n\n**Gitignore Integration:**\n- SHOULD parse .gitignore with ignore library\n- SHOULD convert absolute paths to relative before matching\n- SHOULD return false for external paths (starting with ..)\n- SHOULD handle missing .gitignore gracefully\n\n**Binary Detection:**\n- SHOULD match known extensions via fast-path lookup\n- SHOULD enforce size threshold via fs.stat()\n- SHOULD use isbinaryfile for unknown extensions\n- SHOULD return true on fs.stat() errors\n\n### `src/generation/` Module Tests\n\n**Prompt Construction:**\n- SHOULD inject import map from extractDirectoryImports()\n- SHOULD switch to update prompts when existingSum present\n- SHOULD detect 9 manifest types (package.json, Cargo.toml, etc.)\n- SHOULD preserve user content via AGENTS.local.md prepending\n- SHOULD strip GENERATED_MARKER from LLM output\n\n**Execution Plan:**\n- SHOULD sort directories by depth descending\n- SHOULD construct dependency graph: files → directories → root\n- SHOULD wait for child .sum files via isDirectoryComplete()\n- SHOULD compute directory file map for metadata\n\n**YAML Frontmatter:**\n- SHOULD serialize inline arrays when ≤3 items <40 chars\n- SHOULD serialize multi-line arrays otherwise\n- SHOULD embed SHA-256 content_hash\n- SHOULD parse frontmatter via regex extraction\n- SHOULD return null on parse failure\n\n### `src/orchestration/` Module Tests\n\n**Worker Pool:**\n- SHOULD share single iterator across workers\n- SHOULD prevent over-allocation when tasks < concurrency\n- SHOULD abort all workers on fail-fast error\n- SHOULD emit worker:start/end events\n- SHOULD emit task:pickup/done events with activeTasks counter\n- SHOULD preserve original task order in results\n\n**Progress Tracking:**\n- SHOULD compute ETA via moving average of last 10 durations\n- SHOULD show ETA after 2+ completions\n- SHOULD format as seconds below 60s, minutes+seconds above\n- SHOULD mirror output to progress.log\n- SHOULD strip ANSI codes before file write\n\n**Trace Emission:**\n- SHOULD auto-populate seq, ts, pid, elapsedMs fields\n- SHOULD serialize writes via promise chain\n- SHOULD preserve NDJSON line order despite concurrent emissions\n- SHOULD clean up old traces beyond 500 retention limit\n\n**Plan Tracking:**\n- SHOULD mark checkboxes in GENERATION-PLAN.md\n- SHOULD serialize writes via promise chain\n- SHOULD flush queue on finalize()\n\n### `src/update/` Module Tests\n\n**Hash Comparison:**\n- SHOULD read content_hash from .sum frontmatter\n- SHOULD compute current hash via SHA-256\n- SHOULD classify as filesToAnalyze on hash mismatch\n- SHOULD classify as filesToSkip on hash match\n- SHOULD detect missing .sum as added files\n\n**Orphan Cleanup:**\n- SHOULD delete .sum files for deleted sources\n- SHOULD delete .sum files for renamed oldPath\n- SHOULD remove AGENTS.md when directory has no source files\n- SHOULD preserve AGENTS.md when source files remain\n- SHOULD exclude hidden files from empty check\n- SHOULD exclude .sum files from empty check\n\n**Affected Directories:**\n- SHOULD walk parent directory tree to root\n- SHOULD include all parent directories in set\n- SHOULD return unique directory paths\n\n### `src/quality/` Module Tests\n\n**Code-vs-Doc:**\n- SHOULD extract exports via regex pattern\n- SHOULD detect missing exports in summary\n- SHOULD return null when all exports documented\n- SHOULD populate missingFromDoc array\n\n**Code-vs-Code:**\n- SHOULD build symbol-to-paths map\n- SHOULD detect duplicates when paths.length > 1\n- SHOULD return empty array when no duplicates\n- SHOULD include all files in CodeCodeInconsistency\n\n**Phantom Paths:**\n- SHOULD extract paths via three regex patterns\n- SHOULD skip patterns matching SKIP_PATTERNS\n- SHOULD resolve relative to AGENTS.md directory\n- SHOULD resolve relative to project root\n- SHOULD try .ts fallback for .js imports\n- SHOULD deduplicate via seen Set\n\n**Report Building:**\n- SHOULD aggregate inconsistencies by type\n- SHOULD compute severity counts\n- SHOULD format CLI output with severity tags\n\n### `src/config/` Module Tests\n\n**Schema Validation:**\n- SHOULD enforce concurrency range [1, 20]\n- SHOULD enforce positive timeoutMs\n- SHOULD validate backend enum values\n- SHOULD spread default arrays\n- SHOULD throw ConfigError on ZodError\n\n**Concurrency Calculation:**\n- SHOULD compute CPU-based limit (cores * 5)\n- SHOULD compute memory-based limit (totalMemGB * 0.5 / 0.512)\n- SHOULD return min(cpuBased, memoryBased) clamped to [2, 20]\n\n**Config Writing:**\n- SHOULD generate YAML with inline comments\n- SHOULD apply yamlScalar() quoting for globs\n- SHOULD create parent directory if missing\n\n### `src/installer/` Module Tests\n\n**Hook Registration:**\n- SHOULD append hooks to settings.hooks.SessionStart/SessionEnd arrays\n- SHOULD check duplicates via command string match\n- SHOULD use nested format for Claude\n- SHOULD use flat format for Gemini\n\n**Permission Registration:**\n- SHOULD append ARE_PERMISSIONS patterns to settings.permissions.allow\n- SHOULD deduplicate via includes() check\n\n**Hook Deregistration:**\n- SHOULD filter arrays removing matching command patterns\n- SHOULD clean empty arrays/objects\n- SHOULD handle both current and legacy formats\n\n**Template Writing:**\n- SHOULD write templates to runtime-specific paths\n- SHOULD create parent directories\n- SHOULD skip existing files unless force=true\n- SHOULD return filesCreated/filesSkipped arrays\n\n## 9. Build Plan\n\n### Phase 1: Core Infrastructure (no dependencies)\n\n**Goal:** Establish configuration, logging, and type foundations\n\n**Modules:**\n1. `src/types/` — Shared interfaces (ExcludedFile, DiscoveryResult, DiscoveryStats)\n2. `src/output/logger.ts` — Terminal formatting with picocolors\n3. `src/config/schema.ts` — Zod validation schemas\n4. `src/config/defaults.ts` — Default arrays and concurrency calculation\n5. `src/config/loader.ts` — YAML parsing with loadConfig()/writeDefaultConfig()\n6. `src/version.ts` — Package version extraction\n\n**Verification:**\n- Config loads with valid YAML\n- Default concurrency computes based on system resources\n- Logger produces colored output when colors=true\n\n**Enables:** All subsequent phases depend on Config and Logger\n\n---\n\n### Phase 2: File Discovery (depends: Phase 1)\n\n**Goal:** Implement gitignore-aware file walking with composable filters\n\n**Modules:**\n1. `src/discovery/types.ts` — FileFilter interface, WalkerOptions\n2. `src/discovery/walker.ts` — fast-glob integration with .git/** exclusion\n3. `src/discovery/filters/binary.ts` — Extension + size + content detection\n4. `src/discovery/filters/vendor.ts` — Single/multi-segment directory matching\n5. `src/discovery/filters/gitignore.ts` — ignore library wrapper\n6. `src/discovery/filters/custom.ts` — User-defined glob patterns\n7. `src/discovery/filters/index.ts` — applyFilters() with worker pool\n8. `src/discovery/run.ts` — discoverFiles() orchestrator\n\n**Verification:**\n- Discovers files respecting .gitignore\n- Excludes node_modules, .git, dist\n- Detects binary files via extension/size/content\n- Returns FilterResult with included/excluded arrays\n\n**Enables:** Phase 4 (Generation) requires file lists, Phase 6 (Update) requires discovery\n\n---\n\n### Phase 3: AI Service Layer (depends: Phase 1)\n\n**Goal:** Backend-agnostic subprocess management with retry and telemetry\n\n**Modules:**\n1. `src/ai/types.ts` — AIBackend, AICallOptions, AIResponse, TelemetryEntry\n2. `src/ai/subprocess.ts` — runSubprocess() with resource limits and timeout\n3. `src/ai/retry.ts` — withRetry() exponential backoff\n4. `src/ai/backends/claude.ts` — ClaudeBackend with JSON parsing\n5. `src/ai/backends/gemini.ts` — GeminiBackend stub\n6. `src/ai/backends/opencode.ts` — OpenCodeBackend stub\n7. `src/ai/registry.ts` — Backend registration and auto-detection\n8. `src/ai/service.ts` — AIService orchestrating call()/finalize()\n9. `src/ai/telemetry/logger.ts` — TelemetryLogger with addEntry()/getSummary()\n10. `src/ai/telemetry/run-log.ts` — writeRunLog() with timestamp sanitization\n11. `src/ai/telemetry/cleanup.ts` — cleanupOldLogs() retention enforcement\n\n**Verification:**\n- Spawns Claude CLI subprocess with correct args\n- Parses JSON response extracting tokens/cost\n- Retries rate limits with exponential backoff\n- Writes run logs to .agents-reverse-engineer/logs/\n- Cleans up logs beyond retention limit\n\n**Enables:** Phase 4 (Generation) requires AI calls\n\n---\n\n### Phase 4: Generation Pipeline (depends: Phases 1-3)\n\n**Goal:** Three-phase documentation generation with prompts, writers, collectors\n\n**Modules:**\n1. `src/imports/types.ts` — ImportEntry, FileImports\n2. `src/imports/extractor.ts` — extractImports(), extractDirectoryImports()\n3. `src/generation/types.ts` — AnalysisResult, SummaryOptions\n4. `src/generation/prompts/types.ts` — PromptContext, SUMMARY_GUIDELINES\n5. `src/generation/prompts/templates.ts` — FILE/DIRECTORY/ROOT system/user prompts\n6. `src/generation/prompts/builder.ts` — buildFilePrompt()/buildDirectoryPrompt()/buildRootPrompt()\n7. `src/generation/writers/sum.ts` — writeSumFile()/readSumFile() with YAML frontmatter\n8. `src/generation/writers/agents-md.ts` — writeAgentsMd() with user content preservation\n9. `src/generation/collector.ts` — collectAgentsDocs() recursive traversal\n10. `src/generation/complexity.ts` — analyzeComplexity() with depth calculation\n11. `src/generation/orchestrator.ts` — GenerationOrchestrator.createPlan()\n12. `src/generation/executor.ts` — buildExecutionPlan() with dependency ordering\n\n**Verification:**\n- Builds file prompts with import context\n- Writes .sum files with SHA-256 content_hash\n- Builds directory prompts aggregating child .sum files\n- Writes AGENTS.md preserving AGENTS.local.md\n- Builds root prompts collecting all AGENTS.md\n- Execution plan sorts directories by depth descending\n\n**Enables:** Phase 5 (Orchestration) requires tasks, Phase 7 (Update) requires writers\n\n---\n\n### Phase 5: Orchestration & Progress (depends: Phases 1, 3, 4)\n\n**Goal:** Worker pool execution with trace emission and progress tracking\n\n**Modules:**\n1. `src/orchestration/types.ts` — FileTaskResult, RunSummary, ProgressEvent, TraceEvent\n2. `src/orchestration/trace.ts` — TraceWriter with promise-chain serialization\n3. `src/orchestration/pool.ts` — runPool() shared-iterator pattern\n4. `src/orchestration/progress.ts` — ProgressReporter with ETA calculation\n5. `src/orchestration/plan-tracker.ts` — PlanTracker for GENERATION-PLAN.md\n6. `src/orchestration/runner.ts` — CommandRunner.executeGenerate()/executeUpdate()\n\n**Verification:**\n- Workers share iterator preventing over-allocation\n- Trace events emitted with seq/ts/pid/elapsedMs\n- ETA computed from moving average of last 10 durations\n- Progress mirrored to .agents-reverse-engineer/progress.log\n- Plan tracker marks checkboxes on task completion\n\n**Enables:** Phase 8 (CLI) requires CommandRunner\n\n---\n\n### Phase 6: Change Detection (depends: Phase 1)\n\n**Goal:** Git diff parsing and SHA-256 hashing for incremental updates\n\n**Modules:**\n1. `src/change-detection/types.ts` — ChangeType, FileChange, ChangeDetectionResult\n2. `src/change-detection/detector.ts` — getChangedFiles(), computeContentHash()\n\n**Verification:**\n- Parses git diff --name-status -M with rename detection\n- Merges uncommitted changes when includeUncommitted=true\n- Computes SHA-256 hex digest for file content\n\n**Enables:** Phase 7 (Update) requires change detection\n\n---\n\n### Phase 7: Incremental Updates (depends: Phases 1, 4, 6)\n\n**Goal:** Hash-based regeneration with orphan cleanup\n\n**Modules:**\n1. `src/update/types.ts` — UpdateOptions, UpdateResult, CleanupResult\n2. `src/update/orphan-cleaner.ts` — cleanupOrphans()/getAffectedDirectories()\n3. `src/update/orchestrator.ts` — UpdateOrchestrator.preparePlan()\n\n**Verification:**\n- Reads content_hash from .sum frontmatter\n- Classifies files into filesToAnalyze vs filesToSkip\n- Deletes orphaned .sum files for deleted/renamed sources\n- Removes AGENTS.md from empty directories\n- Computes affected directories via parent tree walk\n\n**Enables:** Phase 8 (CLI update command)\n\n---\n\n### Phase 8: Quality Validation (depends: Phases 1, 4)\n\n**Goal:** Post-generation consistency checks\n\n**Modules:**\n1. `src/quality/types.ts` — Inconsistency discriminated union\n2. `src/quality/inconsistency/code-vs-doc.ts` — extractExports(), checkCodeVsDoc()\n3. `src/quality/inconsistency/code-vs-code.ts` — checkCodeVsCode()\n4. `src/quality/inconsistency/reporter.ts` — buildInconsistencyReport()\n5. `src/quality/phantom-paths/validator.ts` — checkPhantomPaths()\n6. `src/quality/density/validator.ts` — validateFindability() stub\n\n**Verification:**\n- Extracts exports via regex\n- Detects missing exports in summaries\n- Detects duplicate symbols across files\n- Resolves phantom paths with .ts fallback\n- Formats report with severity tags\n\n**Enables:** Phase 9 (CLI) reports quality metrics\n\n---\n\n### Phase 9: CLI Commands (depends: Phases 1-8)\n\n**Goal:** User-facing command interface\n\n**Modules:**\n1. `src/cli/index.ts` — Argument parsing and routing\n2. `src/cli/init.ts` — Config initialization\n3. `src/cli/discover.ts` — Discovery preview\n4. `src/cli/generate.ts` — Three-phase generation\n5. `src/cli/update.ts` — Incremental regeneration\n6. `src/cli/clean.ts` — Artifact deletion\n7. `src/cli/specify.ts` — Specification synthesis\n\n**Verification:**\n- are init creates .agents-reverse-engineer/config.yaml\n- are discover writes GENERATION-PLAN.md\n- are generate executes three phases\n- are update regenerates only changed files\n- are clean deletes .sum/AGENTS.md/CLAUDE.md\n- are specify synthesizes specs/SPEC.md\n\n**Enables:** Phase 10 (Installer) requires CLI\n\n---\n\n### Phase 10: Integration & Installer (depends: Phases 1, 9)\n\n**Goal:** IDE command installation with hook registration\n\n**Modules:**\n1. `src/integration/types.ts` — EnvironmentType, DetectedEnvironment\n2. `src/integration/detect.ts` — detectEnvironments() via filesystem markers\n3. `src/integration/templates.ts` — getClaudeTemplates()/getOpenCodeTemplates()/getGeminiTemplates()\n4. `src/integration/generate.ts` — generateIntegrationFiles()\n5. `src/installer/types.ts` — Runtime, InstallerArgs, InstallerResult\n6. `src/installer/paths.ts` — getRuntimePaths() with environment overrides\n7. `src/installer/prompts.ts` — selectRuntime()/selectLocation() with TTY detection\n8. `src/installer/operations.ts` — installFiles()/registerHooks()/registerPermissions()\n9. `src/installer/uninstall.ts` — uninstallFiles()/unregisterHooks()\n10. `src/installer/banner.ts` — displayBanner()/showNextSteps()\n11. `hooks/` — Session lifecycle scripts (4 files: Claude/Gemini/OpenCode pairs)\n12. `scripts/build-hooks.js` — Prepublish hook copying to hooks/dist/\n\n**Verification:**\n- Detects Claude/OpenCode/Gemini environments\n- Writes command templates to ~/.claude/skills/, etc.\n- Installs hooks to ~/.claude/hooks/\n- Registers hooks in settings.json (nested for Claude, flat for Gemini)\n- Registers permissions for auto-approval\n- Uninstalls templates and deregisters hooks\n- Copies hooks to hooks/dist/ during prepublish\n\n**Enables:** Complete end-to-end workflow\n\n---\n\n### Phase 11: Specification Synthesis (depends: Phases 1, 3, 4)\n\n**Goal:** Generate project specifications from AGENTS.md corpus\n\n**Modules:**\n1. `src/specify/prompts.ts` — buildSpecPrompt() with SPEC_SYSTEM_PROMPT\n2. `src/specify/writer.ts` — writeSpec() with single/multi-file modes\n3. `src/specify/index.ts` — Barrel export\n\n**Verification:**\n- Prompts enforce concern-based organization\n- Single-file mode writes specs/SPEC.md\n- Multi-file mode splits on top-level headings\n- Throws SpecExistsError without --force\n\n**Enables:** Complete feature set\n\n---\n\n### Phase 12: Build & Distribution (depends: all phases)\n\n**Goal:** Package for npm with provenance attestation\n\n**Modules:**\n1. `package.json` — Binary entry points, scripts, dependencies\n2. `tsconfig.json` — ES2022 target, NodeNext resolution\n3. `.github/workflows/publish.yml` — CI/CD with OIDC provenance\n\n**Verification:**\n- tsc compiles src/ → dist/ without errors\n- npm pack includes dist/, hooks/dist/, LICENSE, README.md\n- Binary entry points resolve to dist/cli/index.js\n- GitHub Actions publishes with provenance on release\n\n**Deliverable:** Published npm package",
      "model": "claude-sonnet-4-5-20250929",
      "inputTokens": 3,
      "outputTokens": 14539,
      "cacheReadTokens": 16334,
      "cacheCreationTokens": 51932,
      "latencyMs": 287284,
      "exitCode": 0,
      "retryCount": 0,
      "thinking": "not supported",
      "filesRead": []
    }
  ],
  "summary": {
    "totalCalls": 1,
    "totalInputTokens": 3,
    "totalOutputTokens": 14539,
    "totalCacheReadTokens": 16334,
    "totalCacheCreationTokens": 51932,
    "totalDurationMs": 287284,
    "errorCount": 0,
    "totalFilesRead": 0,
    "uniqueFilesRead": 0
  }
}