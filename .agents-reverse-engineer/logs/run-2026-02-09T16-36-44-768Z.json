{
  "runId": "2026-02-09T16:36:44.768Z",
  "startTime": "2026-02-09T16:36:44.768Z",
  "endTime": "2026-02-09T16:44:11.762Z",
  "entries": [
    {
      "timestamp": "2026-02-09T16:36:44.769Z",
      "prompt": "Generate a comprehensive project specification from the following documentation.\n\n## AGENTS.md Files (29 directories)\n\n### .github/workflows/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# .github/workflows\n\nGitHub Actions CI/CD automation for npm package publication with Sigstore-signed provenance attestation.\n\n## Contents\n\n### [publish.yml](./publish.yml)\nWorkflow automating npm publication on `release[published]` events or manual `workflow_dispatch`. Executes `actions/checkout@v4`, `actions/setup-node@v4` (Node.js 20, registry `https://registry.npmjs.org`), `npm ci`, `npm run build` (invokes `prepublishOnly`: TypeScript compilation + `build:hooks` script from `scripts/build-hooks.js`), and `npm publish --provenance --access public` with `NODE_AUTH_TOKEN` from `secrets.NPM_TOKEN`. Grants `id-token: write` permission enabling Sigstore keyless signing to generate SLSA attestation linking published tarball to source commit SHA.\n\n## CI/CD Pipeline Architecture\n\n**Trigger Strategy:**  \nExecutes on GitHub release publication or manual dispatch, ensuring controlled release cadence.\n\n**Build Steps:**  \nSequential execution: repository checkout at release commit SHA → Node.js 20 installation with npm registry configuration → clean dependency install via `npm ci` → TypeScript compilation and hook file preparation via `npm run build` → authenticated publication with cryptographic attestation.\n\n**Security Model:**  \nOIDC token-based authentication (`id-token: write`) enables Sigstore keyless signing without long-lived credentials. Generated provenance attestation creates verifiable supply chain metadata recording workflow execution context (commit SHA, repository coordinates, workflow file path) consumable via `npm audit signatures` or `sigstore-js` tooling.\n\n## Integration Points\n\n**Build System:**  \nDepends on `prepublishOnly` script in root `package.json` executing TypeScript compiler (`tsc`) and hook file copier (`scripts/build-hooks.js`). Outputs `dist/` directory tree and `hooks/dist/` session lifecycle hook bundles included in npm tarball.\n\n**Publication Authentication:**  \nRequires `NPM_TOKEN` repository secret storing npm automation token with publish permissions for package scope. Token injected as `NODE_AUTH_TOKEN` environment variable during `npm publish` execution.\n\n**Provenance Attestation:**  \n`--provenance` flag triggers GitHub Actions attestation generation via `@actions/attest-build-provenance` internal API, uploading signed SLSA v0.2 attestation to npm registry metadata storage. Consumers verify authenticity by inspecting `attestations` field in registry metadata or using `npm audit signatures` command.\n### AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# agents-reverse-engineer\n\nAI-driven codebase documentation generator executing Recursive Language Model (RLM) algorithm: concurrent per-file `.sum` analysis via subprocess pools, post-order directory `AGENTS.md` aggregation, and platform-specific root synthesis (`CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`) with gitignore-aware discovery, SHA-256 incremental updates, and session lifecycle hooks.\n\n## Stack\n\n**Runtime:** Node.js ≥18.0.0, ES modules (`\"type\": \"module\"`)  \n**Language:** TypeScript 5.7.3 (ES2022 target, NodeNext module resolution, strict mode)  \n**Entry Points:** `are` and `agents-reverse-engineer` binaries → `dist/cli/index.js`  \n**Build:** `tsc` emits `src/` → `dist/` with source maps/declarations, `scripts/build-hooks.js` copies `hooks/` → `hooks/dist/`  \n**Package:** [package.json](./package.json) v0.6.5, MIT license, npm tarball includes `dist/`, `hooks/dist/`, `README.md`, `LICENSE`  \n**Config:** TypeScript via [tsconfig.json](./tsconfig.json), npm scripts for `build`/`dev`/`prepublishOnly`\n\n**Dependencies:**\n- `fast-glob` ^3.3.3 (file discovery)\n- `ignore` ^7.0.3 (gitignore parsing)\n- `isbinaryfile` ^5.0.4 (binary detection)\n- `simple-git` ^3.27.0 (change detection)\n- `yaml` ^2.7.0 (config parsing)\n- `zod` ^3.24.1 (schema validation)\n- `ora` ^8.1.1 (spinners)\n- `picocolors` ^1.1.1 (terminal colors)\n\n## Contents\n\n### Root Documentation\n\n**[README.md](./README.md)** — User-facing marketing page and CLI reference documenting npx-based interactive installation (`--runtime <rt>` + `-g`/`-l` flags), command surface (`init`, `discover`, `generate`, `update`, `clean`, `specify`), IDE integration patterns (`/are-generate` long-running with `run_in_background: true` + `TaskOutput` polling), three-phase pipeline (concurrent file analysis → post-order directory aggregation → sequential root synthesis), incremental update workflow (SHA-256 hash comparison via `.sum` frontmatter, orphan cleanup via `cleanupOrphans()`/`cleanupEmptyDirectoryDocs()`), subprocess resource management (heap/thread limits, process group killing, SIGTERM/SIGKILL timeout), configuration schema (`.agents-reverse-engineer/config.yaml` with `exclude`/`options`/`output`/`ai` sections), session hooks (Claude/Gemini/OpenCode lifecycle event handlers with detached subprocess spawning).\n\n**[LICENSE](./LICENSE)** — MIT License copyright 2026 GeoloeG-IsT grants unrestricted use/modification/distribution/sublicensing with warranty disclaimer, liability limitation, mandatory attribution preservation in derivative works.\n\n**[LANGUAGES-MANIFEST.md](./LANGUAGES-MANIFEST.md)** — Reference table mapping 26 programming language ecosystems to package manager manifest files, documenting which formats `src/generation/prompts/builder.ts` detects via `detectManifest()` for Phase 2 directory aggregation prompt inclusion (9 supported: `package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`, `pom.xml`, `build.gradle`, `Gemfile`, `composer.json`, `CMakeLists.txt`/`Makefile`), identifies coverage gaps for Ruby/Gradle/.NET/Swift/functional/scientific ecosystems.\n\n### Build & Distribution\n\n**[package.json](./package.json)** — npm package metadata declaring dual binaries (`are`, `agents-reverse-engineer`), ES module type, build scripts (`tsc` + `build-hooks.js`), runtime dependencies (fast-glob, ignore, isbinaryfile, simple-git, yaml, zod, ora, picocolors), Node.js ≥18.0.0 engine requirement, npm tarball whitelist (`dist`, `hooks/dist`, `README.md`, `LICENSE`).\n\n**[tsconfig.json](./tsconfig.json)** — TypeScript compiler configuration emitting ES2022 JavaScript from `src/` → `dist/` with NodeNext module resolution, strict type checking, source maps, declaration files, JSON module resolution (enables `package.json` imports in `src/generation/prompts/builder.ts`).\n\n**[.github/workflows/publish.yml](./.github/workflows/publish.yml)** — CI/CD workflow triggering on `release[published]` events, executing `npm ci` → `npm run build` → `npm publish --provenance --access public` with Sigstore-signed provenance attestation linking published artifact to source commit SHA.\n\n**[scripts/](./scripts/)** — Build automation: [build-hooks.js](./scripts/build-hooks.js) copies `.js` files from `hooks/` → `hooks/dist/` via synchronous `copyFileSync()`, invoked by `prepublishOnly` lifecycle hook before npm tarball creation.\n\n### Documentation Artifacts\n\n**[docs/](./docs/)** — [INPUT.md](./docs/INPUT.md) inception document defining RLM algorithm (post-order tree traversal: leaf `.sum` → directory `AGENTS.md` → root synthesis), proposed command interface (`/are-generate`, `/are-update`), session lifecycle integration requirements, research directives for GSD/BMAD methodology analysis.\n\n### Session Lifecycle Hooks\n\n**[hooks/](./hooks/)** — Detached subprocess-spawning session event handlers:\n- [are-check-update.js](./hooks/are-check-update.js) — Claude/Gemini SessionStart: `npm view agents-reverse-engineer version` comparison against `ARE-VERSION` sentinel file (project `.claude/ARE-VERSION` before global), writes cache to `~/.claude/cache/are-update-check.json`\n- [are-session-end.js](./hooks/are-session-end.js) — Claude/Gemini SessionEnd: `git status --porcelain` change detection → `npx agents-reverse-engineer@latest update --quiet` detached spawn if uncommitted changes present, exits silently if `ARE_DISABLE_HOOK=1` or config contains `hook_enabled: false`\n- [opencode-are-check-update.js](./hooks/opencode-are-check-update.js) — OpenCode plugin factory exporting `AreCheckUpdate()` → `event['session.created']` handler with identical npm version check logic\n- [opencode-are-session-end.js](./hooks/opencode-are-session-end.js) — OpenCode plugin factory exporting `AreSessionEnd()` → `event['session.deleted']` handler with identical git status check + update spawn\n\n### TypeScript Source Tree\n\n**[src/](./src/)** — Core implementation modules:\n\n**[src/version.ts](./src/version.ts)** — `getVersion()` reads `package.json` from compiled module parent directory via `fileURLToPath(import.meta.url)` → `dirname()` → `join(__dirname, '..', 'package.json')`, returns `version` field or `'unknown'` on error, called by CLI help text and session hooks.\n\n**[src/cli/](./src/cli/)** — Command entry points: [index.ts](./src/cli/index.ts) parses `process.argv` via `parseArgs()` with short flag expansion, dual routing (installer vs. command dispatch), [generate.ts](./src/cli/generate.ts) orchestrates three-phase pipeline with backend resolution, [update.ts](./src/cli/update.ts) executes hash-based incremental regeneration, [clean.ts](./src/cli/clean.ts) deletes artifacts with `GENERATED_MARKER` filtering, [discover.ts](./src/cli/discover.ts) builds `GENERATION-PLAN.md`, [init.ts](./src/cli/init.ts) writes config YAML, [specify.ts](./src/cli/specify.ts) synthesizes project specs from `AGENTS.md` corpus.\n\n**[src/ai/](./src/ai/)** — Backend-agnostic AI service layer: [subprocess.ts](./src/ai/subprocess.ts) spawns `execFile()` child processes with resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`, `--disallowedTools Task`), process group killing `kill(-pid)`, SIGTERM/SIGKILL timeout escalation; [retry.ts](./src/ai/retry.ts) implements exponential backoff detecting rate limits via stderr patterns; [service.ts](./src/ai/service.ts) orchestrates `call()` → `retry()` → `runSubprocess()` → backend adapter; [telemetry/](./src/ai/telemetry/) writes NDJSON logs to `.agents-reverse-engineer/logs/run-<timestamp>.json` with token/cost tracking, enforces 50-run retention; [backends/](./src/ai/backends/) implements ClaudeBackend (Zod JSON parsing), GeminiBackend/OpenCodeBackend stubs throwing `SUBPROCESS_ERROR`.\n\n**[src/discovery/](./src/discovery/)** — File discovery pipeline: [walker.ts](./src/discovery/walker.ts) chains four filters (GitignoreFilter → VendorFilter → BinaryFilter → CustomPatternFilter) via `applyFilters()` with 30-worker concurrency, [run.ts](./src/discovery/run.ts) executes `walkDirectory()` via `fast-glob` with `{absolute: true, onlyFiles: true, ignore: ['**/.git/**']}`, returns `DiscoveryResult` with `included[]`/`excluded[]` attribution and `stats.exclusionReasons` histogram.\n\n**[src/generation/](./src/generation/)** — Three-phase orchestration: [orchestrator.ts](./src/generation/orchestrator.ts) `GenerationOrchestrator.createPlan()` executes file discovery → `analyzeComplexity()` → `buildFilePrompt()` per file → post-order directory traversal (depth-sorted) → root synthesis; [prompts/builder.ts](./src/generation/prompts/builder.ts) constructs prompts consuming `.sum` frontmatter, child `AGENTS.md`, import maps via `extractDirectoryImports()`, detects 9 manifest types; [writers/](./src/generation/writers/) serializes YAML frontmatter with adaptive array formatting, preserves user content via `AGENTS.local.md` rename pattern.\n\n**[src/orchestration/](./src/orchestration/)** — Worker pool and progress tracking: [pool.ts](./src/orchestration/pool.ts) iterator-based pool shares single `tasks.entries()` across N workers, emits `worker:start/end` and `task:pickup/done` trace events; [runner.ts](./src/orchestration/runner.ts) `CommandRunner.executeGenerate()` runs concurrent Phase 1, post-order Phase 2, sequential Phase 3 with quality validators; [progress.ts](./src/orchestration/progress.ts) streams colored console output with ETA via moving average (last 10 completion times), mirrors to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes; [trace.ts](./src/orchestration/trace.ts) appends NDJSON to `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson` with auto-populated `seq`/`ts`/`pid`/`elapsedMs` base fields, enforces 500-file retention; [plan-tracker.ts](./src/orchestration/plan-tracker.ts) serializes concurrent checkbox updates (`- [ ] → - [x]`) for `GENERATION-PLAN.md`.\n\n**[src/change-detection/](./src/change-detection/)** — Git-based incremental updates: [detector.ts](./src/change-detection/detector.ts) parses `git diff --name-status -M` with rename detection, merges uncommitted working tree changes via `status.modified[]`/`deleted[]`, computes SHA-256 content hashes, returns `ChangeDetectionResult` with `FileChange[]` array mapping `ChangeType` status codes ('added'/'modified'/'deleted'/'renamed').\n\n**[src/update/](./src/update/)** — Incremental documentation synchronization: [orchestrator.ts](./src/update/orchestrator.ts) `UpdateOrchestrator.preparePlan()` executes hash-based change detection via `readSumFile()` YAML frontmatter extraction → `computeContentHash()` SHA-256 comparison → produces `UpdatePlan` with `filesToAnalyze[]`/`filesToSkip[]`/`cleanup`/`affectedDirs[]` (depth-sorted); [orphan-cleaner.ts](./src/update/orphan-cleaner.ts) deletes `.sum` files for `FileChange` entries with `status === 'deleted'` or `status === 'renamed'`, removes `AGENTS.md` from directories containing only hidden files/`.sum` files/generated artifacts.\n\n**[src/quality/](./src/quality/)** — Code-documentation consistency validation: [inconsistency/code-vs-doc.ts](./src/quality/inconsistency/code-vs-doc.ts) extracts exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` with substring verification against `.sum` content; [inconsistency/code-vs-code.ts](./src/quality/inconsistency/code-vs-code.ts) aggregates exports into `Map<symbol, paths[]>` for duplicate detection; [phantom-paths/validator.ts](./src/quality/phantom-paths/validator.ts) extracts path references via three regex patterns (markdown links, backtick paths, prose references) resolving against `AGENTS.md` directory and project root with `.ts`/`.js` fallback; [inconsistency/reporter.ts](./src/quality/inconsistency/reporter.ts) merges issues with summary counts by type/severity.\n\n**[src/config/](./src/config/)** — Configuration management: [loader.ts](./src/config/loader.ts) `loadConfig()` reads `.agents-reverse-engineer/config.yaml` via YAML parsing and `ConfigSchema.parse()` Zod validation (returns defaults on ENOENT, throws `ConfigError` on ZodError), `writeDefaultConfig()` generates commented template with inline defaults, `getDefaultConcurrency()` computes adaptive worker pool size via `clamp(cores * 5, 2, min(memCap, 20))` where `memCap = floor((totalMemGB * 0.5) / 0.512)`.\n\n**[src/imports/](./src/imports/)** — Static import analysis: [extractor.ts](./src/imports/extractor.ts) `extractImports()` applies `IMPORT_REGEX` (`/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm`) extracting ES module syntax into `ImportEntry[]`, `extractDirectoryImports()` scans first 100 lines per file, partitions relative imports into `internal`/`external`, filters bare specifiers.\n\n**[src/installer/](./src/installer/)** — npx installation orchestrator: [index.ts](./src/installer/index.ts) `runInstall()` parses CLI args (`-g`/`-l`/`--runtime`/`--force`), interactive prompts via [prompts.ts](./src/installer/prompts.ts) `selectRuntime()`/`selectLocation()`, [operations.ts](./src/installer/operations.ts) `installFilesForRuntime()` writes command templates from `src/integration/templates.ts` and copies bundled hooks from `hooks/dist/`, registers hooks in `settings.json` via `registerClaudeHooks()`/`registerGeminiHooks()`, writes `ARE-VERSION` file, adds Bash permission patterns to Claude Code allow list; [uninstall.ts](./src/installer/uninstall.ts) removes files, hook registrations, permissions, cleans empty skill directories.\n\n**[src/integration/](./src/integration/)** — Platform-specific AI assistant integration: [detect.ts](./src/integration/detect.ts) `detectEnvironments()` scans for Claude (`.claude/` or `CLAUDE.md`), OpenCode (`.opencode/`), Aider (`.aider.conf.yml` or `.aider/`) via `existsSync()`; [templates.ts](./src/integration/templates.ts) `getTemplatesForRuntime()` generates command files with placeholder substitution for `COMMAND_PREFIX`, `VERSION_FILE_PATH`, `$ARGUMENTS`, embeds background execution pattern with `run_in_background: true` + `TaskOutput` polling + `.agents-reverse-engineer/progress.log` monitoring; [generate.ts](./src/integration/generate.ts) `generateIntegrationFiles()` writes templates via `ensureDir()` → `writeFileSync()` chain, copies bundled hooks for Claude.\n\n**[src/specify/](./src/specify/)** — Specification synthesis: [prompts.ts](./src/specify/prompts.ts) `buildSpecPrompt()` constructs system/user prompts enforcing nine-section structure (Overview, Architecture, API Surface, Data Structures, Configuration, Dependencies, Behavioral Contracts, Test Contracts, Build Plan) with verbatim regex/format/constant preservation; [writer.ts](./src/specify/writer.ts) `writeSpec()` writes single-file or multi-file specifications via heading-based splitting (`splitByHeadings()` partitions on `/^# /m`, `slugify()` sanitizes heading text), throws `SpecExistsError` when targets exist and `force: false`.\n\n**[src/output/](./src/output/)** — Terminal output formatting: [logger.ts](./src/output/logger.ts) `createLogger()` factory with picocolors-based ANSI formatting when `options.colors` is true, `createSilentLogger()` no-op for tests, `Logger` interface with six methods (`info()`, `file()`, `excluded()`, `summary()`, `warn()`, `error()`), output routing (log/warn/error → stdout/stderr).\n\n**[src/types/](./src/types/)** — Shared interfaces: [index.ts](./src/types/index.ts) defines `ExcludedFile`, `DiscoveryResult`, `DiscoveryStats` with `exclusionReasons` histogram, consumed by `src/discovery/walker.ts`, `src/cli/discover.ts`, `src/orchestration/runner.ts`.\n\n## Architecture\n\n### Three-Phase RLM Pipeline\n\n**Phase 1: File Analysis** — Iterator-based worker pool (`src/orchestration/pool.ts`) shares single `tasks.entries()` iterator across N workers (default 2 for WSL, 5 elsewhere) invoking `AIService.call()` → `runSubprocess()` → `execFile()` spawning AI CLI subprocesses with resource limits (heap 512MB, thread pool 4, background tasks disabled, Task tool disallowed). Process group killing (`kill(-pid)`) terminates subprocess trees on timeout (SIGTERM at `timeoutMs`, SIGKILL after 5s). Exponential backoff retry on rate limits (stderr patterns: \"rate limit\", \"429\", \"too many requests\", \"overloaded\"). Writes `.sum` files with YAML frontmatter (`generated_at`, `content_hash`, `purpose`, `critical_todos`, `related_files`) + markdown summary body.\n\n**Phase 2: Directory Aggregation** — Post-order traversal sorts directories by depth descending (`path.relative().split(path.sep).length`), waits for all child `.sum` files via `isDirectoryComplete()` predicate. `buildDirectoryPrompt()` aggregates child `.sum` content via `readSumFile()`, subdirectory `AGENTS.md` files via recursive traversal, import maps via `extractDirectoryImports()` with verified path constraints, manifest detection (9 types: `package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`, `pom.xml`, `build.gradle`, `Gemfile`, `composer.json`, `CMakeLists.txt`/`Makefile`). User-authored `AGENTS.md` files renamed to `AGENTS.local.md` and prepended above generated content. Writes `AGENTS.md` with `<!-- Generated by agents-reverse-engineer -->` marker.\n\n**Phase 3: Root Document Synthesis** — Sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`. Prompts consume all `AGENTS.md` files via `collectAgentsDocs()` recursive tree traversal, parse root `package.json` for project metadata, enforce synthesis-only constraints (no invention of features/hooks/patterns not in source documents). Strips conversational preamble via pattern matching before writing output.\n\n### Incremental Update Strategy\n\n`UpdateOrchestrator.preparePlan()` workflow: (1) read `content_hash` from `.sum` YAML frontmatter via `readSumFile()`, (2) compute current SHA-256 via `computeContentHash()`, (3) hash mismatch → add to `filesToAnalyze` as `FileChange` with `status: 'modified'`/`'added'`, (4) hash match → add to `filesToSkip`, (5) detect orphans: `.sum` files for deleted source files or renamed oldPaths, (6) call `cleanupOrphans()` to delete stale `.sum` files, (7) call `cleanupEmptyDirectoryDocs()` to remove `AGENTS.md` from directories with no remaining sources, (8) compute `affectedDirs` via `getAffectedDirectories()` by walking parent directories of changed files, (9) regenerate `.sum` for `filesToAnalyze` via Phase 1 pool execution, (10) regenerate `AGENTS.md` for `affectedDirs` sequentially (no Phase 2 post-order traversal required). Git integration: supports committed changes (`git diff <baseCommit>..HEAD`) and uncommitted (`git status --porcelain` merge via `--uncommitted` flag), rename detection via `git diff -M` (50% similarity threshold), fallback to SHA-256 hashing for non-git workflows.\n\n### Subprocess Resource Management\n\nMitigations for Claude CLI excessive thread spawning (GitHub issue #5771: 200 NodeJS instances reported): `NODE_OPTIONS='--max-old-space-size=512'` limits heap to 512MB per subprocess, `UV_THREADPOOL_SIZE='4'` constrains libuv thread pool to 4 threads, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` prevents background task spawning, `--disallowedTools Task` blocks subagents. Process group killing: `kill(-pid)` terminates entire subprocess tree. Timeout enforcement: SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period. Default concurrency reduced from 5 → 2 for resource-constrained environments.\n\n### Telemetry & Tracing\n\n**Run logs** (`.agents-reverse-engineer/logs/run-<timestamp>.json`) aggregate per-call token counts, costs, durations, errors, track `filesRead[]` metadata with `path`/`sizeBytes`/`linesRead`, compute summary (`totalInputTokens`, `totalCacheReadTokens`, `errorCount`, `uniqueFilesRead`), enforce retention via `cleanupOldLogs(keepCount)` after each run.\n\n**Trace events** (`.agents-reverse-engineer/traces/trace-<timestamp>.ndjson`) enabled via `--trace` flag emit `phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry` events with auto-populated fields (`seq`, `ts`, `pid`, `elapsedMs`), promise-chain serialization ensures NDJSON line order matches emission order despite concurrent workers, retention keeps 500 most recent traces via `cleanupOldTraces(keepCount)`.\n\n**Progress log** (`.agents-reverse-engineer/progress.log`) human-readable streaming output mirroring console, ETA calculation via moving average of last 10 task durations, quality metrics (code-vs-doc/code-vs-code inconsistencies, phantom path counts), real-time monitoring via `tail -f .agents-reverse-engineer/progress.log`.\n\n### Quality Validation\n\n**Code-vs-Doc Consistency** — Extracts exported symbols via regex `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`, verifies all exports appear in `.sum` summary text via substring search, reports `CodeDocInconsistency` with `missingFromDoc` arrays.\n\n**Code-vs-Code Duplicate Detection** — Aggregates exports across per-directory file groups into `Map<symbol, string[]>`, reports `CodeCodeInconsistency` for symbols appearing in multiple files (pattern: `'duplicate-export'`).\n\n**Phantom Path Resolution** — Extracts path-like strings from `AGENTS.md` via three regex patterns (markdown link targets `/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g`, backtick-quoted paths `` /`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g ``, prose-embedded paths `/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi`), resolves against `AGENTS.md` directory and project root with `.ts`/`.js` fallback, reports `PhantomPathInconsistency` for unresolved references.\n\n## Behavioral Contracts\n\n**GENERATED_MARKER:** `<!-- Generated by agents-reverse-engineer -->`\n\n**Frontmatter extraction regex:** `/^---\\n([\\s\\S]*?)\\n---\\n/`\n\n**YAML field patterns:**\n```javascript\n/generated_at:\\s*(.+)/\n/content_hash:\\s*(.+)/\n/purpose:\\s*(.+)/\n/key:\\s*\\[([^\\]]*)\\]/  // Inline arrays\n/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m  // Multi-line arrays\n```\n\n**Array formatting heuristic:** Inline if `length <= 3` and all items `< 40` chars, multi-line otherwise.\n\n**Export extraction regex:** `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`\n\n**Path extraction patterns (phantom-paths):**\n```javascript\n/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g              // Markdown: [text](./path)\n/`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g  // Backtick: `src/foo.ts`\n/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi // Prose: \"from src/foo/\"\n```\n\n**Rate limit detection patterns:** `['rate limit', '429', 'too many requests', 'overloaded'].some(p => stderr.toLowerCase().includes(p))`\n\n**Preamble stripping patterns:**\n1. YAML separator: `/\\n---\\n/` within first 500 chars\n2. Bold uppercase start: `/^[\\s\\S]{0,500}?(\\*\\*[A-Z])/` matches conversational preamble, strips if <300 chars and no `##` headers\n\n**Skip directories:** `Set(['node_modules', '.git', '.agents-reverse-engineer', 'vendor', 'dist', 'build', '__pycache__', '.next', 'venv', '.venv', 'target', '.cargo', '.gradle'])`\n\n**Manifest detection:** `['package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml', 'pom.xml', 'build.gradle', 'Gemfile', 'composer.json', 'CMakeLists.txt', 'Makefile']`\n\n**Git commands:**\n- Change detection: `git diff --name-status -M <baseCommit>..HEAD` (rename detection 50% threshold)\n- Uncommitted changes: `git status --porcelain` merged with `status.modified[]`/`deleted[]`/`not_added[]`/`staged[]`\n- SHA-256 content hash fallback for non-git workflows\n\n**Detached subprocess spawn pattern:**\n```javascript\nspawn(process.execPath, ['-e', scriptString], { \n  stdio: 'ignore', \n  detached: true, \n  windowsHide: true \n}).unref()\n```\n\n**Hook disable mechanisms:**\n- Environment variable: `ARE_DISABLE_HOOK=1`\n- Config substring: `readFileSync('.agents-reverse-engineer.yaml', 'utf-8').includes('hook_enabled: false')`\n### docs/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# docs\n\nOriginal design specification and research artifacts defining the Recursive Language Model (RLM) algorithm and agents-reverse-engineer tool inception rationale.\n\n## Contents\n\n### [INPUT.md](./INPUT.md)\nInception document defining the RLM algorithm via post-order tree traversal (leaf file analysis → directory aggregation → root synthesis), proposed command interface (`/are-generate`, `/are-update`), session lifecycle integration requirements, and research directives for GSD/BMAD methodology analysis.\n\n## Purpose\n\n`INPUT.md` serves as the foundational design specification established before implementation began. It defines the core RLM workflow: (1) build project tree, (2) traverse post-order starting at deepest leaves, (3) generate `.sum` summaries for files, (4) generate `AGENTS.md` for directories once all children complete, (5) recurse upward to project root. The document specifies target AI platforms (Claude Code, OpenCode, Gemini) and automatic documentation synchronization via session-end hooks.\n\n## Relationship to Implementation\n\nThe three-phase pipeline in `src/generation/orchestrator.ts` implements the RLM algorithm specified here:\n- **Phase 1** (concurrent file analysis) → `.sum` generation for leaf nodes\n- **Phase 2** (post-order directory aggregation) → `AGENTS.md` synthesis with depth-based sorting\n- **Phase 3** (root synthesis) → `CLAUDE.md`/`GEMINI.md`/`OPENCODE.md` platform-specific integration documents\n\nSession lifecycle hooks in `hooks/are-session-end.js` and `hooks/opencode-are-session-end.js` implement the automatic update mechanism proposed in this specification.\n### hooks/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# hooks/\n\n**Session lifecycle hooks for Claude Code, Gemini CLI, and OpenCode runtimes that execute version checking on session start and incremental documentation updates on session end via detached background processes.**\n\n## Contents\n\n### Session Start Hooks\n\n**[are-check-update.js](./are-check-update.js)** — Claude/Gemini SessionStart hook spawning detached `npm view agents-reverse-engineer version` subprocess, comparing against local `ARE-VERSION` file (project `.claude/ARE-VERSION` before global `~/.claude/ARE-VERSION`), writing comparison result to `~/.claude/cache/are-update-check.json` with schema `{ update_available, installed, latest, checked }`.\n\n**[opencode-are-check-update.js](./opencode-are-check-update.js)** — OpenCode plugin exporting `AreCheckUpdate()` async factory returning `event['session.created']` handler that spawns detached npm version check subprocess, writes cache to `~/.config/opencode/cache/are-update-check.json`.\n\n### Session End Hooks\n\n**[are-session-end.js](./are-session-end.js)** — Claude/Gemini SessionEnd hook executing `git status --porcelain` change detection, spawning detached `npx agents-reverse-engineer@latest update --quiet` subprocess if uncommitted changes detected, exits silently if `ARE_DISABLE_HOOK=1` or config contains `hook_enabled: false` substring.\n\n**[opencode-are-session-end.js](./opencode-are-session-end.js)** — OpenCode plugin exporting `AreSessionEnd()` async factory returning `event['session.deleted']` handler that executes identical git status check and detached update spawn as Claude/Gemini variant.\n\n## Architecture\n\n### Detached Subprocess Pattern\n\nAll hooks use identical background process spawning pattern:\n```javascript\nspawn(process.execPath, ['-e', scriptString], { \n  stdio: 'ignore', \n  detached: true, \n  windowsHide: true \n}).unref()\n```\n\nInline script via `-e` flag executes synchronous Node.js APIs (`execSync`, `readFileSync`, `writeFileSync`) in isolated process that survives parent termination. `stdio: 'ignore'` prevents output blocking session lifecycle, `unref()` allows parent exit without waiting for completion.\n\n### Version File Resolution\n\nCheck update hooks read sentinel `ARE-VERSION` file in priority order:\n1. Project-local: `<cwd>/.{claude,opencode}/ARE-VERSION`\n2. Global: `~/{.claude,.config/opencode}/ARE-VERSION`\n\nFalls back to `'0.0.0'` if neither exists. Installer writes this file during setup (`src/installer/operations.ts`).\n\n### Cache Schema\n\nVersion check subprocess writes JSON to platform-specific cache:\n- Claude/Gemini: `~/.claude/cache/are-update-check.json`\n- OpenCode: `~/.config/opencode/cache/are-update-check.json`\n\n**Format:**\n```json\n{\n  \"update_available\": boolean,\n  \"installed\": \"semver-string\",\n  \"latest\": \"semver-string\" | \"unknown\",\n  \"checked\": 1234567890\n}\n```\n\n### Disable Mechanisms\n\nSession-end hooks exit silently when:\n- `process.env.ARE_DISABLE_HOOK === '1'`\n- `.agents-reverse-engineer.yaml` exists and contains substring `'hook_enabled: false'` (no YAML parser)\n\n### Change Detection\n\nSession-end hooks execute `execSync('git status --porcelain', { encoding: 'utf-8' })` and exit silently if output is empty (no uncommitted changes) or if command throws (non-git repo).\n\n## File Relationships\n\n**Hook installation:** `src/installer/operations.ts` copies hooks to platform-specific directories and writes `ARE-VERSION` sentinel file.\n\n**Build process:** `scripts/build-hooks.js` copies hook files to `hooks/dist/` directory for npm tarball inclusion before publish.\n\n**Session-end update invocation:** Spawns `npx agents-reverse-engineer@latest update --quiet` which executes `src/cli/update.ts` orchestrator with hash-based change detection and incremental regeneration.\n\n**Platform path resolution:** `src/installer/paths.ts` provides platform-specific config directory lookup respecting environment overrides (`CLAUDE_CONFIG_DIR`, `OPENCODE_CONFIG_DIR`, `GEMINI_CONFIG_DIR`).\n\n## Behavioral Contracts\n\n**Git status command:** `'git status --porcelain'` with `{ encoding: 'utf-8' }` — detects uncommitted changes (modified/staged/untracked files).\n\n**npm version query:** `'npm view agents-reverse-engineer version'` with `{ encoding: 'utf8', timeout: 10000, windowsHide: true }` — queries registry for latest published version.\n\n**Update invocation:** `['npx', 'agents-reverse-engineer@latest', 'update', '--quiet']` — spawns latest published version with `--quiet` flag suppressing terminal output.\n\n**Config disable check pattern:** `readFileSync('.agents-reverse-engineer.yaml', 'utf-8').includes('hook_enabled: false')` — substring match without YAML parsing for fast disable detection.\n\n**Cache directory creation:** `mkdirSync(cacheDir, { recursive: true })` — ensures `~/{.claude,.config/opencode}/cache/` exists before subprocess spawn.\n### scripts/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# scripts/\n\nBuild automation utilities for npm package distribution. Currently contains a single script that prepares session lifecycle hooks for inclusion in the published npm tarball.\n\n## Contents\n\n**[build-hooks.js](./build-hooks.js)** — Copies `.js` hook files from `hooks/` to `hooks/dist/` via synchronous `copyFileSync()`, filtering non-JS files and the dist directory itself, invoked by `npm run build:hooks` and `prepublishOnly` lifecycle hook.\n\n## Build Pipeline Integration\n\n**Execution trigger:** `build-hooks.js` runs during `npm run prepublishOnly`, which npm automatically invokes before `npm publish`. The package.json `scripts` section chains `prepublishOnly` → `npm run build && npm run build:hooks`, ensuring TypeScript compilation (`tsc`) and hook copying both complete before tarball creation.\n\n**Distribution requirement:** Session lifecycle hooks (`are-check-update.js`, `are-session-end.js`, `opencode-are-check-update.js`, `opencode-are-session-end.js`) must exist in `hooks/dist/` for the npm tarball to include them. The installer module (`src/installer/operations.ts`) copies these files from the installed package into IDE config directories (`~/.claude/hooks/`, `~/.config/opencode/plugins/`).\n\n## File Operations\n\n**Path resolution:** Uses ES module `import.meta.url` → `fileURLToPath()` → `__dirname` pattern to locate project root. Constructs `HOOKS_SRC` as `join(projectRoot, 'hooks')` and `HOOKS_DIST` as `join(projectRoot, 'hooks', 'dist')`.\n\n**Synchronous workflow:**\n1. `existsSync(HOOKS_DIST)` checks for dist directory\n2. `mkdirSync(HOOKS_DIST, { recursive: true })` creates directory if missing\n3. `readdirSync(HOOKS_SRC)` enumerates source files\n4. `.filter(f => f.endsWith('.js') && f !== 'dist')` excludes non-JavaScript files and dist directory\n5. `copyFileSync(join(HOOKS_SRC, file), join(HOOKS_DIST, file))` copies each hook file\n6. Console logs progress: per-file `\"Copied: {file} -> hooks/dist/{file}\"` and summary `\"Done. {count} hook(s) built.\"`\n\n## Behavioral Contracts\n\n**File filter predicate:** `/\\.js$/ && f !== 'dist'` (endsWith check + exclusion)\n### src/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src\n\n**TypeScript source tree containing CLI entry points, three-phase AI orchestration pipeline, file discovery filters, configuration management, subprocess-spawning AI service layer, quality validators, and IDE integration installers for agents-reverse-engineer brownfield documentation generator.**\n\n## Contents\n\n**[version.ts](./version.ts)** — `getVersion()` reads `package.json` from compiled module parent directory (dist/ → project root) via `fileURLToPath(import.meta.url)` → `dirname()` → `join(__dirname, '..', 'package.json')`, parses JSON extracting `version` field, returns `'unknown'` on error (file not found, JSON parse failure, missing field). Called by CLI help text, version flag output, session hooks for npm registry comparison.\n\n## Subdirectories\n\n**[ai/](./ai/)** — Backend-agnostic AI service orchestration: subprocess-spawning adapters (ClaudeBackend with Zod JSON parsing, GeminiBackend/OpenCodeBackend stubs), exponential backoff retry with rate limit detection (['rate limit', '429', 'too many requests', 'overloaded']), timeout enforcement (SIGTERM at timeoutMs, SIGKILL after 5s, process group killing `kill(-pid)`), NDJSON telemetry logging to `.agents-reverse-engineer/logs/run-<timestamp>.json` with token/cost tracking, trace emission (subprocess:spawn/exit/retry).\n\n**[change-detection/](./change-detection/)** — Git-based change detection parsing `git diff --name-status -M` with rename detection, merges uncommitted working tree changes via `status.modified[]`/`deleted[]`/`not_added[]`/`staged[]`, SHA-256 content hashing for `.sum` frontmatter verification, returns `ChangeDetectionResult` with `FileChange[]` array (path/status/oldPath/contentHash), status codes map to `ChangeType` ('added'/'modified'/'deleted'/'renamed').\n\n**[cli/](./cli/)** — Command entry points routing parsed `process.argv` to handlers: `initCommand()` writes config YAML, `cleanCommand()` deletes artifacts with `GENERATED_MARKER` filtering, `discoverCommand()` builds `GENERATION-PLAN.md`, `generateCommand()` orchestrates three-phase pipeline with backend resolution, `updateCommand()` executes incremental hash-based regeneration, `specifyCommand()` synthesizes project specifications from AGENTS.md corpus. Main index parses flags via `parseArgs()` with short flag expansion (`-h` → `help`, `-g` → `global`), dual routing for installer mode vs. command dispatch, exit codes (0=success, 1=partial failure, 2=total failure/CLI not found).\n\n**[config/](./config/)** — Configuration management: `loadConfig()` reads `.agents-reverse-engineer/config.yaml` via YAML parsing and `ConfigSchema.parse()` Zod validation (returns defaults on ENOENT, throws `ConfigError` on ZodError), `writeDefaultConfig()` generates commented template with inline defaults, `getDefaultConcurrency()` computes adaptive worker pool size via `clamp(cores * 5, 2, min(memCap, 20))` where `memCap = floor((totalMemGB * 0.5) / 0.512)`, default exclusions (26 patterns, 18 vendor dirs, 26 binary extensions).\n\n**[discovery/](./discovery/)** — File discovery pipeline: `discoverFiles()` creates four-filter chain (GitignoreFilter → VendorFilter → BinaryFilter → CustomPatternFilter), `walkDirectory()` via `fast-glob` with `{absolute: true, onlyFiles: true, ignore: ['**/.git/**']}`, `applyFilters()` with 30-worker concurrency and short-circuit evaluation, returns `FilterResult` with `included[]`/`excluded[]` attribution. Filters normalize paths via `path.relative(normalizedRoot, absolutePath)` for pattern matching.\n\n**[generation/](./generation/)** — Three-phase orchestration: `GenerationOrchestrator.createPlan()` executes file discovery → `analyzeComplexity()` → `buildFilePrompt()` per file with `projectPlan` injection → groups by `path.dirname()` for directory tasks → `buildExecutionPlan()` post-order traversal (sorted by depth descending) → memory management clears `PreparedFile.content` fields after embedding. `buildDirectoryPrompt()` reads `.sum` frontmatter, child `AGENTS.md`, import maps via `extractDirectoryImports()`, detects 9 manifest types. `buildRootPrompt()` calls `collectAgentsDocs()`, parses root `package.json`, enforces synthesis-only constraints. Writers serialize YAML frontmatter (adaptive array formatting), preserve user content via `AGENTS.local.md` rename pattern.\n\n**[imports/](./imports/)** — Static import analysis: `extractImports()` applies `IMPORT_REGEX` (`/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm`) extracting ES module syntax into `ImportEntry[]`, `extractDirectoryImports()` scans first 100 lines per file for optimization, partitions relative imports into `internal` (`./`) and `external` (`../`), filters bare specifiers (`'react'`, `node:*`), `formatImportMap()` serializes into prompt text blocks with `(type)` suffix.\n\n**[installer/](./installer/)** — npx installation orchestrator: `runInstall()` parses CLI args (`-g`/`-l`/`--runtime`/`--force`), interactive prompts via `selectRuntime()`/`selectLocation()` with arrow-key selection in TTY mode, `installFilesForRuntime()` writes command templates from `src/integration/templates.ts` and copies bundled hooks from `hooks/dist/`, registers hooks in `settings.json` via `registerClaudeHooks()`/`registerGeminiHooks()`, writes `ARE-VERSION` file, adds Bash permission patterns to Claude Code allow list. Uninstaller removes files, hook registrations, permissions, cleans empty skill directories via `cleanupAreSkillDirs()`/`cleanupLegacyGeminiFiles()`/`cleanupEmptyDirs()`.\n\n**[integration/](./integration/)** — Platform-specific AI assistant integration: `detectEnvironments()` scans for Claude (`.claude/` or `CLAUDE.md`), OpenCode (`.opencode/`), Aider (`.aider.conf.yml` or `.aider/`) via `existsSync()`, `getTemplatesForRuntime()` generates command files with placeholder substitution for `COMMAND_PREFIX` (`/are-`), `VERSION_FILE_PATH`, `$ARGUMENTS`, embeds background execution pattern with `run_in_background: true`, `TaskOutput` polling, `.agents-reverse-engineer/progress.log` monitoring. `generateIntegrationFiles()` writes templates via `ensureDir()` → `writeFileSync()` chain, copies bundled hooks for Claude.\n\n**[orchestration/](./orchestration/)** — Iterator-based worker pool orchestrating three-phase execution: `runPool()` shares single `tasks.entries()` iterator across N workers preventing idle time, emits `worker:start/end` and `task:pickup/done` trace events, supports `failFast` abort via mutable flag. `CommandRunner.executeGenerate()` runs concurrent file `.sum` generation with stale-doc detection, post-order directory `AGENTS.md` traversal grouped by depth, sequential root document synthesis (`CLAUDE.md`/`GEMINI.md`/`OPENCODE.md`), embeds quality validators post-phase (code-vs-doc, code-vs-code, phantom-paths). `ProgressReporter` streams colored console output with ETA via moving average (last 10 completion times), `ProgressLog` mirrors to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes. `PlanTracker` serializes concurrent checkbox updates (`- [ ] → - [x]`) for `GENERATION-PLAN.md` via promise-chain pattern. `TraceWriter` appends to `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson` with auto-populated `seq`/`ts`/`pid`/`elapsedMs` base fields, `cleanupOldTraces()` enforces 500-file retention.\n\n**[output/](./output/)** — Terminal output formatting: `createLogger()` factory with picocolors-based ANSI formatting when `options.colors` is true, `createSilentLogger()` no-op for tests, `Logger` interface (six methods: `info()`, `file()`, `excluded()`, `summary()`, `warn()`, `error()`), output routing (log/warn/error → stdout/stderr).\n\n**[quality/](./quality/)** — Code-documentation consistency validation: `checkCodeVsDoc()` extracts exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` with substring verification against `.sum` content, `checkCodeVsCode()` aggregates exports into `Map<symbol, paths[]>` for duplicate detection, `checkPhantomPaths()` extracts path references via three regex patterns (markdown links, backtick paths, prose references) resolving against `AGENTS.md` directory and project root with `.ts`/`.js` fallback. `buildInconsistencyReport()` merges issues with summary counts by type (`code-vs-doc`/`code-vs-code`/`phantom-path`) and severity (`error`/`warning`/`info`).\n\n**[specify/](./specify/)** — Specification synthesis: `buildSpecPrompt()` constructs system/user prompts enforcing nine-section structure (Overview, Architecture, API Surface, Data Structures, Configuration, Dependencies, Behavioral Contracts, Test Contracts, Build Plan) with verbatim regex/format/constant preservation, `writeSpec()` writes single-file or multi-file specifications via heading-based splitting (`splitByHeadings()` partitions on `/^# /m`, `slugify()` sanitizes heading text), throws `SpecExistsError` when targets exist and `force: false`.\n\n**[types/](./types/)** — Shared interfaces for discovery results (`ExcludedFile`, `DiscoveryResult`, `DiscoveryStats` with `exclusionReasons` histogram), consumed by `src/discovery/walker.ts`, `src/cli/discover.ts`, `src/orchestration/runner.ts`.\n\n**[update/](./update/)** — Incremental documentation synchronization: `UpdateOrchestrator.preparePlan()` executes hash-based change detection via `readSumFile()` YAML frontmatter extraction, `computeContentHash()` SHA-256 comparison, produces `UpdatePlan` with `filesToAnalyze[]` (hash mismatch/missing), `filesToSkip[]` (hash match), `cleanup: CleanupResult` (orphaned `.sum` files), `affectedDirs[]` (depth-sorted parent directories). `cleanupOrphans()` deletes `.sum` files for `FileChange` entries with `status === 'deleted'` (uses `change.path`) or `status === 'renamed'` (uses `change.oldPath`). `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` from directories containing only hidden files, `.sum` files, or generated artifacts. `getAffectedDirectories()` walks parent directories via `path.dirname()` excluding deletes.\n\n## Three-Phase Pipeline Architecture\n\n**Phase 1 (File Analysis)** — Concurrent pool execution (default 2 workers for WSL, 5 elsewhere): `GenerationOrchestrator.createFileTasks()` invokes `buildFilePrompt()` per file embedding content + project structure, workers execute via `runPool()` calling `AIService.call()` → `runSubprocess()` → `execFile()` spawning AI CLI subprocesses with resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`, `--disallowedTools Task`). Results written via `writeSumFile()` to `.sum` paths with YAML frontmatter (`generated_at`, `content_hash`, `purpose`, `critical_todos`, `related_files`). Post-phase quality validation: throttled (concurrency=10) `checkCodeVsDoc()` comparing old vs. new `.sum` against source content, `checkCodeVsCode()` for duplicate symbol detection.\n\n**Phase 2 (Directory Aggregation)** — Post-order traversal: `GenerationOrchestrator.createDirectoryTasks()` groups files via `Map<dirname, PreparedFile[]>`, executor sorts tasks by `getDirectoryDepth()` descending (deepest first), waits for child `.sum` files via `isDirectoryComplete()`, constructs prompts via `buildDirectoryPrompt()` consuming `.sum` frontmatter + child `AGENTS.md` + import maps from `extractDirectoryImports()`. Writes via `writeAgentsMd()` preserving user content from `AGENTS.local.md`. Post-phase: runs `checkPhantomPaths()` on each generated `AGENTS.md` (three regex patterns for path extraction), aggregates issues into `phantomReport`.\n\n**Phase 3 (Root Synthesis)** — Sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md` via `buildRootPrompt()` aggregating all `AGENTS.md` via `collectAgentsDocs()`, parsing root `package.json`, enforcing synthesis-only constraints (no invention). Strips conversational preamble via pattern matching before writing output.\n\n## Subprocess Resource Management\n\nAI CLI spawning mitigations for Claude #5771 (200 NodeJS instances): `NODE_OPTIONS='--max-old-space-size=512'` limits heap to 512MB per subprocess, `UV_THREADPOOL_SIZE='4'` constrains libuv thread pool to 4 threads, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` prevents background task spawning, `--disallowedTools Task` blocks subagents. Process group killing: `kill(-pid)` terminates entire subprocess tree. Timeout enforcement: SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period. Default concurrency reduced from 5 → 2 for resource-constrained environments.\n\n## Incremental Update Strategy\n\n`UpdateOrchestrator.preparePlan()` workflow: (1) read `content_hash` from `.sum` YAML frontmatter via `readSumFile()`, (2) compute current SHA-256 via `computeContentHash()`, (3) hash mismatch → add to `filesToAnalyze` as `FileChange` with `status: 'modified'`/`'added'`, (4) hash match → add to `filesToSkip`, (5) detect orphans: `.sum` files for deleted source files or renamed oldPaths, (6) call `cleanupOrphans()` to delete stale `.sum` files, (7) call `cleanupEmptyDirectoryDocs()` to remove `AGENTS.md` from directories with no remaining sources, (8) compute `affectedDirs` via `getAffectedDirectories()` walking parent directories of changed files, (9) regenerate `.sum` for `filesToAnalyze` via Phase 1 pool execution, (10) regenerate `AGENTS.md` for `affectedDirs` sequentially (no Phase 2 post-order traversal required). Git integration: supports committed changes (`git diff <baseCommit>..HEAD`) and uncommitted (`git status --porcelain` merge via `--uncommitted` flag), rename detection via `git diff -M` (50% similarity threshold), fallback to SHA-256 hashing for non-git workflows.\n\n## Behavioral Contracts\n\n**GENERATED_MARKER:** `<!-- Generated by agents-reverse-engineer -->`\n\n**Frontmatter extraction regex:** `/^---\\n([\\s\\S]*?)\\n---\\n/`\n\n**YAML field patterns:**\n```javascript\n/generated_at:\\s*(.+)/\n/content_hash:\\s*(.+)/\n/purpose:\\s*(.+)/\n/key:\\s*\\[([^\\]]*)\\]/  // Inline arrays\n/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m  // Multi-line arrays\n```\n\n**Array formatting heuristic:** Inline if `length <= 3` and all items `< 40` chars, multi-line otherwise.\n\n**Export extraction regex:** `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`\n\n**Path extraction patterns (phantom-paths):**\n```javascript\n/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g              // Markdown: [text](./path)\n/`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g  // Backtick: `src/foo.ts`\n/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi // Prose: \"from src/foo/\"\n```\n\n**Rate limit detection patterns:** `['rate limit', '429', 'too many requests', 'overloaded'].some(p => stderr.toLowerCase().includes(p))`\n\n**Preamble stripping patterns:**\n1. YAML separator: `/\\n---\\n/` within first 500 chars\n2. Bold uppercase start: `/^[\\s\\S]{0,500}?(\\*\\*[A-Z])/` matches conversational preamble, strips if <300 chars and no `##` headers\n\n**Skip directories:** `Set(['node_modules', '.git', '.agents-reverse-engineer', 'vendor', 'dist', 'build', '__pycache__', '.next', 'venv', '.venv', 'target', '.cargo', '.gradle'])`\n\n**Manifest detection:** `['package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml', 'pom.xml', 'build.gradle', 'Gemfile', 'composer.json', 'CMakeLists.txt', 'Makefile']`\n### src/ai/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai\n\nBackend-agnostic AI service orchestration layer: subprocess-spawning adapters for Claude Code/Gemini/OpenCode CLIs, exponential backoff retry logic with rate limit detection, timeout enforcement via SIGTERM/SIGKILL escalation, NDJSON telemetry logging with token cost tracking, and trace event emission for concurrent pool workflows.\n\n## Contents\n\n**[index.ts](./index.ts)** — Barrel export consolidating AIService, BackendRegistry, createBackendRegistry, resolveBackend, detectBackend, getInstallInstructions, withRetry, runSubprocess, isCommandOnPath with type re-exports (AIBackend, AIResponse, AICallOptions, SubprocessResult, RetryOptions, TelemetryEntry, RunLog, FileRead, AIServiceError).\n\n**[registry.ts](./registry.ts)** — BackendRegistry stores AIBackend implementations in insertion-order Map with `register(backend)`, `get(name)`, `getAll()` methods; createBackendRegistry() pre-populates ClaudeBackend/GeminiBackend/OpenCodeBackend; resolveBackend(registry, 'auto'|name) performs auto-detection or explicit lookup throwing CLI_NOT_FOUND with install instructions.\n\n**[retry.ts](./retry.ts)** — withRetry() executes async function with exponential backoff (delay = min(baseDelayMs × multiplier^attempt, maxDelayMs) + jitter[0..500ms]) calling isRetryable(error) predicate before each retry, invoking onRetry(attempt, error) callback for telemetry.\n\n**[service.ts](./service.ts)** — AIService orchestrates call(options) via runSubprocess() wrapped in withRetry(), detects rate limits via stderr pattern matching (['rate limit', '429', 'too many requests', 'overloaded']), emits subprocess:spawn/exit/retry trace events, accumulates TelemetryEntry records via internal TelemetryLogger, writes RunLog to `.agents-reverse-engineer/logs/run-<timestamp>.json` on finalize(), enforces cleanup via cleanupOldLogs(keepRuns).\n\n**[subprocess.ts](./subprocess.ts)** — runSubprocess() spawns child process via execFile() with stdin piping, timeout enforcement (SIGTERM at timeoutMs, SIGKILL after 5s grace), process group killing (`kill(-pid)`) for tree termination, concurrent subprocess tracking via Map<pid, {command, spawnedAt}>, returns SubprocessResult with stdout/stderr/exitCode/signal/durationMs/timedOut/childPid.\n\n**[types.ts](./types.ts)** — Defines AIBackend interface (isAvailable/buildArgs/parseResponse/getInstallInstructions), AICallOptions (prompt/systemPrompt/model/timeoutMs/maxTurns/taskLabel), AIResponse (text/model/inputTokens/outputTokens/cacheReadTokens/cacheCreationTokens/durationMs/exitCode/raw), SubprocessResult, RetryOptions, TelemetryEntry, RunLog with summary aggregation, FileRead, AIServiceError with discriminated codes ('CLI_NOT_FOUND'|'TIMEOUT'|'PARSE_ERROR'|'SUBPROCESS_ERROR'|'RATE_LIMIT').\n\n## Subdirectories\n\n**[backends/](./backends/)** — ClaudeBackend with Zod-validated JSON parsing extracting usage.input_tokens/output_tokens/cache_read_input_tokens/cache_creation_input_tokens, GeminiBackend/OpenCodeBackend stubs throwing SUBPROCESS_ERROR, isCommandOnPath() cross-platform PATH detection with Windows PATHEXT extension iteration.\n\n**[telemetry/](./telemetry/)** — TelemetryLogger accumulates per-call entries computing aggregate summary (totalInputTokens/totalCacheReadTokens/errorCount/uniqueFilesRead), writeRunLog() serializes to `.agents-reverse-engineer/logs/run-<timestamp>.json` with filename sanitization (`/[:.]/g → '-'`), cleanupOldLogs() enforces retention via lexicographic sort on ISO 8601 filenames.\n\n## Architecture\n\n### Three-Layer Design\n\n**Backend Adapter Layer** (backends/): AIBackend implementations translate AICallOptions into CLI-specific argv arrays via buildArgs(), parse stdout JSON into normalized AIResponse via parseResponse(), detect availability via isCommandOnPath() checking PATH directories with Windows PATHEXT handling.\n\n**Subprocess Execution Layer** (subprocess.ts): runSubprocess() spawns execFile() with 10MB maxBuffer, writes input to stdin via Buffer.byteLength() computed payload, enforces timeout via SIGTERM then SIGKILL escalation with unref()'d timer, kills process groups via negative PID (`process.kill(-child.pid, 'SIGKILL')`), tracks active subprocesses in Map for concurrency monitoring.\n\n**Service Orchestration Layer** (service.ts): AIService wraps runSubprocess() calls in withRetry() with isRateLimitStderr() predicate detecting ['rate limit', '429', 'too many requests', 'overloaded'] patterns, emits subprocess:spawn/exit trace events via ITraceWriter, accumulates TelemetryEntry[] via TelemetryLogger, finalizes RunLog with summary (totalInputTokens, totalCacheReadTokens, errorCount, uniqueFilesRead).\n\n### Retry Strategy\n\nwithRetry() executes fn() up to maxRetries+1 times with exponential backoff: `min(baseDelayMs * multiplier^attempt, maxDelayMs) + random(0..500ms)`. Checks isRetryable(error) before each sleep—permanently fails on auth errors or non-retryable signals. Invokes onRetry(attempt, error) before delay for trace emission. AIService.call() only retries RATE_LIMIT errors (code === 'RATE_LIMIT'), treats TIMEOUT as permanent failure to prevent resource exhaustion.\n\n### Timeout Enforcement\n\nrunSubprocess() sends SIGTERM at timeoutMs via execFile killSignal option. Sets unref()'d SIGKILL timer at `timeoutMs + 5000ms`. Clears timer in callback if process exits before escalation. Process group killing (`kill(-pid)`) terminates entire subprocess tree. Falls back to single-process kill if group signal fails.\n\n### Telemetry Pipeline\n\nAIService.call() records TelemetryEntry after each subprocess completion with timestamp/prompt/systemPrompt/response/model/inputTokens/outputTokens/cacheReadTokens/cacheCreationTokens/latencyMs/exitCode/error/retryCount/thinking/filesRead. TelemetryLogger.addEntry() appends to in-memory entries[]. AIService.addFilesReadToLastEntry(filesRead) mutates most recent entry to attach FileRead[] metadata (path + sizeBytes). AIService.finalize() calls TelemetryLogger.toRunLog() computing summary, writes to `.agents-reverse-engineer/logs/run-<timestamp>.json` via writeRunLog(), enforces retention via cleanupOldLogs(keepRuns).\n\n### Resource Management\n\nSubprocess limits injected by AIService via environment variables (set in src/ai/service.ts, executed in subprocess.ts):\n- `NODE_OPTIONS='--max-old-space-size=512'` — limits heap to 512MB per subprocess\n- `UV_THREADPOOL_SIZE='4'` — constrains libuv thread pool to 4 threads\n- `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` — prevents background task spawning\n- CLI args: `--disallowedTools Task` — blocks subagent spawning\n\nactiveSubprocesses Map tracks concurrent processes keyed by PID with {command, spawnedAt}. getActiveSubprocessCount() returns Map size. getActiveSubprocesses() computes runningMs as `Date.now() - spawnedAt`.\n\n### Debug Logging\n\nAIService.setDebug(true) enables stderr output before/after subprocess with heapUsed/rss metrics via formatBytes(). AIService.setSubprocessLogDir(dir) writes per-subprocess `.log` files with metadata header (task/pid/command/exit/signal/duration/timed_out) followed by stdout/stderr sections. Serialized via logWriteQueue promise chain preventing concurrent mkdir races. Failures silently swallowed (non-critical).\n\n## Integration Points\n\n**Phase 1 Orchestration**: `src/generation/executor.ts` calls AIService.call() for each .sum file generation passing prompt from `src/generation/prompts/builder.ts`, attaches filesRead metadata via addFilesReadToLastEntry() after file analysis.\n\n**Worker Pool**: `src/orchestration/pool.ts` shares single AIService instance across N workers (default 2 for WSL, 5 elsewhere), monitors concurrency via getActiveSubprocessCount(), emits trace events via AIService.setTracer(tracer).\n\n**Trace Emission**: AIService subprocess:spawn/exit events serialized to `.agents-reverse-engineer/traces/trace-<timestamp>.ndjson` via `src/orchestration/trace.ts` TraceWriter with promise-chain ordering guarantees.\n\n**Registry Auto-Detection**: `src/cli/generate.ts` calls createBackendRegistry() then resolveBackend(registry, config.ai.backend) for backend selection, throws CLI_NOT_FOUND with install instructions when backend unavailable.\n\n**Incremental Updates**: `src/update/orchestrator.ts` reuses same AIService instance for modified file regeneration, shares telemetry accumulation across discovery + analysis phases.\n\n## Behavioral Contracts\n\n### Rate Limit Detection Patterns\n\n```javascript\n['rate limit', '429', 'too many requests', 'overloaded'].some(p => \n  stderr.toLowerCase().includes(p)\n)\n```\n\n### Timeout Detection\n\n```javascript\nresult.timedOut === true  // set when error.killed === true in execFile callback\n```\n\n### Exit Code Extraction\n\n```javascript\nerror === null ? 0\n: typeof error.code === 'number' ? error.code\n: child.exitCode !== null ? child.exitCode\n: 1\n```\n\n### Process Group Killing\n\n```javascript\nprocess.kill(-child.pid, 'SIGKILL')  // negative PID targets process group\n```\n\n### Filename Sanitization\n\n```javascript\nrunLog.startTime.replace(/[:.]/g, '-')  // ISO 8601 → filesystem-safe\n// Example: 2026-02-07T12:00:00.000Z → run-2026-02-07T12-00-00-000Z.json\n```\n\n### Log File Filtering\n\n```javascript\nname.startsWith('run-') && name.endsWith('.json')\n```\n### src/ai/backends/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai/backends\n\n**Backend adapter implementations for Claude Code, Gemini CLI, and OpenCode providing AIBackend interface compliance with CLI argument construction, JSON response parsing, PATH availability detection, and installation instructions.**\n\n## Contents\n\n### Backend Implementations\n\n**[claude.ts](./claude.ts)** — ClaudeBackend adapter with Zod-validated JSON parsing extracting `text`/`model`/`inputTokens`/`outputTokens`/`cacheReadTokens`/`cacheCreationTokens` from Claude CLI v2.1.31 output, `buildArgs()` constructing `['-p', '--output-format', 'json', '--no-session-persistence', '--permission-mode', 'bypassPermissions']` base arguments with conditional `--model`/`--system-prompt`/`--max-turns` appends, `isCommandOnPath()` cross-platform PATH detection handling Windows `PATHEXT` extension iteration.\n\n**[gemini.ts](./gemini.ts)** — GeminiBackend stub returning `['-p', '--output-format', 'json']` from `buildArgs()` but throwing `SUBPROCESS_ERROR` in `parseResponse()` until Gemini JSON output format stabilizes per RESEARCH.md Open Question 2.\n\n**[opencode.ts](./opencode.ts)** — OpenCodeBackend stub returning `['run', '--format', 'json']` from `buildArgs()` but throwing `SUBPROCESS_ERROR` in `parseResponse()` until JSONL parsing implementation completes per RESEARCH.md Open Question 3.\n\n## AIBackend Interface Contract\n\nAll backends implement five required methods:\n\n- **`isAvailable(): Promise<boolean>`** — Delegates to `isCommandOnPath(this.cliCommand)` checking PATH directories via `fs.stat().isFile()` with Windows PATHEXT handling\n- **`buildArgs(options: AICallOptions): string[]`** — Constructs CLI argument arrays (prompt content delivered via stdin by `runSubprocess()` caller, not CLI arg)\n- **`parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse`** — Normalizes CLI output to `{ text, model, inputTokens, outputTokens, cacheReadTokens, cacheCreationTokens, durationMs, exitCode, raw }` structure\n- **`getInstallInstructions(): string`** — Returns multiline installation guidance with npm/curl commands and documentation URLs\n- **Properties:** `name: string` (backend identifier), `cliCommand: string` (executable name)\n\n## Claude Response Schema\n\n`ClaudeResponseSchema` validates JSON structure:\n\n```typescript\n{\n  type: 'result',\n  subtype: 'success'|'error',\n  is_error: boolean,\n  duration_ms: number,\n  duration_api_ms: number,\n  num_turns: number,\n  result: string,\n  session_id: string,\n  total_cost_usd: number,\n  usage: {\n    input_tokens: number,\n    cache_creation_input_tokens: number,\n    cache_read_input_tokens: number,\n    output_tokens: number\n  },\n  modelUsage: Record<string, {\n    inputTokens: number,\n    outputTokens: number,\n    cacheReadInputTokens: number,\n    cacheCreationInputTokens: number,\n    costUSD: number\n  }>\n}\n```\n\n## Integration with Registry\n\nBackends registered in `src/ai/registry.ts` `AIBackendRegistry.backends` array enabling `detectAvailableBackend()` auto-detection via parallel `isAvailable()` checks. Registry returns first available backend when `config.ai.backend === 'auto'`.\n\n## PATH Detection Strategy\n\n`isCommandOnPath()` implements cross-platform availability checking:\n\n1. Reads `process.env.PATH`, strips double quotes, splits by `path.delimiter` (`:` Unix, `;` Windows)\n2. Reads `process.env.PATHEXT` on Windows (e.g., `.COM;.EXE;.BAT;.CMD`), defaults to `['']` on Unix\n3. Iterates PATH directories × PATHEXT extensions constructing candidate paths\n4. Calls `fs.stat(candidatePath).isFile()` returning `true` on first match (avoids Unix execute bit assumptions)\n5. Returns `false` if no candidates exist as files\n\n## Error Handling\n\nClaudeBackend throws `AIServiceError` with codes:\n\n- **`PARSE_ERROR`** — When `stdout.indexOf('{')` returns `-1` (includes first 200 chars of raw output)\n- **`PARSE_ERROR`** — When Zod validation fails (includes validation error message)\n\nStub backends throw:\n\n- **`SUBPROCESS_ERROR`** — GeminiBackend/OpenCodeBackend until parsing implementation completes\n\n## Behavioral Contracts\n\n### ClaudeBackend CLI Arguments\n\nBase arguments (always included):\n```\n-p\n--output-format json\n--no-session-persistence\n--permission-mode bypassPermissions\n```\n\nConditional arguments:\n```\n--model <value>               # if options.model present\n--system-prompt <value>       # if options.systemPrompt present\n--max-turns <value>           # if options.maxTurns !== undefined\n```\n\n### JSON Parsing Defensive Pattern\n\n```javascript\nconst jsonStart = stdout.indexOf('{')\nif (jsonStart === -1) {\n  throw new AIServiceError('PARSE_ERROR', `No JSON in output: ${stdout.slice(0, 200)}`)\n}\nconst parsed = ClaudeResponseSchema.parse(JSON.parse(stdout.slice(jsonStart)))\n```\n\n### Windows PATHEXT Extensions\n\n```\n.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC\n```\n### src/ai/telemetry/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/ai/telemetry\n\nPersistent telemetry accumulation and retention management: in-memory RunLog assembly via TelemetryLogger, JSON serialization with sanitized ISO 8601 filenames, and log rotation enforcing configurable retention limits.\n\n## Contents\n\n**[cleanup.ts](./cleanup.ts)** — `cleanupOldLogs(projectRoot, keepCount)` deletes old run log files from `.agents-reverse-engineer/logs/`, retaining N most recent via lexicographic sort on ISO 8601 filenames, handles ENOENT gracefully.\n\n**[logger.ts](./logger.ts)** — `TelemetryLogger` class accumulates per-call `TelemetryEntry` objects in memory, computes aggregate summary statistics (total tokens/costs/errors, unique files read), exports `toRunLog()` for serialization.\n\n**[run-log.ts](./run-log.ts)** — `writeRunLog(projectRoot, runLog)` writes RunLog JSON to `.agents-reverse-engineer/logs/run-<timestamp>.json` with directory creation and filename sanitization (`/[:.]/g` → `-`).\n\n## Architecture\n\n**Single-Run Lifecycle:**\n1. CLI invokes `new TelemetryLogger(runId)` with ISO timestamp, captures `startTime`\n2. AIService calls `addEntry(entry)` after each subprocess completion, `setFilesReadOnLastEntry(filesRead)` after file metadata attachment\n3. CLI invokes `toRunLog()` to freeze in-memory state into RunLog structure with computed summary\n4. `writeRunLog()` persists JSON to disk with 2-space indentation\n5. `cleanupOldLogs(projectRoot, config.ai.telemetry.keepRuns)` removes oldest files beyond retention limit\n\n**Cross-Run Retention:**\n- Log filenames encode sortable timestamps via `run-2026-02-07T12-00-00-000Z.json` pattern\n- Lexicographic sort produces correct chronological ordering without timestamp parsing\n- Retention enforced via `entries.slice(keepCount)` after newest-first reversal\n\n## Data Flow\n\n```\nAIService subprocess\n  ↓ (per-call metrics)\nTelemetryLogger.addEntry()\n  ↓ (in-memory accumulation)\nTelemetryLogger.toRunLog()\n  ↓ (RunLog structure with summary)\nwriteRunLog()\n  ↓ (filesystem persistence)\n.agents-reverse-engineer/logs/run-<timestamp>.json\n  ↓ (retention enforcement)\ncleanupOldLogs() removes oldest files\n```\n\n## RunLog Summary Computation\n\n`TelemetryLogger.getSummary()` iterates all `entries[]` to compute:\n- `totalInputTokens`, `totalOutputTokens`, `totalCacheReadTokens`, `totalCacheCreationTokens` (sum of per-call counts)\n- `totalDurationMs` (sum of `latencyMs` values)\n- `errorCount` (count where `error !== undefined`)\n- `totalFilesRead` (sum of `filesRead.length` across entries)\n- `uniqueFilesRead` (cardinality of `Set<string>` from all `file.path` values)\n\nRecomputes on every invocation without caching (safe because typically called once at run end).\n\n## Filesystem Safety\n\n**Filename Sanitization:**\n- ISO 8601 contains `:` (Windows path separator) and `.` (shell metacharacter)\n- `runLog.startTime.replace(/[:.]/g, '-')` produces cross-platform-safe filenames\n- Example: `2026-02-07T12:00:00.000Z` → `run-2026-02-07T12-00-00-000Z.json`\n\n**Directory Creation:**\n- `fs.mkdir()` with `recursive: true` creates `.agents-reverse-engineer/logs/` if absent\n- `cleanupOldLogs()` catches ENOENT from `fs.readdir()` and returns `0` when logs directory missing\n\n## Integration Points\n\n- **TelemetryLogger** threaded via `CommandRunOptions.telemetryLogger` → AIService constructor → per-call hooks\n- **writeRunLog** called by command runners after run completion when `config.ai.telemetry.enabled === true`\n- **cleanupOldLogs** invoked immediately after `writeRunLog()` with `config.ai.telemetry.keepRuns` (default 50)\n- Complements `src/orchestration/trace.ts` which retains 500 NDJSON trace files via similar lexicographic sort + slice pattern\n\n## Type Dependencies\n\nAll modules import from `../types.js`:\n- `TelemetryEntry`: per-call metrics with `inputTokens`, `outputTokens`, `cacheReadTokens`, `cacheCreationTokens`, `latencyMs`, `error?: string`, `filesRead: FileRead[]`\n- `RunLog`: container with `runId`, `startTime`, `endTime`, `entries: TelemetryEntry[]`, `summary` (aggregate statistics)\n- `FileRead`: file metadata with `path`, `sizeBytes`, `linesRead`\n\n## Behavioral Contracts\n\n**Filename Pattern:**\n```regex\n^run-\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2}-\\d{3}Z\\.json$\n```\nMatches sanitized ISO 8601 timestamps where `:` and `.` replaced with `-`.\n\n**Log File Filtering:**\n```typescript\nname.startsWith('run-') && name.endsWith('.json')\n```\nIsolates run log files from other potential artifacts in `.agents-reverse-engineer/logs/`.\n\n**Timestamp Sanitization Transform:**\n```javascript\nrunLog.startTime.replace(/[:.]/g, '-')\n```\nConverts ISO 8601 string to filesystem-safe filename component.\n### src/change-detection/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/change-detection\n\nGit-based change detection and SHA-256 content hashing for incremental documentation updates. Parses `git diff --name-status -M` with rename detection, merges uncommitted working tree changes, and computes file content hashes for `.sum` frontmatter verification.\n\n## Contents\n\n### Core Implementation\n\n**[detector.ts](./detector.ts)** — Implements `isGitRepo()`, `getCurrentCommit()`, `getChangedFiles()` with git diff parsing, `computeContentHash()` and `computeContentHashFromString()` for SHA-256 hex digest generation. Parses status codes (`'A'`/`'M'`/`'D'`/`'R'` prefix) from `git diff --name-status -M` (50% similarity threshold), merges `status.modified[]`, `status.deleted[]`, `status.not_added[]`, `status.staged[]` when `includeUncommitted` is true. Returns `ChangeDetectionResult` with `currentCommit`, `baseCommit`, `changes[]`, `includesUncommitted`.\n\n**[types.ts](./types.ts)** — Defines `ChangeType` union (`'added' | 'modified' | 'deleted' | 'renamed'`), `FileChange` interface with `path`, `status`, optional `oldPath` (renames), optional `contentHash`, `ChangeDetectionResult` interface with `currentCommit`, `baseCommit`, `changes[]`, `includesUncommitted`, and `ChangeDetectionOptions` interface with `includeUncommitted` flag.\n\n**[index.ts](./index.ts)** — Barrel export re-exporting `isGitRepo()`, `getCurrentCommit()`, `getChangedFiles()`, `computeContentHash()`, `computeContentHashFromString()` from `detector.ts` and all types from `types.ts`.\n\n## Integration Points\n\n- **src/update/orchestrator.ts**: Calls `getChangedFiles()` with `includeUncommitted` flag, compares `FileChange.contentHash` against `.sum` YAML frontmatter `content_hash` field, builds `filesToAnalyze` and `filesToSkip` sets, uses `ChangeType === 'deleted' | 'renamed'` for orphan cleanup targeting.\n- **src/generation/writers/sum.ts**: Calls `computeContentHash()` before writing `.sum` files to populate YAML frontmatter `content_hash` field.\n- **src/update/orphan-cleaner.ts**: Uses `FileChange.oldPath` (renames) and `FileChange.path` (deletes) to identify stale `.sum` files requiring removal.\n\n## Behavioral Contracts\n\n**Git diff parsing:** Splits `git diff --name-status -M` output on newlines, splits lines on tab separator. Status codes map to `ChangeType`:\n- `'A'` → `status: 'added'`\n- `'M'` → `status: 'modified'`\n- `'D'` → `status: 'deleted'`\n- `startsWith('R')` → `status: 'renamed'` with `oldPath = parts[1]`, `path = parts[parts.length - 1]`\n\n**SHA-256 hashing:** Uses `crypto.createHash('sha256').update(content).digest('hex')` producing lowercase hex string (64 characters). Matches YAML frontmatter pattern `content_hash: [a-f0-9]{64}`.\n\n**Uncommitted merge:** When `includeUncommitted` is true, deduplicates via `changes.some(c => c.path === file)` before pushing `status.modified[]`, `status.deleted[]`, `status.not_added[]`, `status.staged[]` entries.\n### src/cli/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/cli\n\nCLI command entry points for the agents-reverse-engineer tool, routing parsed arguments to specialized command handlers and orchestrating multi-phase documentation generation workflows.\n\n## Contents\n\n### [clean.ts](./clean.ts)\n`cleanCommand()` deletes generated artifacts (`.sum`, `AGENTS.md` with marker, `CLAUDE.md`, `GENERATION-PLAN.md`) via `fast-glob` discovery, filters `AGENTS.md` by `GENERATED_MARKER` presence, restores `AGENTS.local.md` backups, preserves user-authored files.\n\n### [discover.ts](./discover.ts)\n`discoverCommand()` executes file discovery via `discoverFiles()` filter chain, builds `GenerationPlan` via `createOrchestrator().createPlan()`, transforms via `buildExecutionPlan()` post-order traversal, writes markdown to `GENERATION-PLAN.md`, emits `discovery:start/end` trace events with `filesIncluded/filesExcluded/durationMs` metrics.\n\n### [generate.ts](./generate.ts)\n`generateCommand()` orchestrates three-phase pipeline: resolves AI backend via `resolveBackend()`, instantiates `AIService` with timeout/retry/model config, executes `runner.executeGenerate()` for concurrent file analysis → directory aggregation → root synthesis, writes telemetry/traces, exits with status 0/1/2 for success/partial/total failure.\n\n### [index.ts](./index.ts)\nMain entry point (`#!/usr/bin/env node`) parses `process.argv` via `parseArgs()`, routes to command handlers (`initCommand`, `cleanCommand`, `discoverCommand`, `generateCommand`, `updateCommand`, `specifyCommand`), invokes `runInstaller()` for install/uninstall/interactive modes, prints version via `getVersion()` and usage via `USAGE` constant.\n\n### [init.ts](./init.ts)\n`initCommand()` creates `.agents-reverse-engineer/config.yaml` via `writeDefaultConfig()`, checks existence via `configExists()`, warns on `force: false` when config exists, exits on `EACCES/EPERM` errors, logs guidance referencing `exclude.patterns`, `ai.concurrency`, `ai.backend`.\n\n### [specify.ts](./specify.ts)\n`specifyCommand()` synthesizes project specifications from `AGENTS.md` corpus: collects docs via `collectAgentsDocs()`, auto-invokes `generateCommand()` if no docs exist, resolves backend via `resolveBackend()`, constructs prompt via `buildSpecPrompt()`, calls `AIService.call()` with extended timeout (≥600,000ms), writes output via `writeSpec()`, logs telemetry with token/duration summary.\n\n### [update.ts](./update.ts)\n`updateCommand()` executes incremental update workflow: generates `UpdatePlan` via `createUpdateOrchestrator().preparePlan()` with SHA-256 hash comparison, spawns concurrent AI analysis via `runner.executeUpdate()` for `filesToAnalyze`, regenerates `AGENTS.md` sequentially for `affectedDirs`, finalizes telemetry via `aiService.finalize()`, exits with code 0/1/2 for success/partial/total failure.\n\n## Command Routing Logic\n\n`index.ts` implements dual argument parsing paths: (1) interactive installer mode when `args.length === 0`, (2) explicit command routing when first non-flag arg matches `install|uninstall|init|clean|discover|generate|update|specify`. Installer flags (`--global/-g`, `--local/-l`, `--runtime`, `--force`) trigger `runInstaller()` with `parseInstallerArgs()`. Short flags (`-h`, `-g`, `-l`, `-V`) mapped to long forms (`help`, `global`, `local`, `version`) via inline switch statement. Flags parsed into `Set<string>` for boolean presence checks, `Map<string, string>` for key-value pairs (`--concurrency 3`, `--output ./path`). Positional args extracted after command via filter for non-flag strings (missing leading `--` or `-`).\n\n## Shared Options Pattern\n\n`GenerateOptions` interface defines six fields: `dryRun`, `concurrency`, `failFast`, `debug`, `trace`, reused by `generate.ts`/`update.ts`. `UpdateCommandOptions` extends with `uncommitted` boolean for working tree inclusion. `SpecifyOptions` adds `output` string, `force` boolean, `multiFile` boolean for directory-split output. `CleanOptions` contains only `dryRun`. Option construction in `index.ts` uses `flags.has()` for boolean checks, `values.get()` with `parseInt()` for numeric coercion, `values.get()` for string paths.\n\n## Progress Logging Strategy\n\n`discover.ts`, `generate.ts`, `update.ts`, `specify.ts` create `ProgressLog` instances via `ProgressLog.create(absolutePath)` writing to `.agents-reverse-engineer/progress.log` with ISO 8601 timestamp headers (`=== ARE <Command> (${new Date().toISOString()}) ===`), project path, file counts, phase summaries. `CommandRunner` receives `progressLog` in constructor, streams task pickup/completion events with ETA calculations. Finalized via `progressLog.finalize()` before exit. Designed for `tail -f` monitoring pattern (documented in CLAUDE.md \"Progress log\" section).\n\n## Trace Integration\n\n`generate.ts`, `update.ts`, `discover.ts` support `--trace` flag enabling NDJSON trace emission via `createTraceWriter(absolutePath, options.trace ?? false)` called before config loading. Tracer passed to `loadConfig()`, `createUpdateOrchestrator()`, `CommandRunner`, `discoverFiles()` as `options.tracer`. Events include `phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`, `discovery:start/end`. Finalized via `tracer.finalize()` followed by `cleanupOldTraces(absolutePath)` enforcing 500-file retention limit. Trace paths logged to stderr via `pc.dim('[trace] Writing to <path>')`.\n\n## Backend Resolution Workflow\n\n`generate.ts`, `update.ts`, `specify.ts` resolve AI backend via four-step pattern: (1) create registry via `createBackendRegistry()`, (2) call `resolveBackend(registry, config.ai.backend)` returning first available CLI (Claude/Gemini/OpenCode) or throwing `AIServiceError` with `code: 'CLI_NOT_FOUND'`, (3) catch error and print installation instructions via `getInstallInstructions(registry)` to stderr, (4) call `process.exit(2)` on CLI absence. Instantiate `AIService` with backend and config options `{ timeoutMs, maxRetries, model, telemetry }`, enable debug mode via `aiService.setDebug(true)` if `options.debug`, configure subprocess log directory via `aiService.setSubprocessLogDir(logDir)` if `options.trace`.\n\n## Exit Code Strategy\n\nCommands use three exit codes consistently: **0** for success (all files succeeded or no files to process), **1** for partial failure (`summary.filesFailed > 0 && summary.filesProcessed > 0`), **2** for total failure (`summary.filesProcessed === 0 && summary.filesFailed > 0`) or CLI not found during backend resolution. `update.ts` exits early with implicit code 0 on first run detection (`plan.isFirstRun`) or no changes (`filesToAnalyze.length === 0 && cleanup counts === 0`). `specify.ts` exits with code 1 on `SpecExistsError` during `writeSpec()`, code 2 on `AIServiceError` with `CLI_NOT_FOUND`. `init.ts` exits with code 1 on `EACCES/EPERM` during `writeDefaultConfig()`.\n\n## Dry-Run Mode Handling\n\n`generate.ts` shows plan summary via `formatPlan()` and task breakdown via `buildExecutionPlan()` without backend resolution when `options.dryRun === true`. `update.ts` displays plan via `formatPlan(plan)` including baseline commit, file statuses (`+` added, `R` renamed, `M` modified, `=` unchanged), cleanup actions, affected directories, exits before AI service instantiation. `specify.ts` computes `estimatedTokensK = Math.ceil(totalChars / 4) / 1000`, prints doc count/token estimate/output path/mode table, warns if exceeds 150K tokens. `clean.ts` enumerates artifacts to delete with `pc.dim()` paths, skips `unlink()`/`rename()` calls, prints `Dry run — no files were changed.` in yellow.\n\n## Telemetry Finalization\n\n`generate.ts`, `update.ts`, `specify.ts` finalize telemetry via `aiService.finalize(absolutePath)` returning `summary` with fields `totalInputTokens`, `totalOutputTokens`, `totalDurationMs`, `filesRead[]`. Log summary line formatted as `Tokens: ${totalInputTokens} in / ${totalOutputTokens} out | Duration: ${(totalDurationMs / 1000).toFixed(1)}s | Output: ${outputPath}`. `update.ts` records run state via `orchestrator.recordRun(currentCommit, filesProcessed, filesSkipped)` after finalization (legacy no-op since frontmatter hash migration).\n\n## Auto-Generation Fallback\n\n`specify.ts` checks `docs.length === 0` after `collectAgentsDocs()`, invokes `generateCommand(targetPath, { debug, trace })` when no AGENTS.md files exist and not in dry-run mode, re-collects docs after generation, exits with code 1 if still zero. Prints `No AGENTS.md files found after generation. Cannot proceed.` in red. Prevents specification synthesis with empty corpus.\n### src/config/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/config\n\nConfiguration management layer providing YAML-based project configuration with Zod schema validation, adaptive concurrency computation based on system resources, and default exclusion rules for file discovery.\n\n## Contents\n\n### Core Modules\n\n**[schema.ts](./schema.ts)** — Exports `ConfigSchema` (root Zod schema accepting empty object), `ExcludeSchema` (patterns/vendorDirs/binaryExtensions arrays), `OptionsSchema` (followSymlinks/maxFileSize), `OutputSchema` (colors boolean), `AISchema` (backend enum/model/timeoutMs/maxRetries/concurrency/telemetry with dynamic default via `getDefaultConcurrency()` invocation), and inferred TypeScript types `Config`, `ExcludeConfig`, `OptionsConfig`, `OutputConfig`, `AIConfig`.\n\n**[loader.ts](./loader.ts)** — Exports `loadConfig(root, options)` reading `.agents-reverse-engineer/config.yaml` via YAML parsing and `ConfigSchema.parse()` validation (returns defaults on ENOENT, emits `config:loaded` trace event, throws `ConfigError` on ZodError/parse failures), `configExists(root)` checking file presence via `fs.access()`, `writeDefaultConfig(root)` generating commented YAML template with inline defaults, `ConfigError` class extending Error with `filePath` and `cause` properties, and constants `CONFIG_DIR` ('.agents-reverse-engineer'), `CONFIG_FILE` ('config.yaml').\n\n**[defaults.ts](./defaults.ts)** — Exports `getDefaultConcurrency()` computing worker pool size via formula `clamp(cores * 5, 2, min(memCap, 20))` where `memCap = floor((totalMemGB * 0.5) / 0.512)` caps memory usage at 50% of RAM divided by 512MB subprocess heap budget, constants `DEFAULT_VENDOR_DIRS` (18 directories: node_modules/.git/dist/build/__pycache__/.next/venv/.venv/target/.cargo/.gradle/.agents-reverse-engineer/.agents/.planning/.claude/.opencode/.gemini/vendor), `DEFAULT_EXCLUDE_PATTERNS` (26 globs: AI docs/lock files/dotfiles), `DEFAULT_BINARY_EXTENSIONS` (26 extensions: images/archives/executables/media/documents/fonts/compiled), `DEFAULT_MAX_FILE_SIZE` (1MB threshold), and `DEFAULT_CONFIG` object spreading all default arrays.\n\n## Configuration Schema Hierarchy\n\nConfigSchema composes four nested schemas via Zod object merging:\n\n1. **exclude** (ExcludeSchema) — File/directory filtering rules\n   - `patterns: string[]` — Gitignore-style globs (default: 26 patterns excluding AGENTS.md/CLAUDE.md/lock files/*.sum/*.log)\n   - `vendorDirs: string[]` — Third-party directories to skip (default: 18 directories)\n   - `binaryExtensions: string[]` — Non-text file extensions (default: 26 extensions)\n\n2. **options** (OptionsSchema) — Discovery traversal behavior\n   - `followSymlinks: boolean` — Enable symlink following (default: false)\n   - `maxFileSize: number` — Binary detection threshold in bytes (default: 1048576 = 1MB)\n\n3. **output** (OutputSchema) — CLI rendering preferences\n   - `colors: boolean` — Enable ANSI color codes (default: true)\n\n4. **ai** (AISchema) — AI service orchestration parameters\n   - `backend: 'claude' | 'gemini' | 'opencode' | 'auto'` — CLI backend selection (default: 'auto')\n   - `model: string` — Backend-specific model identifier (default: 'sonnet')\n   - `timeoutMs: number` — Subprocess timeout milliseconds (default: 300000 = 5 minutes)\n   - `maxRetries: number` — Exponential backoff retry attempts (default: 3, min: 0)\n   - `concurrency: number` — Worker pool size (default: dynamic via `getDefaultConcurrency()`, min: 1, max: 20)\n   - `telemetry.keepRuns: number` — Run log retention count (default: 50, min: 0)\n\n## Adaptive Concurrency Algorithm\n\n`getDefaultConcurrency()` implements memory-aware concurrency calculation:\n\n1. **CPU-based baseline**: `cores * 5` where `cores = os.availableParallelism() || os.cpus().length`\n2. **Memory capacity ceiling**: `memCap = floor((totalMemGB * 0.5) / 0.512)` allocating 50% of system RAM with 512MB per subprocess\n3. **Clamping**: `max(2, min(baseline, memCap, 20))` enforcing [2, 20] interval\n4. **Edge case handling**: Returns Infinity when `totalMemGB <= 1` to bypass memory constraint on low-RAM systems\n\nConstants:\n- `CONCURRENCY_MULTIPLIER = 5` (CPU core scaling factor)\n- `MIN_CONCURRENCY = 2` (floor matching WSL default)\n- `MAX_CONCURRENCY = 20` (ceiling matching Zod `.max(20)` constraint)\n- `SUBPROCESS_HEAP_GB = 0.512` (512MB heap budget from `NODE_OPTIONS='--max-old-space-size=512'` in subprocess.ts)\n- `MEMORY_FRACTION = 0.5` (allocate 50% of total RAM to pool)\n\n## Configuration Loading Workflow\n\n`loadConfig(root, options)` executes sequence:\n\n1. **Path resolution**: Constructs `${root}/.agents-reverse-engineer/config.yaml`\n2. **File read**: `readFile(configPath, 'utf-8')` with ENOENT catch returning `ConfigSchema.parse({})`\n3. **YAML parsing**: `parse(rawYaml)` with Error catch wrapped in ConfigError\n4. **Schema validation**: `ConfigSchema.parse(raw)` with ZodError catch formatted as `${path}: ${message}`\n5. **Trace emission**: `tracer?.emit({ type: 'config:loaded', configPath, model, concurrency })`\n6. **Debug output**: `console.error(pc.dim(JSON.stringify(config, null, 2)))` when `options.debug` enabled\n\nError paths throw ConfigError with:\n- `message`: Formatted validation errors or YAML parse message\n- `filePath`: Absolute config file path\n- `cause`: Underlying ZodError or Error instance\n\n## Default Configuration Template\n\n`writeDefaultConfig(root)` generates YAML with four comment-delimited sections:\n\n```yaml\n# FILE & DIRECTORY EXCLUSIONS\nexclude:\n  patterns: [...26 quoted globs...]\n  vendorDirs: [...18 directory names...]\n  binaryExtensions: [...26 extensions...]\n\n# DISCOVERY OPTIONS\noptions:\n  followSymlinks: false\n  maxFileSize: 1048576\n\n# OUTPUT FORMATTING\noutput:\n  colors: true\n\n# AI SERVICE CONFIGURATION\nai:\n  backend: auto\n  model: sonnet\n  timeoutMs: 300000\n  maxRetries: 3\n  # concurrency: <current machine default>\n  telemetry:\n    keepRuns: 50\n```\n\n`yamlScalar(value)` helper quotes strings containing YAML metacharacters (`[*{}\\[\\]?,:#&!|>'\"%@` ]`) via regex `/[*{}\\[\\]?,:#&!|>'\"%@`]/` test, escapes backslashes (`\\\\` → `\\\\\\\\`) and quotes (`\"` → `\\\\\"`) before wrapping in double quotes.\n\n## Integration with Codebase\n\n**Consumed by**:\n- `src/cli/init.ts` — Calls `writeDefaultConfig()` for initialization command\n- `src/cli/generate.ts`, `src/cli/update.ts`, `src/cli/discover.ts` — Call `loadConfig()` to retrieve runtime configuration\n- `src/orchestration/pool.ts` — Uses `config.ai.concurrency` for worker count\n- `src/ai/service.ts` — Uses `config.ai.backend`, `config.ai.model`, `config.ai.timeoutMs`, `config.ai.maxRetries`\n- `src/discovery/walker.ts` — Uses `config.exclude.*` and `config.options.*` for file filtering\n- `src/output/logger.ts` — Uses `config.output.colors` for picocolors enablement\n- `src/ai/telemetry/cleanup.ts` — Uses `config.ai.telemetry.keepRuns` for log retention\n\n**Provides types to**:\n- All CLI entry points requiring type-safe configuration access\n- Orchestration modules needing concurrency/timeout parameters\n- Discovery filters requiring exclusion rule arrays\n\n## Default Exclusion Patterns\n\n**DEFAULT_EXCLUDE_PATTERNS** (26 globs):\n- AI docs: `AGENTS.md`, `CLAUDE.md`, `OPENCODE.md`, `GEMINI.md` (root + recursive `**/*`)\n- Lock files: `*.lock`, `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml`, `bun.lock`, `bun.lockb`, `Gemfile.lock`, `Cargo.lock`, `poetry.lock`, `composer.lock`, `go.sum`\n- Dotfiles: `.gitignore`, `.gitattributes`, `.gitkeep`, `.env` (root + recursive `**/.env*`)\n- Artifacts: `*.log`, `*.sum` (root + recursive), `**/SKILL.md`\n\n**DEFAULT_VENDOR_DIRS** (18 directories):\n- Package managers: `node_modules`, `vendor`\n- Build outputs: `dist`, `build`, `target`, `.next`, `__pycache__`\n- Version control: `.git`\n- Python venvs: `venv`, `.venv`\n- Cargo/Gradle caches: `.cargo`, `.gradle`\n- AI assistant directories: `.agents-reverse-engineer`, `.agents`, `.planning`, `.claude`, `.opencode`, `.gemini`\n\n**DEFAULT_BINARY_EXTENSIONS** (26 extensions):\n- Images: `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`, `.ico`, `.webp`\n- Archives: `.zip`, `.tar`, `.gz`, `.rar`, `.7z`\n- Executables: `.exe`, `.dll`, `.so`, `.dylib`\n- Media: `.mp3`, `.mp4`, `.wav`\n- Documents: `.pdf`\n- Fonts: `.woff`, `.woff2`, `.ttf`, `.eot`\n- Compiled: `.class`, `.pyc`\n### src/discovery/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/discovery\n\nFile discovery pipeline orchestrating four-filter chain execution (gitignore → vendor → binary → custom) after fast-glob directory traversal, returning attributed inclusion/exclusion results.\n\n## Contents\n\n**[run.ts](./run.ts)** — Exports `discoverFiles()` facade creating filter chain (GitignoreFilter → VendorFilter → BinaryFilter → CustomPatternFilter) via factory functions, invoking `walkDirectory()` with symlink control, applying filters via `applyFilters()` with trace/debug propagation, returning `FilterResult` with per-file attribution.\n\n**[types.ts](./types.ts)** — Defines `FileFilter` interface (`name: string`, `shouldExclude(path, stats?): boolean | Promise<boolean>`), `ExcludedFile` record (`path`, `reason`, `filter`), `FilterResult` aggregate (`included: string[]`, `excluded: ExcludedFile[]`), `WalkerOptions` config (`cwd`, `followSymlinks?`, `dot?`).\n\n**[walker.ts](./walker.ts)** — Implements `walkDirectory(options: WalkerOptions): Promise<string[]>` via `fg.glob('**/*', {absolute: true, onlyFiles: true, suppressErrors: true, ignore: ['**/.git/**']})` with cwd-relative traversal, dotfile inclusion (default true), symlink control (default false).\n\n## Subdirectories\n\n**[filters/](./filters/)** — Four filter implementations: `binary.ts` (extension Set + size threshold + content analysis), `gitignore.ts` (`.gitignore` parser via `ignore` library), `vendor.ts` (Set lookup for single-segment + substring for path patterns), `custom.ts` (user-defined glob patterns). Orchestrator `index.ts` exports `applyFilters()` with 30-worker concurrency, short-circuit evaluation, per-filter statistics (`matched`/`rejected`), `filter:applied` trace events.\n\n## Architecture\n\n### Discovery Pipeline Flow\n\n1. **Configuration** — Caller (CLI commands) loads `DiscoveryConfig` subset from full config schema via `loadConfig()`\n2. **Filter Creation** — `discoverFiles()` constructs four filters in deterministic order: `createGitignoreFilter(root)`, `createVendorFilter(config.exclude.vendorDirs)`, `createBinaryFilter({maxFileSize, additionalExtensions: config.exclude.binaryExtensions})`, `createCustomFilter(config.exclude.patterns, root)`\n3. **Directory Walking** — Delegates to `walkDirectory({cwd: root, followSymlinks: config.options.followSymlinks})` returning absolute paths via fast-glob\n4. **Filter Application** — Invokes `applyFilters(files, filters, {tracer, debug})` from `filters/index.ts` executing short-circuit filter chain across 30 concurrent workers\n5. **Result Aggregation** — Returns `FilterResult` with `included` files passing all filters, `excluded` array containing `ExcludedFile` records with `filter`/`reason` attribution\n\n### Path Normalization Contract\n\nFilters receive absolute paths from walker, convert to relative via `path.relative(normalizedRoot, absolutePath)` for pattern matching (gitignore/custom patterns). Paths outside root (relative path starts with `..`) bypass filtering. Walker emits absolute paths via `fast-glob` option `{absolute: true}`.\n\n### Filter Interface Polymorphism\n\n`FileFilter.shouldExclude()` supports both sync/async implementations via union return type `boolean | Promise<boolean>`. Binary filter uses async `fs.stat()` + `isbinaryfile.isBinaryFile()`, others use sync string matching. Filter chain executor awaits all promises via `Promise.resolve()` wrapper.\n\n### Configuration Structural Typing\n\n`DiscoveryConfig` interface in `run.ts` defines minimal subset of full `Config` schema from `src/config/schema.ts` containing only `exclude.*`, `options.maxFileSize`, `options.followSymlinks` fields. Enables unit testing with minimal mock objects, prevents tight coupling to entire config schema.\n\n## Integration Points\n\n**Callers**: `src/cli/discover.ts`, `src/cli/generate.ts`, `src/cli/update.ts` invoke `discoverFiles()` with config from `loadConfig()`.\n\n**Consumers**: `FilterResult.included` feeds Phase 1 file analysis worker pool in `src/generation/executor.ts`, `FilterResult.excluded` populates `GENERATION-PLAN.md` statistics via `PlanTracker.writeGenerationPlan()`.\n\n**Telemetry**: `ITraceWriter` from `src/orchestration/trace.ts` emits `filter:applied` events with per-filter match/rejection counts when `--trace` flag enabled.\n### src/discovery/filters/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/discovery/filters\n\nComposable file exclusion filters implementing gitignore semantics, binary detection, vendor directory skipping, and custom glob patterns for the file discovery pipeline.\n\n## Contents\n\n### Filter Implementations\n\n**[binary.ts](./binary.ts)** — Three-phase binary file detector: extension fast-path lookup in 82-member `BINARY_EXTENSIONS` set (images/archives/executables/media/fonts/bytecode/databases), size threshold comparison via `fs.stat()` (default 1MB), content analysis fallback via `isbinaryfile.isBinaryFile()`.\n\n**[custom.ts](./custom.ts)** — User-defined gitignore-style pattern matcher via `ignore` library, converts absolute paths to relative via `path.relative()`, bypasses filtering for paths outside root (relative path starts with `..`).\n\n**[gitignore.ts](./gitignore.ts)** — `.gitignore` parser consuming `ignore` library, silently passes all paths when `.gitignore` missing, converts absolute paths to relative for pattern matching.\n\n**[vendor.ts](./vendor.ts)** — Vendor directory excluder with dual matching: single-segment Set lookup (`node_modules`, `.git`, `dist`, `build`, `__pycache__`, `.next`, `venv`, `.venv`, `target`) and path-pattern substring search for multi-segment patterns (`.agents/skills`, `apps/vendor`).\n\n**[index.ts](./index.ts)** — Filter chain orchestrator with `applyFilters()` executing short-circuit evaluation (stops at first exclusion) across 30 concurrent workers sharing iterator, collects per-filter statistics (`matched`/`rejected` counts), emits `filter:applied` trace events, re-exports all filter creators.\n\n## Architecture\n\n### Filter Chain Execution\n\n`applyFilters()` bounds concurrency to 30 workers via `Math.min(CONCURRENCY, files.length)` to prevent file descriptor exhaustion during binary detection I/O. Each worker drains shared `files.entries()` iterator, processes files serially through filter array with short-circuit semantics (breaks on first `shouldExclude()` true return). Results sorted by original index to preserve input order despite concurrent execution.\n\n### Path Normalization Contract\n\nAll filters receive absolute paths, convert to relative via `path.relative(normalizedRoot, absolutePath)` for pattern matching libraries (`ignore` requires relative paths without leading slash). Paths outside root (starting with `..`) bypass filtering by returning `false`. Empty relative paths also bypass exclusion.\n\n### Binary Detection Strategy\n\n`createBinaryFilter()` prioritizes performance via three-tiered approach:\n1. Extension lookup in pre-allocated Set (O(1), no I/O)\n2. Size threshold check via `fs.stat()` (single syscall)\n3. Content analysis via `isbinaryfile` heuristics (reads file header bytes)\n\nReturns `true` on `fs.stat()` failure (file unreadable/missing) to fail-safe exclude corrupt/inaccessible files.\n\n### Vendor Path Pattern Classification\n\n`createVendorFilter()` splits patterns into `singleSegments` Set and `pathPatterns` array based on presence of path separator after normalization (`dir.replace(/[\\\\/]/g, path.sep)`). Single segments use Set membership check, path patterns use substring search. Normalization ensures cross-platform compatibility (Windows backslashes converted to `path.sep`).\n\n## Filter Statistics\n\n`applyFilters()` aggregates statistics in `Map<string, { matched: number; rejected: number }>`:\n- `rejected` increments when filter excludes file\n- `matched` increments for all filters when file passes entire chain (not per individual filter pass)\n\nStatistics emitted as `filter:applied` trace events with `filterName`, `filesMatched`, `filesRejected` fields for downstream effectiveness analysis.\n\n## Behavioral Contracts\n\n### Binary Extension Set (82 entries)\nImages: `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`, `.ico`, `.webp`, `.svg`, `.tiff`, `.tif`, `.psd`, `.raw`, `.heif`, `.heic`\nArchives: `.zip`, `.tar`, `.gz`, `.rar`, `.7z`, `.bz2`, `.xz`, `.tgz`\nExecutables: `.exe`, `.dll`, `.so`, `.dylib`, `.bin`, `.msi`, `.app`, `.dmg`\nMedia: `.mp3`, `.mp4`, `.wav`, `.avi`, `.mov`, `.mkv`, `.flac`, `.ogg`, `.webm`, `.m4a`, `.aac`, `.wma`, `.wmv`, `.flv`\nDocuments: `.pdf`, `.doc`, `.docx`, `.xls`, `.xlsx`, `.ppt`, `.pptx`, `.odt`, `.ods`, `.odp`\nFonts: `.woff`, `.woff2`, `.ttf`, `.eot`, `.otf`\nBytecode: `.class`, `.pyc`, `.pyo`, `.o`, `.obj`, `.a`, `.lib`, `.wasm`\nDatabases: `.db`, `.sqlite`, `.sqlite3`, `.mdb`\nMisc: `.ico`, `.icns`, `.cur`, `.deb`, `.rpm`, `.jar`, `.war`, `.ear`\n\n### Default Vendor Directories (10 entries)\n`node_modules`, `vendor`, `.git`, `dist`, `build`, `__pycache__`, `.next`, `venv`, `.venv`, `target`\n\n### Default Max File Size\n`1024 * 1024` (1MB)\n\n### Filter Chain Concurrency\n30 workers (constant `CONCURRENCY` in `index.ts`)\n\n## Integration Points\n\nConsumed by `src/discovery/walker.ts` as composable filter chain during Phase 1 file analysis. Configured via `config.exclude` fields in `.agents-reverse-engineer/config.yaml`:\n- `patterns` → `createCustomFilter()`\n- `vendorDirs` → `createVendorFilter()`\n- `binaryExtensions` → `createBinaryFilter()` (merged with `BINARY_EXTENSIONS`)\n- `.maxFileSize` → `createBinaryFilter()`\n\nImplements `FileFilter` interface from `../types.js` with `name: string` and `shouldExclude(absolutePath: string): Promise<boolean>` signature.\n### src/generation/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# generation\n\n**Phase orchestration, file/directory task preparation, complexity analysis, prompt construction, `.sum` + `AGENTS.md` I/O, and root document collection for the three-phase AI-driven documentation pipeline.**\n\n## Contents\n\n### [collector.ts](./collector.ts)\n`collectAgentsDocs()` recursively walks project tree via `readdir()` with `withFileTypes: true`, accumulates all `AGENTS.md` files into `Array<{ relativePath, content }>`, skips 13 directories (`node_modules`, `.git`, `.agents-reverse-engineer`, `vendor`, `dist`, `build`, `__pycache__`, `.next`, `venv`, `.venv`, `target`, `.cargo`, `.gradle`), returns lexicographically sorted array via `localeCompare()`.\n\n### [complexity.ts](./complexity.ts)\n`analyzeComplexity()` computes `ComplexityMetrics` from file array: `fileCount`, `directoryDepth` via `path.relative().split(path.sep).length - 1`, `directories` set via `path.dirname()` parent chain walk until root `.`, `files` array passthrough.\n\n### [executor.ts](./executor.ts)\n`buildExecutionPlan()` transforms `GenerationPlan` into `ExecutionPlan` with three task categories: `fileTasks` (format `file:<path>`, outputs `.sum`, zero dependencies), `directoryTasks` (format `dir:<path>`, outputs `AGENTS.md`, depends on child file IDs, sorted by `getDirectoryDepth()` descending for post-order traversal), `rootTasks` (format `root:CLAUDE.md`, depends on all directory IDs). `isDirectoryComplete()` verifies all `.sum` files exist via `sumFileExists()`. `formatExecutionPlanAsMarkdown()` generates `GENERATION-PLAN.md`.\n\n### [orchestrator.ts](./orchestrator.ts)\n`GenerationOrchestrator.createPlan()` executes seven-step pipeline: reads file content via `readFile()`, calls `analyzeComplexity()`, invokes `buildProjectStructure()` for compact tree, calls `buildFilePrompt()` per file with `projectPlan` injection, groups files by `path.dirname()` for directory task creation, concatenates `fileTasks + dirTasks`, clears `PreparedFile.content` fields to free memory, emits `phase:start`/`plan:created`/`phase:end` trace events.\n\n### [types.ts](./types.ts)\nDefines `AnalysisResult` (fields: `summary`, `metadata: SummaryMetadata`), `SummaryMetadata` (fields: `purpose`, `criticalTodos?`, `relatedFiles?`), `SummaryOptions` (fields: `targetLength: 'short'|'standard'|'detailed'`, `includeCodeSnippets: boolean`).\n\n## Subdirectories\n\n### [prompts/](./prompts/)\n`buildFilePrompt()` substitutes `{{FILE_PATH}}`, `{{CONTENT}}`, `{{LANG}}`, selects `FILE_UPDATE_SYSTEM_PROMPT` when `existingSum` present. `buildDirectoryPrompt()` reads `.sum` via `readSumFile()`, collects child `AGENTS.md`, extracts imports via `extractDirectoryImports()`, detects 9 manifest types (`package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`, `pom.xml`, `build.gradle`, `Gemfile`, `composer.json`, `CMakeLists.txt`/`Makefile`). `buildRootPrompt()` calls `collectAgentsDocs()`, parses root `package.json`, embeds synthesis constraints. Templates enforce density rules, anchor term preservation, behavioral contract extraction (verbatim regex patterns, format strings, magic constants).\n\n### [writers/](./writers/)\n`writeSumFile()` serializes YAML frontmatter (`generated_at`, `content_hash`, `purpose`, `critical_todos`, `related_files`) with adaptive array formatting (inline `[a,b,c]` for ≤3 items <40 chars, multi-line `- item` otherwise). `readSumFile()` parses via dual-pattern regex. `writeAgentsMd()` implements four-step user content preservation: detect ownership via `GENERATED_MARKER` absence, rename to `AGENTS.local.md`, prepend above LLM output with `---` separator. `getSumPath()` returns `${sourcePath}.sum`.\n\n## Architecture\n\n### Three-Phase Pipeline\n\n**Phase 1 (File Analysis):** `GenerationOrchestrator.createFileTasks()` invokes `buildFilePrompt()` per file, embeds content + project structure, populates `AnalysisTask[]` with `type: 'file'`, `systemPrompt`, `userPrompt`. Workers execute concurrently via `src/orchestration/pool.ts`, call `AIService.call()` → `runSubprocess()` → `execFile()` spawning AI CLI subprocesses with resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`, `--disallowedTools Task`). Results written via `writeSumFile()` to `.sum` paths from `getSumPath()`.\n\n**Phase 2 (Directory Aggregation):** `GenerationOrchestrator.createDirectoryTasks()` groups files via `Map<dirname, PreparedFile[]>`, creates `AnalysisTask[]` with `type: 'directory'`, `directoryInfo: { sumFiles, fileCount }`. Executor sorts tasks by `getDirectoryDepth()` descending (deepest first), waits for child `.sum` files via `isDirectoryComplete()`, constructs prompts via `buildDirectoryPrompt()` consuming `.sum` frontmatter + child `AGENTS.md` + import maps from `extractDirectoryImports()`. Writes via `writeAgentsMd()` preserving user content from `AGENTS.local.md`.\n\n**Phase 3 (Root Synthesis):** Sequential execution (concurrency=1) generates `CLAUDE.md`, `GEMINI.md`, `OPENCODE.md` via `buildRootPrompt()` aggregating all `AGENTS.md` via `collectAgentsDocs()`, parsing root `package.json`, enforcing synthesis-only constraints (no invention). Strips conversational preamble via pattern matching before writing output.\n\n### Dependency Graph\n\n`buildExecutionPlan()` constructs DAG with three layers:\n1. File tasks: zero dependencies, parallel-eligible\n2. Directory tasks: depend on child file IDs (`files.map(f => 'file:${f}')`), sorted by depth descending\n3. Root tasks: depend on all directory IDs\n\n`isDirectoryComplete()` predicate blocks directory processing until all child `.sum` files exist, ensuring post-order traversal guarantees data availability for parent synthesis.\n\n### Memory Management\n\n`createPlan()` clears `PreparedFile.content` fields via cast `(file as { content: string }).content = ''` after embedding content into file task prompts. Comment: \"The runner re-reads files from disk\" during execution phase. Reduces peak memory from O(total codebase size) to O(largest file × concurrency).\n\n## File Relationships\n\n`orchestrator.ts` calls `buildFilePrompt()` from `./prompts/index.js`, `analyzeComplexity()` from `./complexity.js`, `buildProjectStructure()` internally. `executor.ts` imports `sumFileExists()` from `./writers/sum.ts` for completion checks. `collector.ts` supplies `collectAgentsDocs()` to `./prompts/builder.ts` for root prompt construction. `writers/sum.ts` writes files consumed by `writers/agents-md.ts` prompt builder, both consumed by `executor.ts` via `./writers/index.js` barrel export.\n\n## Integration Points\n\nConsumed by `src/orchestration/runner.ts` which invokes `GenerationOrchestrator.createPlan()` → `buildExecutionPlan()` → three-phase execution via worker pools. Prompts passed to `AIService.call()` in `src/ai/service.ts`. Results written to filesystem via `writeSumFile()` + `writeAgentsMd()`. Trace events emitted to `src/orchestration/trace.ts`. Complexity metrics logged via `src/output/logger.ts`. Discovery input from `src/discovery/run.ts` as `DiscoveryResult`. Configuration from `src/config/loader.ts` as `Config`.\n\n## Behavioral Contracts\n\n**GENERATED_MARKER** (writers/agents-md.ts):\n```javascript\n'<!-- Generated by agents-reverse-engineer -->'\n```\n\n**Frontmatter extraction** (writers/sum.ts):\n```javascript\n/^---\\n([\\s\\S]*?)\\n---\\n/\n```\n\n**YAML field patterns**:\n```javascript\n/generated_at:\\s*(.+)/\n/content_hash:\\s*(.+)/\n/purpose:\\s*(.+)/\n/key:\\s*\\[([^\\]]*)\\]/  // Inline arrays\n/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m  // Multi-line arrays\n```\n\n**Array formatting heuristic** (writers/sum.ts):\n- Inline if `length <= 3` and all items `< 40` chars\n- Multi-line otherwise\n\n**Directory depth calculation** (executor.ts):\n```javascript\ndir.split(path.sep).length  // Returns 0 for '.', 1 for 'src', 2 for 'src/cli'\n```\n\n**Post-order sort comparator** (executor.ts):\n```javascript\n(a, b) => getDirectoryDepth(dirB) - getDirectoryDepth(dirA)  // Descending\n```\n\n**Task ID formats** (executor.ts):\n- File: `file:<relativePath>`\n- Directory: `dir:<relativePath>`\n- Root: `root:<filename>`\n\n**Skip directories** (collector.ts):\n```javascript\nSet(['node_modules', '.git', '.agents-reverse-engineer', 'vendor', 'dist', 'build', '__pycache__', '.next', 'venv', '.venv', 'target', '.cargo', '.gradle'])\n```\n\n**Manifest detection** (prompts/builder.ts):\n```javascript\n['package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml', 'pom.xml', 'build.gradle', 'Gemfile', 'composer.json', 'CMakeLists.txt', 'Makefile']\n```\n\n**Source file filter for imports** (prompts/builder.ts):\n```javascript\n/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/\n```\n\n**Language extension map** (prompts/builder.ts):\n22 extensions: `.ts` → `'typescript'`, `.py` → `'python'`, `.rs` → `'rust'`, etc., defaults to `'text'`.\n### src/generation/prompts/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# generation/prompts\n\n**This directory exports `buildFilePrompt()`, `buildDirectoryPrompt()`, `buildRootPrompt()` for constructing system+user prompt pairs fed to AI CLI subprocesses during three-phase documentation generation: per-file `.sum` analysis, directory-level `AGENTS.md` aggregation, and root integration document synthesis (`CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`).**\n\n## Contents\n\n### [builder.ts](./builder.ts)\nImplements `buildFilePrompt()` (substitutes `{{FILE_PATH}}`, `{{CONTENT}}`, `{{LANG}}`, `{{PROJECT_PLAN_SECTION}}` placeholders, appends contextFiles, selects `FILE_UPDATE_SYSTEM_PROMPT` when `context.existingSum` present), `buildDirectoryPrompt()` (reads `.sum` files via `readSumFile()`, collects child `AGENTS.md`, extracts imports via `extractDirectoryImports()`, detects 9 manifest types: `package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`, `pom.xml`, `build.gradle`, `Gemfile`, `composer.json`, `CMakeLists.txt`, `Makefile`), `buildRootPrompt()` (calls `collectAgentsDocs()`, parses root `package.json`, embeds synthesis constraints), and `detectLanguage()` (maps 22 file extensions to syntax identifiers).\n\n### [index.ts](./index.ts)\nBarrel export re-exporting `PromptContext`, `SUMMARY_GUIDELINES`, `buildFilePrompt()`, `buildDirectoryPrompt()`, `buildRootPrompt()`, `detectLanguage()` from `types.ts` and `builder.ts` to form public API consumed by `src/generation/executor.ts`.\n\n### [templates.ts](./templates.ts)\nDefines `FILE_SYSTEM_PROMPT` (density rules, anchor term preservation, behavioral contract extraction), `FILE_USER_PROMPT` (placeholders: `{{FILE_PATH}}`, `{{CONTENT}}`), `DIRECTORY_SYSTEM_PROMPT` (path accuracy constraints, adaptive section selection), `FILE_UPDATE_SYSTEM_PROMPT` (incremental preservation directives), `DIRECTORY_UPDATE_SYSTEM_PROMPT` (structure preservation), `ROOT_SYSTEM_PROMPT` (synthesis constraints forbidding invention).\n\n### [types.ts](./types.ts)\nExports `PromptContext` (fields: `filePath`, `content`, `contextFiles`, `projectPlan`, `existingSum`) consumed by prompt builders and `SUMMARY_GUIDELINES` (targetLength: 300-500 words, include array mandating behavioral contracts: verbatim regex patterns, format strings, magic constants, sentinel values, environment variables).\n\n## Architecture\n\n### Three-Phase Prompt Construction\n\n**Phase 1: File Analysis**  \n`buildFilePrompt()` receives `PromptContext`, detects language via extension lookup (`detectLanguage()`), substitutes placeholders in `FILE_USER_PROMPT` template, appends related files section when `contextFiles` populated, selects `FILE_UPDATE_SYSTEM_PROMPT` for incremental updates (when `existingSum` present) or `FILE_SYSTEM_PROMPT` for fresh analysis.\n\n**Phase 2: Directory Aggregation**  \n`buildDirectoryPrompt()` reads directory via `readdir()`, filters against `knownDirs` set (skips non-source directories), reads `.sum` files in parallel via `Promise.all(readSumFile(getSumPath(entryPath)))`, collects child `AGENTS.md`, extracts imports from source files matching `/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/` via `extractDirectoryImports()`, detects manifest files, checks for user documentation (AGENTS.local.md or non-generated AGENTS.md lacking `GENERATED_MARKER`), assembles sections: file summaries, import map via `formatImportMap()`, project structure, subdirectories, directory hints, user notes, existing AGENTS.md (update mode), returns `DIRECTORY_UPDATE_SYSTEM_PROMPT` when `existingAgentsMd` supplied.\n\n**Phase 3: Root Synthesis**  \n`buildRootPrompt()` calls `collectAgentsDocs()` to recursively gather all `AGENTS.md` files, reads root `package.json` and extracts metadata (name, version, description, packageManager, scripts), embeds all AGENTS.md content as `### ${relativePath}` sections, appends package metadata, includes synthesis constraint: \"Use ONLY the information provided below. Do NOT invent features, hooks, patterns, or APIs that are not explicitly mentioned in the AGENTS.md content.\"\n\n### Template Substitution Pattern\n\nAll prompts follow structure: system prompt (behavioral constraints) + user prompt (context injection). Builder functions perform string interpolation with runtime data:\n- `buildFilePrompt()` injects file path, source code, language identifier, project plan section\n- `buildDirectoryPrompt()` injects `.sum` summaries, import maps, child AGENTS.md, manifest hints, user notes\n- `buildRootPrompt()` injects all AGENTS.md content, package metadata, output requirements checklist\n\n## Behavioral Contracts\n\n### Density Rules (FILE_SYSTEM_PROMPT)\n`\"Every sentence must reference at least one specific identifier (function name, class name, type name, or constant)\"`. Banned filler phrases: `\"this file\", \"this module\", \"provides\", \"responsible for\", \"is used to\", \"basically\", \"essentially\", \"provides functionality for\"`.\n\n### Anchor Term Preservation (FILE_SYSTEM_PROMPT)\n`\"All exported function/class/type/const names MUST appear in the summary exactly as written in source\"`, `\"Preserve exact casing of identifiers\"`, `\"Missing any exported identifier is a failure\"`.\n\n### Output Format Requirements (FILE_SYSTEM_PROMPT, DIRECTORY_SYSTEM_PROMPT)\n`\"Start your response DIRECTLY with the purpose statement\"` for file prompts. `\"Output ONLY the raw markdown content. No code fences, no preamble\"` for directory prompts. `\"First line MUST be exactly: <!-- Generated by agents-reverse-engineer -->\"` for AGENTS.md.\n\n### Behavioral Contract Extraction (FILE_SYSTEM_PROMPT)\nRequired captures: `\"Regex patterns for parsing/validation/extraction — include the full pattern verbatim in backticks\"`, `\"Format strings, output templates, serialization structures — show exact format\"`, `\"Magic constants, sentinel values, numeric thresholds (timeouts, buffer sizes, retry counts)\"`, `\"Prompt text or template strings that control AI/LLM behavior\"`, `\"Error message patterns and error code strings\"`, `\"Environment variable names and their expected values\"`, `\"File format specifications (YAML frontmatter schemas, NDJSON line formats)\"`.\n\n### Path Accuracy Constraints (DIRECTORY_SYSTEM_PROMPT)\n`\"When referencing files or modules outside this directory, use ONLY paths from the 'Import Map' section\"`, `\"Do NOT invent, rename, or guess module paths\"`, `\"Use the exact directory names from 'Project Directory Structure' — do NOT rename directories\"`, `\"Cross-module references must use the specifier format from actual import statements\"`, `\"If you are unsure about a path, omit the cross-reference rather than guessing\"`.\n\n### Incremental Update Preservation (FILE_UPDATE_SYSTEM_PROMPT, DIRECTORY_UPDATE_SYSTEM_PROMPT)\n`\"Preserve the structure, section headings, and phrasing of the existing summary wherever the underlying code is unchanged\"`, `\"Only modify content that is directly affected by the code changes\"`, `\"Regex patterns, format strings, magic constants, and template content from the existing summary MUST be preserved verbatim unless the source code changed them\"`, `\"Never summarize or paraphrase regex patterns — always show the exact pattern in backticks\"`.\n\n### Root Synthesis Constraints (ROOT_SYSTEM_PROMPT)\n`\"Synthesize ONLY from the AGENTS.md content provided in the user prompt\"`, `\"Do NOT invent, extrapolate, or hallucinate features, hooks, APIs, patterns, or dependencies not explicitly mentioned\"`, `\"Every claim must be traceable to a specific AGENTS.md file provided\"`.\n\n### Source File Extension Filter (builder.ts)\n`/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/` — only files matching these extensions processed by `extractDirectoryImports()` for import map generation.\n\n### Manifest Detection Pattern (builder.ts)\n`['package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml', 'pom.xml', 'build.gradle', 'Gemfile', 'composer.json', 'CMakeLists.txt', 'Makefile']` — presence triggers \"likely a package or project root\" hint in directory prompts.\n\n### Language Extension Map (builder.ts detectLanguage())\n22 extensions: `.ts` → `'typescript'`, `.tsx` → `'tsx'`, `.js` → `'javascript'`, `.jsx` → `'jsx'`, `.py` → `'python'`, `.rb` → `'ruby'`, `.go` → `'go'`, `.rs` → `'rust'`, `.java` → `'java'`, `.kt` → `'kotlin'`, `.swift` → `'swift'`, `.cs` → `'csharp'`, `.php` → `'php'`, `.vue` → `'vue'`, `.svelte` → `'svelte'`, `.json` → `'json'`, `.yaml`/`.yml` → `'yaml'`, `.md` → `'markdown'`, `.css` → `'css'`, `.scss` → `'scss'`, `.html` → `'html'`. Defaults to `'text'`.\n\n## File Relationships\n\n`builder.ts` calls `readSumFile()` + `getSumPath()` from `../writers/sum.js` to retrieve `.sum` frontmatter+content, references `GENERATED_MARKER` from `../writers/agents-md.js` to detect user-authored vs. generated AGENTS.md, invokes `extractDirectoryImports()` + `formatImportMap()` from `../../imports/index.js` for verified import maps, calls `collectAgentsDocs()` from `../collector.js` to aggregate AGENTS.md recursively. `templates.ts` provides raw prompt text consumed by `builder.ts` via import. `types.ts` defines `PromptContext` structure threaded through `builder.ts` functions. `index.ts` re-exports public API consumed by `src/generation/executor.ts` during three-phase pipeline execution.\n\n## Integration Points\n\nConsumed by `src/generation/executor.ts` which invokes prompt builders during phase execution: `buildFilePrompt()` called for each file in Phase 1 concurrent pool, `buildDirectoryPrompt()` called for each directory in Phase 2 post-order traversal, `buildRootPrompt()` called once per root document in Phase 3 sequential execution. Prompts passed as `{ system, user }` pairs to `AIService.call()` in `src/ai/service.ts` which spawns CLI subprocesses (`claude`, `gemini`, `opencode`) with resource limits (`NODE_OPTIONS='--max-old-space-size=512'`, `UV_THREADPOOL_SIZE='4'`, `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'`, `--disallowedTools Task`).\n### src/generation/writers/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/generation/writers\n\n`.sum` file I/O with YAML frontmatter serialization, `AGENTS.md` lifecycle management with user content preservation, and path resolution utilities for Phase 1/Phase 2 writer operations.\n\n## Contents\n\n**[sum.ts](./sum.ts)** — Serializes `SumFileContent` to `.sum` files with YAML frontmatter (`generated_at`, `content_hash`, `purpose`, `critical_todos`, `related_files`), parses frontmatter via regex extraction of inline/multi-line arrays, computes `.sum` paths via `getSumPath()`, validates existence via `sumFileExists()`.\n\n**[agents-md.ts](./agents-md.ts)** — Writes directory-level `AGENTS.md` with `GENERATED_MARKER` ownership detection, preserves user-authored content by renaming to `AGENTS.local.md` and prepending above LLM output, strips marker prefix from incoming content, constructs final structure with optional user content block and `---` separator.\n\n**[index.ts](./index.ts)** — Re-exports `writeSumFile`, `readSumFile`, `getSumPath`, `sumFileExists`, `SumFileContent` from `sum.ts` and `writeAgentsMd` from `agents-md.ts` as public API boundary.\n\n## YAML Frontmatter Format\n\nsum.ts serializes frontmatter with adaptive array formatting: inline `[a, b, c]` for ≤3 items under 40 chars each, multi-line `- item` otherwise. Parses via dual-pattern regex supporting both syntaxes. Mandatory fields: `generated_at` (ISO 8601), `content_hash` (SHA-256 hex), `purpose` (single-line string). Optional arrays: `critical_todos`, `related_files`.\n\n## User Content Preservation\n\nagents-md.ts implements idempotent preservation via four-step workflow:\n\n1. Read existing `AGENTS.md`, detect user authorship via `GENERATED_MARKER` absence, rename to `AGENTS.local.md` if user-authored\n2. Attempt read of already-renamed `AGENTS.local.md` from previous run if step 1 found no user content\n3. Strip `GENERATED_MARKER` prefix from incoming LLM content via `slice()` + `/^\\n+/` normalization\n4. Construct final content: `GENERATED_MARKER` → optional user block with `<!-- User-defined AGENTS.md preserved as AGENTS.local.md -->` header and `---` separator → LLM content, write via `writeFile()` with `mkdir({recursive: true})`\n\nPreserved content prepended above generated content ensures AI assistants encounter project-specific context before auto-generated summaries.\n\n## Path Resolution\n\n`getSumPath(sourcePath)` returns `${sourcePath}.sum` for given source file. No directory transformation — `.sum` files colocate with source files throughout tree. `sumFileExists()` delegates to `readSumFile()` non-null check, avoiding redundant `access()` syscalls.\n\n## Integration with Pipeline Phases\n\n**Phase 1 (File Analysis):** `src/generation/executor.ts` workers call `writeSumFile()` after AI subprocess returns `SumFileContent`, writes to path from `getSumPath(sourceFile.path)`.\n\n**Phase 2 (Directory Aggregation):** `src/generation/orchestrator.ts` calls `readSumFile()` via `collectAgentsDocs()` to load child `.sum` files for prompt construction, calls `writeAgentsMd()` with LLM response from `AIService.call()`.\n\n**Incremental Updates:** `src/update/orphan-cleaner.ts` calls `readSumFile()` to extract `content_hash` from YAML frontmatter for SHA-256 comparison, `cleanupEmptyDirectoryDocs()` uses `isGeneratedAgentsMd()` to determine deletion eligibility.\n\n**Cleanup:** `src/cli/clean.ts` calls `isGeneratedAgentsMd()` to filter deletion targets, skips user-authored files, restores `AGENTS.local.md` → `AGENTS.md` after removing generated version.\n\n## Behavioral Contracts\n\n**GENERATED_MARKER constant:**\n```javascript\n'<!-- Generated by agents-reverse-engineer -->'\n```\n\n**Frontmatter extraction regex (parseSumFile):**\n```javascript\n/^---\\n([\\s\\S]*?)\\n---\\n/\n```\n\n**Field patterns:**\n```javascript\n/generated_at:\\s*(.+)/\n/content_hash:\\s*(.+)/\n/purpose:\\s*(.+)/\n```\n\n**Array parsing patterns (parseYamlArray):**\n```javascript\n/key:\\s*\\[([^\\]]*)\\]/  // Inline: key: [a, b, c]\n/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m  // Multi-line: key:\\n  - item\n```\n\n**Quote stripping (inline arrays):**\n```javascript\n.replace(/^[\"']|[\"']$/g, '')\n```\n\n**Multi-line item prefix:**\n```javascript\n/^\\s*-\\s*/  // Strips leading '  - '\n```\n\n**Array format heuristic (formatYamlArray):**\n- Inline if `values.length <= 3` and all items `< 40` chars\n- Multi-line otherwise\n- Empty: `key: []`\n\n**Newline normalization (writeAgentsMd):**\n```javascript\ncontent.slice(GENERATED_MARKER.length).replace(/^\\n+/, '')\n```\n### src/imports/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/imports\n\n**Static import analysis module extracting TypeScript/JavaScript import statements via regex parsing to construct dependency graphs and import maps for AI-driven documentation prompts.**\n\n## Contents\n\n### Core Extraction\n\n**[extractor.ts](./extractor.ts)** — Regex-based import parser extracting ES module syntax into `ImportEntry[]` arrays. `extractImports()` applies `IMPORT_REGEX` (`/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm`) to capture five groups: (1) `type` keyword, (2) named symbols, (3) namespace imports, (4) default imports, (5) module specifier. `extractDirectoryImports()` scans first 100 lines of each file to optimize import-region parsing, filters bare specifiers (`'react'`, `node:*`), partitions relative imports into `internal` (`./`) and `external` (`../`). `formatImportMap()` serializes `FileImports[]` into LLM prompt text blocks with `(type)` suffix for type-only imports.\n\n**[types.ts](./types.ts)** — Type definitions for import extraction results. `ImportEntry` models single import statement with `specifier`, `symbols[]`, `typeOnly` discriminator. `FileImports` aggregates directory-level imports via `externalImports[]` (cross-directory dependencies) and `internalImports[]` (same-directory coupling). External/internal partitioning enables `AGENTS.md` prompts to emphasize architectural boundaries.\n\n**[index.ts](./index.ts)** — Barrel export exposing `extractImports()`, `extractDirectoryImports()`, `formatImportMap()`, `ImportEntry`, `FileImports` for integration with Phase 2 directory aggregation pipeline (`src/generation/prompts/builder.ts`).\n\n## Integration Points\n\n**Generation Phase 2 (Directory Aggregation):**\n- `src/generation/prompts/builder.ts` calls `extractDirectoryImports()` during `AGENTS.md` synthesis\n- Import maps injected into prompts via `formatImportMap()` output in `src/generation/prompts/templates.ts`\n- External import paths verified against filesystem constraints to prevent phantom references\n\n**Discovery Pipeline:**\n- `src/generation/orchestrator.ts` passes `discoveredFiles[]` list enabling directory-level filtering without redundant scans\n- Skips binary files, vendor directories, custom exclude patterns from upstream discovery filters\n\n**Data Flow:**\n- Runner invokes `extractDirectoryImports(dirPath, fileNames)` → reads first 100 lines → regex extraction → internal/external partitioning → `FileImports[]` return\n- Prompt builder calls `formatImportMap(fileImports)` → text serialization → template injection\n\n## Behavioral Contracts\n\n**IMPORT_REGEX Pattern:**\n```regex\n/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm\n```\n- Group 1: `type` keyword (`import type { Foo }`)\n- Group 2: Named symbols within braces (`{ Foo, Bar as Baz }`)\n- Group 3: Namespace imports (`* as name`)\n- Group 4: Default imports (bare identifier after `import`)\n- Group 5: Module specifier (quoted string after `from`)\n- Anchored `^` for line start, `gm` flags for global multiline\n- Does NOT capture dynamic imports (`import('...')`) or side-effect imports (`import './styles.css'`)\n\n**Format Template (formatImportMap output):**\n```\nrunner.ts:\n  ../ai/index.js → AIService\n  ../generation/executor.js → ExecutionPlan, ExecutionTask\n\npool.ts:\n  ./trace.js → ITraceWriter (type)\n```\n\n**File Read Optimization:**\n- Reads only first 100 lines via `content.split('\\n').slice(0, 100).join('\\n')` before regex scanning\n- Assumption: ES module imports typically concentrated in file header region\n- Trade-off: Skips late-file dynamic import detection for 95%+ file I/O reduction\n\n**Import Classification:**\n- Bare specifiers (`'react'`, `'lodash'`) → filtered out (external packages)\n- `node:` prefixed (`'node:fs'`) → filtered out (built-in modules)\n- Relative starting `./` → `internalImports[]` (same-directory coupling)\n- Relative starting `../` → `externalImports[]` (cross-directory dependencies)\n### src/installer/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/installer\n\nnpx installation orchestrator for deploying ARE command templates and session hooks into AI coding assistant runtime directories (`~/.claude`, `~/.config/opencode`, `~/.gemini`), with interactive prompts for missing parameters, parallel multi-runtime support, hook registration in settings.json, and permission preauthorization for Claude Code.\n\n## Contents\n\n### Core Installation Logic\n\n**[operations.ts](./operations.ts)** — Writes command templates from `src/integration/templates.ts` to runtime directories, copies bundled hook files from `hooks/dist/`, registers hooks in `settings.json` via `registerClaudeHooks()`/`registerGeminiHooks()`, writes `ARE-VERSION` file, adds Bash permission patterns to Claude Code allow list. Exports `installFiles()` fan-out across runtimes, `verifyInstallation()` checking file existence via `existsSync()`, `getPackageVersion()` reading from package.json, `formatInstallResult()` for human-readable output.\n\n**[uninstall.ts](./uninstall.ts)** — Removes command templates, hooks, hook registrations from `settings.json`, Bash permission entries from allow list, and `ARE-VERSION` file. Calls `cleanupAreSkillDirs()` deleting empty `are-*` skill directories for Claude, `cleanupLegacyGeminiFiles()` removing pre-TOML `*.md` files, `cleanupEmptyDirs()` recursively deleting empty parent directories stopping at runtime roots. Exports `uninstallFiles()`, `deleteConfigFolder()` for `.agents-reverse-engineer` removal.\n\n**[paths.ts](./paths.ts)** — Resolves runtime installation paths with environment variable overrides (`CLAUDE_CONFIG_DIR`, `OPENCODE_CONFIG_DIR`, `GEMINI_CONFIG_DIR`). Exports `getRuntimePaths()` returning `RuntimePaths` objects with `global`/`local`/`settingsFile` fields, `resolveInstallPath()` joining runtime paths with project root, `isRuntimeInstalledLocally()`/`isRuntimeInstalledGlobally()` existence checks via `stat()`.\n\n### Workflow Orchestration\n\n**[index.ts](./index.ts)** — Parses CLI args via `parseInstallerArgs()` supporting `-g`/`--global`, `-l`/`--local`, `--runtime`, `--force`, `-u`/`--uninstall`, `-q`/`--quiet`, dispatches to `runInstall()`/`runUninstall()` after resolving runtime and location via `determineRuntimes()`/`determineLocation()` with interactive prompt fallback. Calls `verifyInstallation()` checking created file existence, formats results via `displayInstallResults()`/`displayUninstallResults()` showing file counts, hook registration status, and `showNextSteps()` with ARE command list. Exits with code 1 in non-interactive mode when required flags missing.\n\n**[prompts.ts](./prompts.ts)** — Arrow-key selection in TTY mode via `arrowKeySelect()` with `readline.emitKeypressEvents()`, numbered fallback via `numberedSelect()` for non-TTY. Exports `selectRuntime()` prompting for `'claude'`/`'opencode'`/`'gemini'`/`'all'`, `selectLocation()` for `'global'`/`'local'`, `confirmAction()` for yes/no prompts, `isInteractive()` checking `process.stdin.isTTY`. Enforces raw mode cleanup via `cleanupRawMode()` in try/finally blocks and process exit handlers (`'exit'`, `'SIGINT'`) preventing terminal state corruption.\n\n### Display Formatting\n\n**[banner.ts](./banner.ts)** — Styled terminal output with ASCII art \"ARE\" logo in green via `pc.green()`, version footer via `getVersion()`, usage instructions with `pc.bold()` section headers covering CLI options and example invocations. Exports `displayBanner()`, `showHelp()`, `showNextSteps()` listing ARE commands (`/are-help`, `/are-init`, `/are-discover`, `/are-generate`, `/are-update`, `/are-specify`, `/are-clean`) in cyan, message helpers `showSuccess()`/`showError()`/`showWarning()`/`showInfo()` with prefixed symbols.\n\n### Type Definitions\n\n**[types.ts](./types.ts)** — Defines `Runtime = 'claude' | 'opencode' | 'gemini' | 'all'`, `Location = 'global' | 'local'`, `InstallerArgs` interface with boolean flags and optional runtime field, `InstallerResult` interface tracking `filesCreated[]`, `filesSkipped[]`, `errors[]`, `hookRegistered`, `versionWritten`, `RuntimePaths` interface with `global`/`local`/`settingsFile` path strings.\n\n## Installation Flow\n\n1. **Argument Parsing** — `parseInstallerArgs()` extracts flags, validates `--runtime` against `['claude', 'opencode', 'gemini', 'all']`\n2. **Interactive Prompts** — `determineLocation()` calls `selectLocation()` if both/neither `-g`/`-l` set, `determineRuntimes()` calls `selectRuntime()` if `--runtime` missing\n3. **Path Resolution** — `resolveInstallPath()` combines `getRuntimePaths(runtime)` with project root for local installs, uses global path for `-g`\n4. **File Operations** — `installFilesForRuntime()` calls `getTemplatesForRuntime()` from `src/integration/templates.ts`, writes templates via `ensureDir()` → `writeFileSync()`, copies hooks from `hooks/dist/` via `readBundledHook()` → `writeFileSync()`\n5. **Hook Registration** — `registerHooks()` dispatches to `registerClaudeHooks()` or `registerGeminiHooks()`, merges hooks into `settings.json` under `hooks.SessionStart`/`hooks.SessionEnd`, writes ARE Bash permission patterns via `registerPermissions()` for Claude only\n6. **Verification** — `verifyInstallation()` checks all file paths via `existsSync()`, reports `missing[]` array for absent files\n7. **Display Results** — `displayInstallResults()` accumulates `totalCreated`/`totalSkipped`/`hooksRegistered` counters, calls `showNextSteps()` with ARE command list unless `--quiet` flag set\n\n## Uninstallation Flow\n\n1. **File Deletion** — `uninstallFilesForRuntime()` reads templates for path extraction, deletes command files and hooks via `unlinkSync()`, removes `ARE-VERSION` file\n2. **Hook Cleanup** — `unregisterHooks()` filters `settings.json` event arrays removing hooks matching `getHookPatterns()` for current (`node ${runtimeDir}/hooks/${filename}`) and legacy (`node hooks/${filename}`) formats, deletes empty event arrays and empty `hooks` object\n3. **Permission Cleanup** — `unregisterPermissions()` filters `permissions.allow` removing all `ARE_PERMISSIONS` entries, cleans up empty `permissions.allow`/`permissions` structures\n4. **Directory Cleanup** — `cleanupAreSkillDirs()` removes empty `are-*` skill subdirectories for Claude, `cleanupLegacyGeminiFiles()` deletes pre-TOML `*.md` files and nested `are/*.toml` files, `cleanupEmptyDirs()` recursively deletes empty parents stopping at runtime roots (`.claude`, `.opencode`, `.gemini`, `.config`)\n5. **Config Removal** — `deleteConfigFolder()` removes `.agents-reverse-engineer` directory for local installs via `rmSync({ recursive: true, force: true })`\n\n## Runtime-Specific Behaviors\n\n**Claude Code:**\n- Installs to `~/.claude` (global) or `.claude` (local), overridable via `CLAUDE_CONFIG_DIR`\n- Registers hooks in nested format: `settings.hooks[event] = [{ hooks: [{ type: 'command', command: string }] }]`\n- Adds five Bash permission patterns to `settings.permissions.allow`: `Bash(npx agents-reverse-engineer@latest init*)`, `discover*`, `generate*`, `update*`, `clean*`\n- Cleans up skill directories matching `are-*` prefix during uninstall\n\n**OpenCode:**\n- Installs to `~/.config/opencode` (global) or `.opencode` (local), respects `OPENCODE_CONFIG_DIR` → `XDG_CONFIG_HOME/opencode` → default fallback chain\n- Copies plugins to `plugins/` directory (auto-loaded by OpenCode runtime)\n- No settings.json registration (plugin system auto-discovers)\n- Supports plugin filenames: `are-check-update.js`, `are-session-end.js`\n\n**Gemini:**\n- Installs to `~/.gemini` (global) or `.gemini` (local), overridable via `GEMINI_CONFIG_DIR`\n- Registers hooks in flat format: `settings.hooks[event] = [{ name: string, type: 'command', command: string }]`\n- Cleans up legacy files during uninstall: `are-*.md` (pre-TOML commands), `are/*.toml` (pre-flat structure)\n\n## Behavioral Contracts\n\n**Hook Command Pattern:**\n```\nCurrent: node ${runtimeDir}/hooks/${filename}\nLegacy:  node hooks/${filename}\n```\n\n**Permission Pattern:**\n```\nBash(npx agents-reverse-engineer@latest <command>*)\n```\n\n**Settings JSON Indentation:**\n```javascript\nJSON.stringify(settings, null, 2)  // 2-space indent\n```\n\n**Runtime Root Basenames (recursion stop):**\n```\n.claude, .opencode, .gemini, .config\n```\n\n**Hook File Sources:**\n```\nhooks/dist/are-check-update.js\nhooks/dist/are-session-end.js\nhooks/dist/opencode-are-check-update.js\nhooks/dist/opencode-are-session-end.js\n```\n\n**Version File Location:**\n```\n${basePath}/ARE-VERSION\n```\n### src/integration/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/integration/\n\n**Platform-specific AI assistant integration layer performing environment detection, template generation, and file installation for Claude Code, OpenCode, Gemini CLI, and Aider via filesystem marker scanning and bundled hook deployment.**\n\n## Contents\n\n### Environment Detection\n\n**[detect.ts](./detect.ts)** — Exports `detectEnvironments()` and `hasEnvironment()` for AI runtime discovery via filesystem markers. `detectEnvironments()` scans `projectRoot` for Claude (`.claude/` or `CLAUDE.md`), OpenCode (`.opencode/`), Aider (`.aider.conf.yml` or `.aider/`) using synchronous `existsSync()` checks. Returns `DetectedEnvironment[]` with `type`, `configDir`, `detected` fields. `hasEnvironment()` provides predicate wrapper filtering by `EnvironmentType`.\n\n**[types.ts](./types.ts)** — Defines `EnvironmentType` literal union `'claude' | 'opencode' | 'aider' | 'gemini'`, `DetectedEnvironment` with `type`/`configDir`/`detected` fields, `IntegrationTemplate` with `filename`/`path`/`content` fields, `IntegrationResult` with `environment`/`filesCreated`/`filesSkipped` arrays.\n\n### Template Generation\n\n**[templates.ts](./templates.ts)** — Exports `getClaudeTemplates()`, `getOpenCodeTemplates()`, `getGeminiTemplates()` producing `IntegrationTemplate[]` arrays with platform-specific command files. Defines `COMMANDS` object with six templates (`generate`, `update`, `init`, `discover`, `clean`, `specify`, `help`) containing placeholder substitution for `COMMAND_PREFIX` (`/are-`), `VERSION_FILE_PATH` (`.claude/ARE-VERSION` | `.opencode/ARE-VERSION` | `.gemini/ARE-VERSION`), `$ARGUMENTS`. `PLATFORM_CONFIGS` maps `Platform` to `PlatformConfig` specifying `pathPrefix` (`.claude/skills/` | `.opencode/commands/` | `.gemini/commands/`), `filenameSeparator`, `usesName` (Claude-only YAML frontmatter), `extraFrontmatter` (OpenCode `agent: build`). `buildTemplate()` constructs paths, `buildFrontmatter()` injects YAML, `buildGeminiToml()` generates TOML format. Command content embeds background execution pattern with `run_in_background: true`, `TaskOutput` polling, `.agents-reverse-engineer/progress.log` monitoring via `Read` tool with `offset` parameter. `discover`/`clean` templates include strict rule blocks forbidding flag injection beyond `$ARGUMENTS`.\n\n### File Installation\n\n**[generate.ts](./generate.ts)** — Exports `generateIntegrationFiles(projectRoot, options?)` orchestrating setup via `detectEnvironments()` → `getTemplatesForEnvironment()` → `writeFileSync()` chain. Maps `EnvironmentType` to config directories (`claude` → `.claude`, `opencode` → `.opencode`, `aider` → `.aider`, `gemini` → `.gemini`). Creates parent directories via `ensureDir()` using `mkdirSync({ recursive: true })`. Skips existing files unless `options.force` overrides, populates `IntegrationResult.filesSkipped[]`. For `claude` environment specifically, copies bundled hook `are-session-end.js` from `hooks/dist/` to `.claude/hooks/are-session-end.js` via `readBundledHook()` → `writeFileSync()`. `getBundledHookPath()` resolves hook paths from `dist/integration/` up two levels to project root then into `hooks/dist/{hookName}`. Throws `Error` if bundled hook missing. Returns `IntegrationResult[]` with `filesCreated`/`filesSkipped` per environment. Respects `options.dryRun` for preview mode. Defines `GenerateOptions` interface with `dryRun?`, `force?`, `environment?` fields.\n\n## Integration Points\n\nConsumed by `src/installer/operations.ts` during npx-based installation workflow. `detectEnvironments()` validates target runtime presence before hook registration. Template generators provide command file content for `src/installer/operations.ts` writes. Generated files reference `VERSION_FILE_PATH` for session hooks' version checking logic.\n\n## File Path Patterns\n\n**Claude Code:**\n- Commands: `.claude/skills/are-{command}/SKILL.md`\n- Hooks: `.claude/hooks/are-session-end.js`\n- Version cache: `.claude/ARE-VERSION`\n\n**OpenCode:**\n- Commands: `.opencode/commands/are-{command}.md`\n- Version cache: `.opencode/ARE-VERSION`\n\n**Gemini CLI:**\n- Commands: `.gemini/commands/are-{command}.toml`\n- Version cache: `.gemini/ARE-VERSION`\n\n**Aider:**\n- Markers: `.aider.conf.yml`, `.aider/`\n- No template generation (detection only)\n\n## Hook Bundling Convention\n\nHooks copied from `hooks/dist/{hookName}` (post-build artifacts from `scripts/build-hooks.js`). Claude `are-session-end.js` hook spawns detached `npx agents-reverse-engineer@latest update --quiet` process on `git status --porcelain` detecting changes. Disable via `ARE_DISABLE_HOOK=1` environment variable or `hook_enabled: false` config flag.\n### src/orchestration/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/orchestration\n\n**Iterator-based concurrency pool orchestrating three-phase AI-driven documentation generation (file analysis → directory aggregation → root synthesis) with streaming progress, promise-chain serialized writes for GENERATION-PLAN.md updates and NDJSON trace emission, ETA calculation via moving average, and quality validation integration.**\n\n## Contents\n\n### Core Orchestration\n\n**[runner.ts](./runner.ts)** — `CommandRunner` executes three-phase pipeline: concurrent file `.sum` generation via `runPool()` with stale-doc detection, post-order directory `AGENTS.md` traversal grouped by depth, sequential root document synthesis (`CLAUDE.md`/`GEMINI.md`/`OPENCODE.md`), embeds quality validators (`checkCodeVsDoc`/`checkCodeVsCode`/`checkPhantomPaths`) post-phase with throttled directory grouping, builds `RunSummary` with token/cost/duration/inconsistency aggregates.\n\n**[pool.ts](./pool.ts)** — `runPool<T>()` implements shared-iterator worker pattern: all N workers pull from single `tasks.entries()` iterator preventing idle time between batches, emits `worker:start/end` and `task:pickup/done` trace events with `activeTasks` counter, supports `failFast` abort via mutable `aborted` flag checked before each task pickup, returns sparse `TaskResult<T>[]` array indexed by original task position.\n\n**[progress.ts](./progress.ts)** — `ProgressReporter` streams colored console output (`pc.cyan('ANALYZING')`, `pc.green('DONE')`, `pc.red('FAIL')`) with ETA calculated via sliding window (last 10 completion times) for files and directories separately, `ProgressLog` mirrors ANSI-stripped output to `.agents-reverse-engineer/progress.log` via promise-chain serialized writes for `tail -f` monitoring in buffered environments.\n\n**[plan-tracker.ts](./plan-tracker.ts)** — `PlanTracker` serializes concurrent checkbox updates (`- [ ] → - [x]`) for `GENERATION-PLAN.md` via promise-chain pattern (`writeQueue`), maintains in-memory markdown state, requires exact backtick-wrapped path matching (`` `src/cli/init.ts` ``), swallows write errors (non-critical operation).\n\n**[trace.ts](./trace.ts)** — `createTraceWriter()` factory returns `NullTraceWriter` (zero overhead) or `TraceWriter` (appends to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson`), auto-populates `seq`/`ts`/`pid`/`elapsedMs` base fields, emits 14 event types (`phase:start/end`, `worker:start/end`, `task:pickup/done`, `subprocess:spawn/exit`, `retry`, `discovery:start/end`, `filter:applied`, `plan:created`, `config:loaded`), `cleanupOldTraces()` enforces 500-file retention, uses `DistributiveOmit<TraceEvent, BaseKeys>` for discriminated union stripping.\n\n### Type Definitions\n\n**[types.ts](./types.ts)** — `FileTaskResult` carries per-task metrics (`tokensIn`/`tokensOut`/`cacheReadTokens`/`cacheCreationTokens`/`durationMs`/`model`), `RunSummary` aggregates command-level totals with quality counts (`inconsistenciesCodeVsDoc`/`inconsistenciesCodeVsCode`/`phantomPaths`), `ProgressEvent` discriminates five event types (`start`/`done`/`error`/`dir-done`/`root-done`) with type-specific optional fields, `CommandRunOptions` threads `concurrency`/`failFast`/`debug`/`dryRun`/`tracer`/`progressLog` from CLI through runner to pool and AIService.\n\n**[index.ts](./index.ts)** — Barrel export exposing `runPool`, `ProgressReporter`, `ProgressLog`, `PlanTracker`, `CommandRunner`, `ITraceWriter`, `TraceEvent`, `TraceEventPayload`, `createTraceWriter`, `cleanupOldTraces`, and shared types (`FileTaskResult`, `RunSummary`, `ProgressEvent`, `CommandRunOptions`, `PoolOptions`, `TaskResult`).\n\n## Concurrency Architecture\n\n### Shared-Iterator Pattern\n\n`runPool()` avoids batch-based idling by sharing single `tasks.entries()` iterator across N workers. Each worker pulls next `[index, taskFn]` tuple immediately after completing previous task, ensuring all slots stay busy until iterator exhausts. `Promise.allSettled(workers)` waits for all workers to finish or abort.\n\n### Fail-Fast Abort\n\nMutable `aborted` boolean flag set by any worker encountering error when `failFast: true`. Workers check `if (aborted) break` before pulling next task but do not interrupt running tasks. Results array remains sparse (undefined entries at aborted indices).\n\n### Serialization Guarantees\n\n`PlanTracker` and `TraceWriter` use promise-chain pattern (`writeQueue: Promise<void>`) to serialize concurrent writes. Each `markDone()` or `emit()` call chains onto previous write: `this.writeQueue = this.writeQueue.then(() => fs.writeFile(...))`. Guarantees NDJSON line order matches emission order despite pool concurrency.\n\n## Three-Phase Execution Flow\n\n### Phase 1: File Analysis (Concurrent)\n\n`CommandRunner.executeGenerate()` pre-caches existing `.sum` files at concurrency=20 for stale-doc detection. Maps file tasks to async functions reading source via `fs.readFile()`, computing `contentHash` via `computeContentHashFromString()`, calling `AIService.call()` with `buildFilePrompt()`, stripping preamble, extracting purpose (first non-preamble line truncated to 120 chars), writing `SumFileContent` with YAML frontmatter (`generated_at`, `content_hash`, `purpose`). Executes via `runPool(fileTasks, { concurrency, failFast, tracer, phaseLabel: 'phase-1-files' })`. Post-phase: groups files by directory, runs throttled (concurrency=10) `checkCodeVsDoc()` comparing old vs. new `.sum` against source content, aggregates `filesForCodeVsCode` array and runs `checkCodeVsCode()` for duplicate symbol detection.\n\n### Phase 2: Directory Aggregation (Post-Order Traversal)\n\nGroups `plan.directoryTasks` by `metadata.depth` into `Map<number, ExecutionTask[]>`, sorts depth levels descending (deepest-first). For each depth level: computes `dirConcurrency = Math.min(concurrency, dirsAtDepth.length)`, emits `phase:start`, maps directory tasks to async functions calling `buildDirectoryPrompt()` with `knownDirs` set and project structure context, calls AI service, writes via `writeAgentsMd()` (prepends existing `AGENTS.local.md` content if present), updates reporter and plan tracker. Executes via `runPool()` with depth-specific `phaseLabel`. Post-phase: runs `checkPhantomPaths()` on each generated `AGENTS.md` (three regex patterns: markdown links, backtick-quoted paths, prose-embedded paths), aggregates issues into `phantomReport`.\n\n### Phase 3: Root Synthesis (Sequential)\n\nSequential execution (concurrency=1) over `plan.rootTasks` (`CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`). Emits `task:start`, calls `buildRootPrompt()` with all `AGENTS.md` injected and root `package.json` metadata, calls `AIService.call({ prompt, systemPrompt, maxTurns: 1 })`, strips conversational preamble (two patterns: `\\n---\\n` separator or bold uppercase start), writes via `fs.writeFile()`, emits `task:done`, updates reporter and plan tracker. Flushes `planTracker.flush()` after loop.\n\n## Progress Reporting & ETA\n\n### Moving Average ETA\n\n`ProgressReporter` maintains `completionTimes: number[]` (files) and `dirCompletionTimes: number[]` (directories) sliding windows (max 10 entries). On task completion: pushes `durationMs`, shifts oldest if window exceeds size. `formatETA()` computes moving average `(sum / count) * remaining`, formats as `~Ns` or `~Mm Ss`, returns empty string if fewer than 2 completions.\n\n### Dual Output Streams\n\nConsole output uses `picocolors` for colored ANSI codes (`pc.cyan('ANALYZING')`, `pc.green('DONE')`, `pc.blue('DONE')` for directories/roots, `pc.red('FAIL')`). `ProgressLog` strips ANSI via regex `/\\x1b\\[[0-9;]*m/g` and appends to `.agents-reverse-engineer/progress.log` via promise-chain serialization. File handle opened lazily in truncate mode ('w') on first write, closed via `finalize()`.\n\n### Token Accounting Display\n\nTotal input tokens displayed as `tokensIn + cacheReadTokens + cacheCreationTokens`. Completion messages show format: `[X/Y] DONE path Xs in/out tok model ~ETA`. Summary prints: files processed/failed/skipped, total calls, tokens (input + cache read + cache creation / output), cache statistics (% read tokens, % creation tokens), files read (total and unique), elapsed time, errors, retries.\n\n## Trace Event System\n\n### Event Types & Schema\n\nDiscriminated union `TraceEvent` with 14 types. All events extend `TraceEventBase` with auto-populated fields: `seq` (monotonic counter), `ts` (ISO 8601), `pid` (`process.pid`), `elapsedMs` (high-resolution delta from `process.hrtime.bigint()` start).\n\n**Pool events:** `worker:start` (workerId, phase), `worker:end` (workerId, phase, tasksExecuted), `task:pickup` (workerId, taskIndex, taskLabel, activeTasks), `task:done` (workerId, taskIndex, taskLabel, durationMs, success, error?, activeTasks).\n\n**Subprocess events:** `subprocess:spawn` (childPid, command, taskLabel), `subprocess:exit` (childPid, command, taskLabel, exitCode, signal, durationMs, timedOut).\n\n**Phase events:** `phase:start` (phase, taskCount, concurrency), `phase:end` (phase, durationMs, tasksCompleted, tasksFailed).\n\n**Other events:** `retry` (attempt, taskLabel, errorCode), `discovery:start/end`, `filter:applied`, `plan:created`, `config:loaded`.\n\n### Emission & Serialization\n\nUsers call `tracer.emit(payload)` with `TraceEventPayload = DistributiveOmit<TraceEvent, BaseKeys>` (user-supplied data without auto-populated fields). `TraceWriter.emit()` populates base fields, serializes to JSON line, enqueues write via `writeQueue = writeQueue.then(() => fd.write(line))` promise-chain. Lazy-opens file handle via `fs.open(filePath, 'a')` after ensuring directory exists. `finalize()` awaits `writeQueue`, closes handle.\n\n### Cleanup & Retention\n\n`cleanupOldTraces(projectRoot, keepCount = 500)` reads `.agents-reverse-engineer/traces/`, sorts files by creation time descending via `fs.stat()`, deletes excess files, returns deletion count. Auto-invoked by `AIService.finalize()` in telemetry shutdown.\n\n## Quality Validation Integration\n\n### Code-vs-Doc Consistency\n\nPost-Phase 1: groups processed files by `path.dirname()`, runs throttled (concurrency=10) validation per directory. For each file: reads cached `sourceContent` from map, reads old `.sum` via `readSumFile()`, runs `checkCodeVsDoc(sourceContent, oldSum.summary, filePath)` appending `(stale documentation)` label, reads fresh `.sum`, runs second pass. `checkCodeVsDoc()` extracts exported symbols via regex `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`, verifies all exports appear in summary via substring search, reports `CodeDocInconsistency` with `missingFromDoc` arrays.\n\n### Code-vs-Code Duplicate Detection\n\nAggregates exports across per-directory file groups into `Map<symbol, string[]>`. Runs `checkCodeVsCode(filesForCodeVsCode)` detecting symbols appearing in multiple files, reports `CodeCodeInconsistency` with `pattern: 'duplicate-export'`.\n\n### Phantom Path Resolution\n\nPost-Phase 2: for each generated `AGENTS.md`, runs `checkPhantomPaths(agentsMdPath, content, projectRoot)` extracting path-like strings via three regex patterns (markdown links, backtick-quoted paths, prose-embedded paths), resolves against AGENTS.md directory and project root with `.ts`/`.js` fallback, reports `PhantomPathInconsistency` for unresolved references.\n\n### Report Formatting\n\nBuilds `InconsistencyReport` via `buildInconsistencyReport(issues, metadata)` with `metadata` (timestamp, projectRoot, filesChecked, durationMs), `issues[]` (discriminated union), `summary` (counts by type/severity). Prints via `formatReportForCli(report)` showing counts and groupings. Embeds in `RunSummary.inconsistencyReport` field.\n\n## Incremental Update Support\n\n`CommandRunner.executeUpdate()` implements Phase 1 only re-analysis for changed files. Attempts to load `GENERATION-PLAN.md` from `.agents-reverse-engineer/` for `projectPlan` context (falls through on error). Maps `filesToAnalyze` to async tasks reading source, reading existing `.sum`, building prompt via `buildFilePrompt({ filePath, content, projectPlan, existingSum })`, calling AI service, writing `.sum` with hash. Runs identical post-analysis quality checks (code-vs-doc, code-vs-code) without stale-doc comparison. Builds `RunSummary` with `updateInconsistenciesCodeVsDoc`/`updateInconsistenciesCodeVsCode` from report summary.\n\n## Behavioral Contracts\n\n### Preamble Stripping Patterns\n\n`stripPreamble()` implements two regex-based detection patterns:\n1. YAML separator: `/\\n---\\n/` within first 500 chars, returns content after separator\n2. Bold uppercase start: `/^[\\s\\S]{0,500}?(\\*\\*[A-Z])/` matches conversational preamble preceding bold section header, strips if <300 chars and no `##` markdown headers present\n\n### Purpose Extraction Filter\n\n`extractPurpose()` skips lines matching `PREAMBLE_PREFIXES` array via `line.toLowerCase().startsWith()`:\n```javascript\n['now i', 'perfect', 'based on', 'let me', 'here is', \"i'll\", 'i will', 'great', 'okay', 'sure', 'certainly', 'alright']\n```\n\nReturns first non-preamble/non-header/non-separator line with bold markdown stripped (`/^\\*\\*(.+)\\*\\*$/`) and 120-char truncation.\n\n### Checkbox Markdown Format\n\n`PlanTracker.markDone()` requires exact backtick-wrapped path format:\n```markdown\n- [ ] `src/cli/init.ts`     → file task\n- [ ] `src/cli/AGENTS.md`   → directory task (caller appends /AGENTS.md)\n- [ ] `CLAUDE.md`           → root task\n```\n\nString replacement via `` `- [ ] \\`${itemPath}\\`` → `- [x] \\`${itemPath}\\`` ``. Returns early if no match (no checkbox update queued).\n\n### Trace Filename Format\n\n`trace-{timestamp}.ndjson` where timestamp converts ISO 8601 to filesystem-safe format via `new Date().toISOString().replace(/[:.]/g, '-')` (colons/periods → hyphens).\n\n### Export Symbol Extraction Regex\n\nCode-vs-doc validator uses pattern: `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` matching top-level exports with optional `default` keyword, capturing symbol name via `(\\w+)` group.\n\n### Phantom Path Extraction Patterns\n\nThree regex patterns in `checkPhantomPaths()`:\n1. Markdown links: `/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g` captures relative paths in link targets\n2. Backtick-quoted paths: `` /`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g `` captures backtick-wrapped paths starting with `src/` or `./` or `../` with file extensions\n3. Prose-embedded paths: `/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi` captures paths following prepositions in prose text\n### src/output/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/output/\n\nTerminal output formatting layer providing dependency-injectable logger abstraction with conditional color support via picocolors.\n\n## Contents\n\n### [logger.ts](./logger.ts)\nExports `Logger` interface (six methods: `info()`, `file()`, `excluded()`, `summary()`, `warn()`, `error()`), `createLogger(options)` factory with picocolors-based ANSI formatting, and `createSilentLogger()` no-op factory for test/programmatic contexts.\n\n## Architecture\n\n**Dependency Injection Pattern**: Consumers receive `Logger` interface rather than direct `console` access, enabling output capture in tests and silence in programmatic workflows.\n\n**Conditional Color Support**: `createLogger(options)` binds `ColorFunctions` to picocolors `pc` when `options.colors` is true, otherwise to `noColor` identity functions. Single conditional at factory construction avoids per-call branching.\n\n**Output Routing**: `info()/file()/excluded()/summary()` write to `console.log()`, `warn()` to `console.warn()`, `error()` to `console.error()` for stream separation in shell redirects.\n\n## Behavioral Contracts\n\n**File Discovery Formatting**:\n- Included file: `` `  +` `` (green) + `path`\n- Excluded file: `` `  -` `` (dim) + `path` + ` (${reason}: ${filter})` (dim)\n- Summary: `Discovered ${included} files (${excluded} excluded)` (bold count, dim excluded)\n\n**Warning/Error Prefixes**:\n- `warn()`: `\"Warning: \"` (yellow) + message → stderr\n- `error()`: `\"Error: \"` (red) + message → stderr\n\n## Usage Context\n\nThreaded through `CommandRunOptions` → `DiscoveryOptions` → `run()` in `src/discovery/run.ts`. CLI commands instantiate via `createLogger({ colors: config.output.colors })`, test suites use `createSilentLogger()`.\n### src/quality/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality\n\nCode-documentation consistency validation subsystem executing three detection strategies: regex-based export extraction with substring matching (`code-vs-doc`), cross-file duplicate symbol aggregation (`code-vs-code`), and regex-based path reference resolution with filesystem verification (`phantom-paths`).\n\n## Contents\n\n**[index.ts](./index.ts)** — Barrel module re-exporting `checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()` validators, `buildInconsistencyReport()`, `formatReportForCli()` reporters, disabled `validateFindability()` density validator, and discriminated union types (`CodeDocInconsistency`, `CodeCodeInconsistency`, `PhantomPathInconsistency`, `Inconsistency`, `InconsistencyReport`).\n\n**[types.ts](./types.ts)** — Defines `InconsistencySeverity` (`'info' | 'warning' | 'error'`), `CodeDocInconsistency` (exported symbols missing from `.sum` with `missingFromDoc[]`), `CodeCodeInconsistency` (duplicate exports across files with `pattern: 'duplicate-export'`), `PhantomPathInconsistency` (unresolved paths in `AGENTS.md` with `referencedPath`, `resolvedTo`, `context`), `Inconsistency` discriminated union, `InconsistencyReport` container with metadata (`timestamp`, `projectRoot`, `filesChecked`, `durationMs`) and summary counts.\n\n## Subdirectories\n\n**[inconsistency/](./inconsistency/)** — code-vs-doc validator extracting exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm` with substring verification against `.sum` content; code-vs-code detector aggregating exports into `Map<symbol, paths[]>` to identify duplicates; reporter building aggregated `InconsistencyReport` with formatted CLI output.\n\n**[phantom-paths/](./phantom-paths/)** — Path reference validator extracting strings via three regex patterns (markdown links, backtick paths, prose references), resolving against `AGENTS.md` directory and project root with `.ts`/`.js` fallback, returning `PhantomPathInconsistency[]` for unresolved references.\n\n**[density/](./density/)** — Disabled `validateFindability()` stub previously verifying exported symbols from `.sum` files appeared in parent `AGENTS.md`; implementation gutted after `SumFileContent.metadata.publicInterface` removal.\n\n## Validation Workflow\n\n**Code-vs-Doc Consistency:**  \n`extractExports(filePath)` scans source via regex capturing export identifiers → `checkCodeVsDoc(filePath, sumContent)` performs substring search against `.sum` summary text → returns `CodeDocInconsistency` with `missingFromDoc[]` when drift detected or `null` when consistent.\n\n**Code-vs-Code Duplicate Detection:**  \n`checkCodeVsCode(files[])` aggregates `extractExports()` results into `Map<symbol, string[]>` → filters entries with `paths.length > 1` → returns `CodeCodeInconsistency[]` with `pattern: 'duplicate-export'` and `severity: 'warning'`.\n\n**Phantom Path Resolution:**  \n`checkPhantomPaths(agentsMdPath, content, projectRoot)` applies three regex patterns to extract path references → attempts resolution via `existsSync()` against `AGENTS.md` directory and project root with extension substitution → returns `PhantomPathInconsistency[]` for unresolved paths with 120-char context excerpt.\n\n**Report Aggregation:**  \n`buildInconsistencyReport(issues[], metadata)` merges inconsistency arrays → computes summary counts by `type` (`code-vs-doc`, `code-vs-code`, `phantom-path`) and `severity` (`error`, `warning`, `info`) → returns `InconsistencyReport` with timestamp metadata. `formatReportForCli(report)` transforms into plain-text output with severity tags (`[ERROR]`, `[WARN]`, `[INFO]`) and type-specific field rendering for stderr/`progress.log`.\n\n## Behavioral Contracts\n\n**Export Extraction Regex (inconsistency/):**  \n`/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`\n\n**Path Extraction Patterns (phantom-paths/validator.ts):**  \n```javascript\n/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g              // Markdown: [text](./path)\n/`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g  // Backtick: `src/foo.ts`\n/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi // Prose: \"from src/foo/\"\n```\n\n**Severity Tags (inconsistency/reporter.ts):**  \n`severity: 'error'` → `[ERROR]`, `severity: 'warning'` → `[WARN]`, `severity: 'info'` → `[INFO]`\n\n**Type Discriminator Field:**  \n`type: 'code-vs-doc' | 'code-vs-code' | 'phantom-path'` enables exhaustive switch narrowing.\n\n## Known Limitations\n\n**Regex-Based Export Extraction:**  \nMisses destructured (`export { foo }`), namespace (`export *`), dynamic exports, multiline declarations. No AST analysis—purely heuristic pattern matching.\n\n**Substring Verification:**  \nFalse negatives when export names appear in comments/prose rather than documented API surface. No structured field verification after `publicInterface` schema removal.\n\n**Intentional Duplication:**  \nCode-vs-code cannot distinguish factory patterns, parallel implementations, intentional re-exports. Caller must scope input to per-directory groups to minimize false positives.\n\n**Extension Fallback Logic:**  \nPath resolution attempts `.js` → `.ts` substitution but doesn't handle `.jsx`/`.tsx`, `.cjs`/`.mjs`, or index file resolution (`./foo` → `./foo/index.ts`).\n### src/quality/density/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/density\n\nDisabled findability validation stub that previously verified exported symbols from .sum files appeared in parent AGENTS.md content, retained for future structured metadata extraction support.\n\n## Contents\n\n**[validator.ts](./validator.ts)** — Exports `validateFindability()` returning empty array; previously extracted symbol names from `SumFileContent.metadata.publicInterface` and performed substring search in AGENTS.md content to compute per-file `FindabilityResult` with score calculation.\n\n## Exported Interface\n\n**FindabilityResult** — Validation result containing `filePath`, `symbolsTested[]`, `symbolsFound[]`, `symbolsMissing[]`, and `score` (0.0–1.0 ratio of found to tested symbols).\n\n**validateFindability()** — `(agentsMdContent: string, sumFiles: Map<string, SumFileContent>) => FindabilityResult[]` — Returns empty array; signature preserved but implementation gutted after `SumFileContent.metadata.publicInterface` removal.\n\n## Disabled Feature Context\n\nvalidator.ts implements LLM-free validation using string-based symbol matching with no AI subprocess calls. Disabled in `../index.ts` quality validation pipeline when `publicInterface` field removed from `SumFileContent` schema in `../../generation/writers/sum.ts`. Previously detected when directory-level AGENTS.md aggregation failed to preserve critical symbol names from child .sum file summaries.\n\n## Restoration Path\n\nRe-implementation requires:\n1. Adding structured export extraction to .sum file generation (Phase 1 of three-phase pipeline in `../../generation/orchestrator.ts`)\n2. Parsing YAML frontmatter in .sum files via `readSumFile()` from `../../generation/writers/sum.ts`\n3. Implementing symbol presence checks against AGENTS.md content\n4. Re-enabling in `../index.ts` quality validator orchestrator\n\n## Type Dependencies\n\nImports `SumFileContent` from `../../generation/writers/sum.ts` — Interface for parsed .sum file containing YAML frontmatter (`generated_at`, `content_hash`, `purpose`, `critical_todos[]`, `related_files[]`) and markdown summary content.\n### src/quality/inconsistency/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/inconsistency\n\nValidates code-documentation consistency by extracting exports from source files, verifying their presence in `.sum` documentation, detecting duplicate exports across file groups, and aggregating validation results into structured reports with CLI-formatted output.\n\n## Contents\n\n### Validators\n\n**[code-vs-doc.ts](./code-vs-doc.ts)** — `extractExports()` extracts exported identifiers from TypeScript/JavaScript source via regex pattern `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`. `checkCodeVsDoc()` verifies extracted exports appear in `.sum` file `summary` text via substring search, returning `CodeDocInconsistency` with `missingFromDoc[]` array when drift detected, or `null` when consistent.\n\n**[code-vs-code.ts](./code-vs-code.ts)** — `checkCodeVsCode()` detects duplicate exports across file groups by aggregating `extractExports()` results into `Map<symbol, paths[]>`, returning `CodeCodeInconsistency[]` array for symbols exported from multiple files with `pattern: 'duplicate-export'` and `severity: 'warning'`.\n\n### Report Generation\n\n**[reporter.ts](./reporter.ts)** — `buildInconsistencyReport()` aggregates `Inconsistency[]` into `InconsistencyReport` with summary counts by type (`code-vs-doc`, `code-vs-code`, `phantom-path`) and severity (`error`, `warning`, `info`). `formatReportForCli()` transforms report into plain-text output with severity tags `[ERROR]`/`[WARN]`/`[INFO]` and type-specific field rendering for stderr and `progress.log` output.\n\n## Validation Algorithm\n\n**Phase 1: Export Extraction**  \nRegex-based identifier capture from source declarations (`export function foo`, `export const BAR`, `export default class App`). Matches capture group 1 containing symbol name, filtering lines matching `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`.\n\n**Phase 2: Documentation Verification**  \nSubstring search against `.sum` file `summary` text. Export name must appear anywhere in summary content to pass validation. Missing symbols populate `CodeDocInconsistency.details.missingFromDoc[]` array.\n\n**Phase 3: Cross-File Duplicate Detection**  \nAggregates exports into `Map<symbol, string[]>` where keys are export names and values are file paths. Filters map entries where `paths.length > 1`, constructing `CodeCodeInconsistency` records with formatted description `\"Symbol \\\"${name}\\\" exported from ${paths.length} files\"`.\n\n**Phase 4: Report Aggregation**  \nMerges inconsistency arrays from code-vs-doc, code-vs-code, and phantom-path validators into single `InconsistencyReport` with summary counts. Populates metadata (timestamp, projectRoot, filesChecked, durationMs) and discriminates union via `issue.type` for CLI rendering.\n\n## Behavioral Contracts\n\n**Regex Export Pattern (code-vs-doc.ts, code-vs-code.ts):**  \n`/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`\n\n**CLI Report Severity Tags (reporter.ts):**  \n- `severity: 'error'` → `[ERROR]`  \n- `severity: 'warning'` → `[WARN]`  \n- `severity: 'info'` → `[INFO]`\n\n**Type-Specific Field Rendering (reporter.ts):**  \n- `code-vs-doc`: `File: ${filePath}`  \n- `code-vs-code`: `Files: ${files.join(', ')}`  \n- `phantom-path`: `Doc: ${agentsMdPath}`, `Path: ${referencedPath}`\n\n## Integration with Quality Pipeline\n\nCalled by `src/quality/index.ts` orchestrator after per-file validation. `checkCodeVsDoc()` invoked for each source file with parsed `.sum` content. `checkCodeVsCode()` receives scoped per-directory file groups to avoid false positives across unrelated modules. Results merged with phantom-path validation output, passed to `buildInconsistencyReport()` with run metadata (filesChecked, durationMs), then formatted via `formatReportForCli()` for stderr and `progress.log` output.\n\n## Known Limitations\n\n**Regex-Based Export Extraction:**  \nMisses destructured exports (`export { foo, bar }`), namespace exports (`export * from './module'`), dynamic exports, multiline declarations. No AST analysis—purely heuristic pattern matching.\n\n**Substring Verification:**  \nProduces false negatives when export names appear in comments, prose descriptions, or unrelated context rather than as documented API surface. No structured field verification after `publicInterface` schema removal.\n\n**Intentional Duplication:**  \nCode-vs-code validator cannot distinguish factory patterns, parallel implementations, or other intentional duplication without semantic analysis. Caller must scope input to per-directory groups to minimize false positives.\n### src/quality/phantom-paths/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/quality/phantom-paths\n\nDetects unresolvable path references in `AGENTS.md` files by extracting path-like strings via regex patterns, resolving them against both the `AGENTS.md` directory and project root with `.ts`/`.js` fallback logic, and returning `PhantomPathInconsistency` objects for non-existent paths.\n\n## Contents\n\n### [index.ts](./index.ts)\nBarrel re-export consolidating `checkPhantomPaths` validator for single import point.\n\n### [validator.ts](./validator.ts)\nCore validation logic extracting paths via `PATH_PATTERNS`, resolving with extension fallback, reporting `PhantomPathInconsistency` for unresolved references.\n\n## Exported Interface\n\n- **`checkPhantomPaths(agentsMdPath, content, projectRoot)`** — Validates path references in `AGENTS.md` content, returns `PhantomPathInconsistency[]` with `type: 'phantom-path'`, `severity: 'warning'`, `referencedPath`, `resolvedTo`, and 120-char `context` excerpt\n\n## Path Extraction Patterns\n\nThree regex patterns (`PATH_PATTERNS`) capture references:\n\n```javascript\n/\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g              // Markdown links: [text](./path)\n/`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g  // Backtick paths: `src/foo/bar.ts`\n/(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi // Prose paths: \"from src/foo/\"\n```\n\n`SKIP_PATTERNS` excludes `node_modules`, `.git/`, URLs (`https?:`), template syntax (`{{`, `${`), glob wildcards (`*`), brace expansions (`{a,b,c}`).\n\n## Resolution Strategy\n\nAttempts resolution in order: (1) relative to `agentsMdDir` via `path.dirname(agentsMdPath)`, (2) relative to `projectRoot`, (3) `.js` → `.ts` substitution for TypeScript import convention. Uses `existsSync()` to validate at least one candidate exists. Deduplicates via `seen` Set tracking `rawPath` strings.\n\n## Integration Context\n\nPart of quality validation subsystem (`src/quality/`) alongside code-vs-doc consistency (`../inconsistency/code-vs-doc.js`) and code-vs-code duplicate detection (`../inconsistency/code-vs-code.js`). Invoked during post-generation validation phase via `src/quality/index.ts` to identify broken path references that may mislead AI coding assistants.\n### src/specify/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# specify/\n\nSpecification synthesis from AGENTS.md corpus via AI-driven prompt construction (`buildSpecPrompt`) and filesystem output (`writeSpec`) with multi-file splitting and overwrite protection.\n\n## Contents\n\n### Files\n\n**[index.ts](./index.ts)** — Barrel module re-exporting `buildSpecPrompt`, `writeSpec`, `SpecPrompt`, `WriteSpecOptions`, `SpecExistsError` for `/are-specify` command integration.\n\n**[prompts.ts](./prompts.ts)** — `buildSpecPrompt(docs: AgentsDocs): SpecPrompt` constructs system/user prompts enforcing nine-section structure (Overview, Architecture, API Surface, Data Structures, Configuration, Dependencies, Behavioral Contracts, Test Contracts, Build Plan) with verbatim regex/format/constant preservation. `SPEC_SYSTEM_PROMPT` prohibits folder-mirroring, mandates concern-based organization, targets AI agents with actionable instructions.\n\n**[writer.ts](./writer.ts)** — `writeSpec(content: string, options: WriteSpecOptions): Promise<string[]>` writes single-file or multi-file specifications via heading-based splitting. `splitByHeadings(content)` partitions on `/^# /m` regex, `slugify()` sanitizes heading text to filenames (e.g., `\"Project Overview\"` → `\"project-overview.md\"`). Throws `SpecExistsError` with `paths: string[]` when targets exist and `force: false`.\n\n## Data Flow\n\n1. **Orchestration** (`src/cli/specify.ts`) invokes `collectAgentsDocs()` to gather all `AGENTS.md` files recursively\n2. **Prompt Construction** (`prompts.ts`) injects corpus into `SPEC_SYSTEM_PROMPT` template with section delimiters `### ${relativePath}`, appends nine-section requirements\n3. **AI Synthesis** (`AIService.call()` from `src/ai/service.ts`) processes prompt pair, returns specification markdown\n4. **Output** (`writer.ts`) writes single `specs/SPEC.md` or splits into `specs/<slugified-heading>.md` per top-level heading\n5. **Error Handling** catches `SpecExistsError` and displays `--force` hint\n\n## Behavioral Contracts\n\n### Prompt Constraints (SPEC_SYSTEM_PROMPT)\n\n**Organization rules:**\n- Regex `/^# (Project Overview|Architecture|Public API Surface|Data Structures & State|Configuration|Dependencies|Behavioral Contracts|Test Contracts|Build Plan)$/m` defines mandatory section headings\n- Prohibition pattern: \"Do NOT prescribe exact filenames or file paths\" / \"Do NOT mirror the project's folder structure\" / \"Do NOT use directory names as section headings\"\n- Behavioral Contracts split: \"Runtime Behavior (error handling, concurrency, lifecycle)\" + \"Implementation Contracts (verbatim regex patterns, format specs, magic constants)\"\n\n**Output format enforcement:**\n- Terminal instruction: `\"OUTPUT: Raw markdown. No preamble. No meta-commentary. No 'Here is...' or 'I've generated...' prefix.\"`\n- User prompt: `\"Output ONLY the markdown content. No preamble.\"`\n\n### File System Patterns (writer.ts)\n\n**Heading splitting regex:** `/^(?=# )/m` (positive lookahead for top-level headings)  \n**Heading extraction:** `/^# (.+)/` (capture heading text)  \n**Slugification chain:**\n1. `.toLowerCase()`\n2. `/\\s+/g` → `'-'` (whitespace to hyphens)\n3. `/[^a-z0-9-]/g` → `''` (strip non-alphanumeric except hyphens)\n4. `/-+/g` → `'-'` (collapse consecutive hyphens)\n5. `/^-|-$/g` → `''` (trim leading/trailing hyphens)\n\n**Preamble filename:** `00-preamble.md` (content before first `# ` heading)\n\n## Integration Points\n\n**Consumed by:** `src/cli/specify.ts` (command orchestrator)  \n**Consumes:**\n- `collectAgentsDocs()` from `../generation/collector.js` → `AgentsDocs` (array of `{relativePath, content}`)\n- `AIService.call()` from `../ai/service.js` (prompt pair execution)\n- `mkdir()`, `writeFile()`, `access()` from `node:fs/promises` (file operations)\n- `path.dirname()`, `path.join()` from `node:path` (path resolution)\n\n**Error propagation:** `SpecExistsError` thrown when `force: false` and target paths exist, caught by CLI layer for `--force` hint display\n### src/types/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/types\n\nShared TypeScript interface definitions for file discovery results, exclusion tracking, and statistics aggregation across ARE modules.\n\n## Contents\n\n### [index.ts](./index.ts)\nExports `ExcludedFile` (path + reason), `DiscoveryResult` (files + excluded arrays), `DiscoveryStats` (totalFiles, includedFiles, excludedFiles, exclusionReasons histogram).\n\n## Usage Pattern\n\n`src/discovery/walker.ts` returns `DiscoveryResult` from traversal functions. `src/cli/discover.ts` consumes `DiscoveryResult` to format console output and write `GENERATION-PLAN.md`. `src/orchestration/runner.ts` logs `DiscoveryStats` to telemetry during discovery phase.\n\n## Data Model\n\n### ExcludedFile\n- `path: string` — Absolute/relative file path\n- `reason: string` — Exclusion rationale (\"gitignore pattern\", \"binary file\", \"vendor directory\")\n\n### DiscoveryResult\n- `files: string[]` — Selected for analysis\n- `excluded: ExcludedFile[]` — Rejected with reasons\n\n### DiscoveryStats\n- `totalFiles: number`, `includedFiles: number`, `excludedFiles: number` — Counts\n- `exclusionReasons: Record<string, number>` — Reason → occurrence count map\n### src/update/AGENTS.md\n\n<!-- Generated by agents-reverse-engineer -->\n\n# src/update/\n\nIncremental documentation synchronization via frontmatter SHA-256 hash comparison, orphaned artifact cleanup, and targeted directory regeneration.\n\n## Contents\n\n### Core Orchestration\n\n**[index.ts](./index.ts)** — Barrel export aggregating `UpdateOrchestrator` class, `createUpdateOrchestrator()` factory, cleanup functions (`cleanupOrphans`, `cleanupEmptyDirectoryDocs`, `getAffectedDirectories`), and type interfaces (`UpdateOptions`, `UpdateResult`, `UpdateProgress`, `CleanupResult`).\n\n**[orchestrator.ts](./orchestrator.ts)** — `UpdateOrchestrator` class executing hash-based change detection via `preparePlan()`: discovers files through `runDiscovery()`, reads `.sum` YAML frontmatter via `readSumFile()` to extract `contentHash`, computes current SHA-256 via `computeContentHash()`, produces `UpdatePlan` with `filesToAnalyze[]` (hash mismatch/missing), `filesToSkip[]` (hash match), `cleanup: CleanupResult` (orphaned `.sum` files), `affectedDirs[]` (depth-sorted parent directories). Emits trace events (`phase:start`, `plan:created`, `phase:end`) via `ITraceWriter`. No-op methods (`close()`, `recordFileAnalyzed()`, `removeFileState()`, `recordRun()`, `getLastRun()`) preserved for API compatibility after SQLite state manager removal.\n\n**[orphan-cleaner.ts](./orphan-cleaner.ts)** — `cleanupOrphans()` deletes `.sum` files for `FileChange` entries with `status === 'deleted'` (uses `change.path`) or `status === 'renamed'` (uses `change.oldPath`), returns `CleanupResult` with `deletedSumFiles[]` and `deletedAgentsMd[]`. `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` from directories containing only hidden files (`.` prefix), `.sum` files, or `GENERATED_FILES` set members. `getAffectedDirectories()` walks parent directories via `path.dirname()` for non-deleted `FileChange` entries, excludes `status === 'deleted'`, always includes `'.'` root.\n\n**[types.ts](./types.ts)** — `UpdateOptions` interface with `includeUncommitted?: boolean` (merges `git status --porcelain` into change set) and `dryRun?: boolean` (preview-only). `UpdateResult` interface with `analyzedFiles[]`, `skippedFiles[]`, `cleanup`, `regeneratedDirs[]`, `baseCommit`, `currentCommit`, `dryRun` fields. `UpdateProgress` callback interface with `onFileStart()`, `onFileDone()`, `onCleanup()`, `onDirRegenerate()` hooks. `CleanupResult` interface with `deletedSumFiles[]`, `deletedAgentsMd[]` arrays. Re-exports `FileChange` from `../change-detection/types.js`.\n\n## Update Algorithm\n\n**Hash-Based Change Detection** (orchestrator.ts `preparePlan()` method):\n1. `checkPrerequisites()` verifies git repository via `isGitRepo()`\n2. `getCurrentCommit()` retrieves HEAD commit SHA\n3. `discoverFiles()` wraps `runDiscovery()` from `../discovery/run.js`, converts absolute paths to relative via `path.relative()`\n4. For each file: `getSumPath()` locates `.sum` file, `readSumFile()` extracts `contentHash` from YAML frontmatter, `computeContentHash()` computes current SHA-256\n5. Hash mismatch or missing `.sum` → `FileChange` with `status: 'added'|'modified'` added to `filesToAnalyze[]`\n6. Hash match → path added to `filesToSkip[]`\n7. `cleanupOrphans()` deletes `.sum` files for deleted/renamed sources\n8. `getAffectedDirectories()` computes unique parent directory set from `filesToAnalyze[]`\n9. `affectedDirs[]` sorted by depth descending via `split(path.sep).length` (deepest-first for bottom-up regeneration)\n\n**Orphan Cleanup** (orphan-cleaner.ts):\n- Deleted files: Appends `.sum` to `change.path`, calls `deleteIfExists()`\n- Renamed files: Appends `.sum` to `change.oldPath`, calls `deleteIfExists()`\n- Empty directories: `cleanupEmptyDirectoryDocs()` removes `AGENTS.md` if directory contains no source files (excludes hidden files, `.sum` files, `AGENTS.md`, `CLAUDE.md`)\n- `deleteIfExists()` internal helper: `stat()` existence check, `unlink()` delete (skipped if `dryRun === true`), returns boolean\n\n## Integration Points\n\n**Upstream Dependencies:**\n- `../change-detection/index.js` — `isGitRepo()`, `getCurrentCommit()`, `computeContentHash()`, `FileChange` type\n- `../generation/writers/sum.js` — `readSumFile()` (parses YAML frontmatter), `getSumPath()` (resolves `.sum` path)\n- `../discovery/run.js` — `discoverFiles()` wrapping `runDiscovery()` for file scanning\n- `../config/schema.js` — `Config` type with exclude patterns and concurrency settings\n- `../orchestration/trace.js` — `ITraceWriter` interface for NDJSON trace emission\n\n**Downstream Consumers:**\n- `../cli/update.ts` — CLI entry point invoking `createUpdateOrchestrator()` with parsed options\n- `hooks/are-session-end.js` — Session hook spawning `npx agents-reverse-engineer@latest update --quiet` on uncommitted changes\n\n## API Compatibility Pattern\n\norchestrator.ts no-op methods preserve interface contract for consumers expecting SQLite-based state management (removed in frontmatter migration):\n- `close()` — No database resources to clean\n- `recordFileAnalyzed()` — Hash now stored in `.sum` YAML frontmatter\n- `removeFileState()` — Cleanup handled by `cleanupOrphans()`\n- `recordRun()` — Returns `0` (no run history tracking)\n- `getLastRun()` — Returns `undefined` (no historical run data)\n\n## Trace Events\n\norchestrator.ts emits via `ITraceWriter`:\n- `{ type: 'phase:start', phase: 'update-plan-creation' }` — Start of `preparePlan()`\n- `{ type: 'plan:created', planType: 'update', fileCount, taskCount }` — Plan finalized\n- `{ type: 'phase:end', phase: 'update-plan-creation', durationMs, tasksCompleted: 1, tasksFailed: 0 }` — Plan complete\n\n## Debug Logging\n\norchestrator.ts stderr output (when `debug: true`):\n- `'[debug] Creating update plan with change detection...'` — Start signal\n- `'[debug] Git commit: <hash>'` — First 7 characters of commit SHA\n- `'[debug] Discovering files...'` — Before discovery phase\n- `'[debug] Change detection: <changed> changed, <unchanged> unchanged, <orphaned> orphaned'` — After hash comparison\n- `'[debug] Affected directories: <count>'` — Directory regeneration scope\n\n## Output Requirements\n\nThe specification MUST include these sections in order:\n1. Project Overview (purpose, value, tech stack)\n2. Architecture (module boundaries, data flow, design decisions)\n3. Public API Surface (all exported interfaces, full type signatures)\n4. Data Structures & State (types, schemas, config objects)\n5. Configuration (options, types, defaults, validation)\n6. Dependencies (each with version and rationale)\n7. Behavioral Contracts (error handling, concurrency, lifecycle, PLUS verbatim regex patterns, format specs, magic constants, templates)\n8. Test Contracts (per-module test scenarios and edge cases)\n9. Build Plan (phased implementation order with dependencies)\n\nOutput ONLY the markdown content. No preamble.",
      "systemPrompt": "You produce software specifications from documentation.\n\nTASK:\nGenerate a comprehensive specification document from the provided AGENTS.md content. The specification must contain enough detail for an AI agent to reconstruct the entire project from scratch without seeing the original source code.\n\nAUDIENCE: AI agents (LLMs) — use structured, precise, instruction-oriented language. Every statement should be actionable.\n\nORGANIZATION (MANDATORY):\nGroup content by CONCERN, not by directory structure. Use these conceptual sections in order:\n\n1. Project Overview — purpose, core value proposition, problem solved, technology stack with versions\n2. Architecture — system design, module boundaries, data flow patterns, key design decisions and their rationale\n3. Public API Surface — all exported interfaces, function signatures with full parameter and return types, type definitions, error contracts\n4. Data Structures & State — key types, schemas, config objects, state management patterns, serialization formats\n5. Configuration — all config options with types, defaults, validation rules, environment variables\n6. Dependencies — each external dependency with exact version and rationale for inclusion\n7. Behavioral Contracts — Split into two subsections:\n   a. Runtime Behavior: error handling strategies (exact error types/codes and when thrown), retry logic (formulas, delay values), concurrency model, lifecycle hooks, resource management\n   b. Implementation Contracts: every regex pattern used for parsing/validation/extraction (verbatim in backticks), every format string and output template (exact structure with examples), every magic constant and sentinel value with its meaning, every environment variable with expected values, every file format specification (YAML schemas, NDJSON structures). These are reproduction-critical — an AI agent needs them to rebuild the system with identical observable behavior.\n8. Test Contracts — what each module's tests should verify: scenarios, edge cases, expected behaviors, error conditions\n9. Build Plan — phased implementation sequence: what to build first and why, dependency order between modules, incremental milestones\n\nRULES:\n- Describe MODULE BOUNDARIES and their interfaces — not file paths or directory layouts\n- Use exact function, type, and constant names as they appear in the documentation\n- Include FULL type signatures for all public APIs (parameters, return types, generics)\n- Do NOT prescribe exact filenames or file paths — describe what each module does and exports\n- Do NOT mirror the project's folder structure in your section organization\n- Do NOT use directory names as section headings\n- Include version numbers for ALL external dependencies\n- The Build Plan MUST list implementation phases with explicit dependency ordering\n- Each Build Plan phase must state what it depends on and what it enables\n- Behavioral Contracts must specify exact error types/codes and when they are thrown\n- Behavioral Contracts MUST include verbatim regex patterns, format strings, and magic constants from the source documents — do NOT paraphrase regex patterns into prose descriptions\n- When multiple modules reference the same constant or pattern, consolidate into a single definition with cross-references to the modules that use it\n\nOUTPUT: Raw markdown. No preamble. No meta-commentary. No \"Here is...\" or \"I've generated...\" prefix.",
      "response": "# agents-reverse-engineer: AI-Driven Codebase Documentation Generator\n\n## 1. Project Overview\n\n**Purpose**: Automate brownfield documentation for AI coding assistants by generating AI-friendly codebase documentation through concurrent file analysis, post-order directory aggregation, and platform-specific root synthesis.\n\n**Core Value Proposition**: Transforms undocumented codebases into structured, AI-consumable documentation via the Recursive Language Model (RLM) algorithm—a three-phase pipeline executing concurrent per-file `.sum` analysis via subprocess pools, post-order directory `AGENTS.md` aggregation, and platform-specific root document synthesis (`CLAUDE.md`, `GEMINI.md`, `OPENCODE.md`).\n\n**Problem Solved**: AI coding assistants require structured codebase context to provide accurate assistance. Manual documentation is time-consuming and quickly becomes stale. ARE automates this process with gitignore-aware discovery, SHA-256 incremental updates, and session lifecycle hooks that keep documentation synchronized with code changes.\n\n**Technology Stack**:\n- **Runtime**: Node.js ≥18.0.0 (ES modules)\n- **Language**: TypeScript 5.7.3 (ES2022 target, NodeNext module resolution, strict mode)\n- **Core Dependencies**:\n  - `fast-glob` ^3.3.3 — File discovery with glob patterns\n  - `ignore` ^7.0.3 — Gitignore parsing\n  - `isbinaryfile` ^5.0.4 — Binary file detection\n  - `simple-git` ^3.27.0 — Git-based change detection\n  - `yaml` ^2.7.0 — Configuration YAML parsing\n  - `zod` ^3.24.1 — Schema validation\n  - `ora` ^8.1.1 — CLI spinner UI\n  - `picocolors` ^1.1.1 — Terminal ANSI colors\n- **AI Backend Adapters**:\n  - `@anthropic-ai/claude-code` — Claude Code CLI integration\n  - Gemini CLI — Stub implementation (JSON output stabilization pending)\n  - OpenCode CLI — Stub implementation (JSONL parsing pending)\n- **Build System**: TypeScript compiler (`tsc`) emitting `src/` → `dist/`, `scripts/build-hooks.js` copying `hooks/` → `hooks/dist/`\n- **Distribution**: npm package v0.6.5 with dual binary entry points (`are`, `agents-reverse-engineer`), MIT license\n\n---\n\n## 2. Architecture\n\n### 2.1 System Design: Three-Phase RLM Pipeline\n\n**Phase 1: Concurrent File Analysis**\n\nIterator-based worker pool (`src/orchestration/pool.ts`) shares single task iterator (`tasks.entries()`) across N workers (default 2 for WSL, 5 elsewhere) to prevent over-allocation. Each worker invokes:\n\n```\nAIService.call() → withRetry() → runSubprocess() → execFile()\n```\n\nSpawns AI CLI subprocesses with resource limits:\n- `NODE_OPTIONS='--max-old-space-size=512'` — 512MB heap per subprocess\n- `UV_THREADPOOL_SIZE='4'` — 4-thread libuv pool constraint\n- `CLAUDE_CODE_DISABLE_BACKGROUND_TASKS='1'` — Prevents background task spawning\n- `--disallowedTools Task` — Blocks subagent spawning\n\nProcess group killing (`kill(-pid)`) terminates subprocess trees on timeout. SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period. Exponential backoff retry on rate limits (stderr patterns: `\"rate limit\"`, `\"429\"`, `\"too many requests\"`, `\"overloaded\"`).\n\nWrites `.sum` files with YAML frontmatter:\n```yaml\n---\ngenerated_at: 2026-02-09T12:34:56.789Z\ncontent_hash: a3f5d8e9... (SHA-256 hex, 64 chars)\npurpose: One-line purpose statement\ncritical_todos:\n  - Security issue\nrelated_files:\n  - path1\n  - path2\n---\n\nMarkdown summary content...\n```\n\n**Phase 2: Post-Order Directory Aggregation**\n\nSorts directories by depth descending (`path.relative().split(path.sep).length` metric—deepest first). Waits for all child `.sum` files via `isDirectoryComplete()` predicate before processing directory.\n\nPrompts include:\n- Aggregated child `.sum` content via `readSumFile()`\n- Subdirectory `AGENTS.md` files via recursive traversal\n- Import maps via `extractDirectoryImports()` with verified path constraints\n- Manifest detection (9 types: `package.json`, `Cargo.toml`, `go.mod`, `pyproject.toml`, `pom.xml`, `build.gradle`, `Gemfile`, `composer.json`, `CMakeLists.txt`/`Makefile`)\n\nUser-authored `AGENTS.md` files renamed to `AGENTS.local.md` and prepended above generated content with `---` separator. Writes `AGENTS.md` with `<!-- Generated by agents-reverse-engineer -->` marker.\n\n**Phase 3: Root Document Synthesis**\n\nSequential execution (concurrency=1) generates platform-specific integration documents:\n- `CLAUDE.md` — Claude Code runtime integration\n- `GEMINI.md` — Gemini CLI integration\n- `OPENCODE.md` — OpenCode runtime integration\n\nPrompts consume all `AGENTS.md` files via `collectAgentsDocs()` recursive tree traversal, parse root `package.json` for project metadata, enforce synthesis-only constraints (no invention of features/hooks/patterns not in source documents). Strips conversational preamble via pattern matching before writing output.\n\n### 2.2 Module Boundaries\n\n**Discovery Layer** (`src/discovery/`)\n- **Responsibility**: Gitignore-aware file traversal with composable exclusion filters\n- **Exports**: `discoverFiles(root, config)` → `FilterResult` with `included[]`/`excluded[]` attribution\n- **Dependencies**: `fast-glob` for directory walking, `ignore` for gitignore parsing, `isbinaryfile` for content analysis\n\n**Generation Layer** (`src/generation/`)\n- **Responsibility**: Three-phase orchestration with prompt construction and writer coordination\n- **Exports**: `GenerationOrchestrator.createPlan()` → `GenerationPlan`, `buildExecutionPlan()` → `ExecutionPlan`, prompt builders\n- **Dependencies**: Discovery results, AI service, import extractor, file writers\n\n**AI Service Layer** (`src/ai/`)\n- **Responsibility**: Backend-agnostic subprocess management with retry logic and telemetry\n- **Exports**: `AIService`, backend registry, subprocess runner\n- **Dependencies**: Child process management, Zod for parsing, backend adapters\n\n**Orchestration Layer** (`src/orchestration/`)\n- **Responsibility**: Worker pool execution with progress streaming and trace emission\n- **Exports**: `runPool()`, `CommandRunner`, `ProgressReporter`, `TraceWriter`, `PlanTracker`\n- **Dependencies**: AI service, generation plan, progress log, NDJSON serialization\n\n**Update Layer** (`src/update/`)\n- **Responsibility**: Incremental synchronization via SHA-256 hash comparison\n- **Exports**: `UpdateOrchestrator.preparePlan()` → `UpdatePlan`, orphan cleanup functions\n- **Dependencies**: Change detection, discovery, generation writers, directory depth sorting\n\n**Quality Layer** (`src/quality/`)\n- **Responsibility**: Code-documentation consistency validation\n- **Exports**: `checkCodeVsDoc()`, `checkCodeVsCode()`, `checkPhantomPaths()`, report builder\n- **Dependencies**: Regex-based export extraction, filesystem path resolution\n\n**Configuration Layer** (`src/config/`)\n- **Responsibility**: YAML config management with Zod validation and adaptive defaults\n- **Exports**: `loadConfig()`, `writeDefaultConfig()`, `getDefaultConcurrency()`\n- **Dependencies**: YAML parser, Zod schema, OS resource detection\n\n**CLI Layer** (`src/cli/`)\n- **Responsibility**: Command routing with argument parsing and orchestration coordination\n- **Exports**: Command handlers (`generate`, `update`, `init`, `discover`, `clean`, `specify`)\n- **Dependencies**: All subsystems via facade pattern\n\n**Installer Layer** (`src/installer/`)\n- **Responsibility**: npx-based IDE integration with hook registration\n- **Exports**: `runInstall()`, `runUninstall()`, interactive prompts\n- **Dependencies**: Template generator, path resolution, filesystem operations\n\n### 2.3 Data Flow Patterns\n\n**Generate Command Flow**:\n```\nCLI parse args\n→ loadConfig()\n→ resolveBackend()\n→ discoverFiles()\n→ GenerationOrchestrator.createPlan()\n  → analyzeComplexity()\n  → buildFilePrompt() per file\n  → group by directory\n  → sort by depth\n→ CommandRunner.executeGenerate()\n  → Phase 1: runPool(fileTasks, concurrency)\n    → AIService.call() per file\n    → writeSumFile()\n  → Phase 2: runPool(dirTasks, depth-grouped)\n    → buildDirectoryPrompt()\n    → AIService.call()\n    → writeAgentsMd()\n  → Phase 3: sequential root tasks\n    → buildRootPrompt()\n    → AIService.call()\n    → stripPreamble()\n    → writeFile()\n→ Quality validation\n→ Telemetry finalization\n```\n\n**Update Command Flow**:\n```\nCLI parse args\n→ loadConfig()\n→ UpdateOrchestrator.preparePlan()\n  → isGitRepo()\n  → getCurrentCommit()\n  → discoverFiles()\n  → for each file:\n    → readSumFile() extract contentHash\n    → computeContentHash() current\n    → hash match? filesToSkip : filesToAnalyze\n  → cleanupOrphans() delete stale .sum\n  → getAffectedDirectories() parent walk\n  → depth-sort affectedDirs\n→ CommandRunner.executeUpdate()\n  → Phase 1: runPool(filesToAnalyze)\n  → Phase 2: sequential affectedDirs regeneration\n→ Quality validation\n→ Telemetry finalization\n```\n\n**Trace Event Flow**:\n```\nCLI --trace flag\n→ createTraceWriter()\n→ Thread tracer via CommandRunOptions\n→ Worker pool emits: worker:start/end, task:pickup/done\n→ AIService emits: subprocess:spawn/exit, retry\n→ Discovery emits: discovery:start/end, filter:applied\n→ TraceWriter serializes via promise-chain\n→ Append to .agents-reverse-engineer/traces/trace-{timestamp}.ndjson\n→ cleanupOldTraces() enforces 500-file retention\n```\n\n### 2.4 Key Design Decisions\n\n**Decision**: Shared iterator pool over batch-based distribution\n**Rationale**: Prevents idle workers between batches. Single `tasks.entries()` iterator consumed by all N workers ensures continuous work pickup until exhaustion. Sparse result array indexed by original task position preserves ordering despite concurrent execution.\n\n**Decision**: YAML frontmatter for content hashing over SQLite state database\n**Rationale**: Eliminates external database dependency, makes `.sum` files self-contained, enables simple filesystem-based cleanup without database synchronization concerns. SHA-256 hash stored directly in frontmatter enables O(1) staleness check per file.\n\n**Decision**: Post-order traversal with directory depth sorting\n**Rationale**: Ensures all child `.sum` files exist before parent `AGENTS.md` generation. Depth-based grouping (`Map<depth, directories[]>`) enables concurrent processing within depth levels while maintaining bottom-up data dependency guarantees.\n\n**Decision**: Process group killing with negative PID\n**Rationale**: Claude CLI spawns internal subprocess trees (GitHub #5771: 200 NodeJS instances). Positive PID kills only parent, leaving orphan children consuming resources. Negative PID (`kill(-pid)`) sends signal to entire process group, terminating trees atomically.\n\n**Decision**: Promise-chain serialization for concurrent writes\n**Rationale**: Worker pool concurrency creates race conditions for `GENERATION-PLAN.md` checkbox updates and NDJSON trace emission. Mutable `writeQueue: Promise<void>` with chaining pattern (`writeQueue = writeQueue.then(() => fs.writeFile(...))`) serializes writes while preserving emission order without blocking workers.\n\n**Decision**: Exponential backoff retry only for rate limits\n**Rationale**: Timeout errors indicate resource exhaustion (heap/threads) where retries would compound problem. Rate limit errors indicate temporary API throttling where exponential backoff succeeds. `isRateLimitStderr()` predicate enables selective retry strategy.\n\n---\n\n## 3. Public API Surface\n\n### 3.1 CLI Commands\n\n**Binary Entry Points**: `are` and `agents-reverse-engineer` (both resolve to `dist/cli/index.js`)\n\n```bash\n# Initialization\nare init [--force]\n# Creates .agents-reverse-engineer/config.yaml with defaults\n\n# Discovery (preview)\nare discover [--debug] [--trace]\n# Scans files, writes GENERATION-PLAN.md with phase breakdown\n\n# Generation\nare generate [--concurrency N] [--debug] [--trace] [--fail-fast] [--dry-run]\n# Three-phase execution: .sum → AGENTS.md → CLAUDE.md/GEMINI.md/OPENCODE.md\n\n# Incremental Update\nare update [--uncommitted] [--concurrency N] [--debug] [--trace] [--fail-fast] [--dry-run]\n# Hash-based change detection, regenerates only modified files\n\n# Specification Synthesis\nare specify [--output PATH] [--multi-file] [--force] [--debug] [--trace]\n# Synthesizes all AGENTS.md into specs/SPEC.md or split specs\n\n# Cleanup\nare clean [--dry-run]\n# Removes .sum, generated AGENTS.md, CLAUDE.md, GENERATION-PLAN.md\n\n# Installation\nnpx agents-reverse-engineer [--runtime claude|opencode|gemini] [--global|-g] [--local|-l] [--force]\n# Interactive installer for IDE integration\n\n# Uninstallation\nnpx agents-reverse-engineer --uninstall [--runtime claude|opencode|gemini] [-g|-l]\n# Removes commands, hooks, config artifacts\n\n# Version & Help\nare --version|-V\nare --help|-h\n```\n\n**Global Flags** (available across all commands):\n- `--debug` — Enable verbose subprocess logging with heap/RSS metrics to stderr\n- `--trace` — Emit NDJSON trace events to `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson`\n- `--dry-run` — Preview operations without writing files (generate/update/clean)\n- `--concurrency N` — Override worker pool size (1-20, default from config adaptive calculation)\n- `--fail-fast` — Abort on first task failure instead of continuing\n\n**Command-Specific Flags**:\n- `update --uncommitted` — Include working tree changes (merges `git status --porcelain` output)\n- `specify --output PATH` — Custom output path (default: `specs/SPEC.md`)\n- `specify --multi-file` — Split by top-level headings into `specs/<slug>.md` files\n- `specify --force` — Overwrite existing specification files\n- `init --force` — Overwrite existing config.yaml\n- Installer `--runtime RT` — Target runtime: `claude`, `opencode`, `gemini`, or `all`\n- Installer `-g|--global` — Install to global config directory (`~/.claude`, `~/.config/opencode`, `~/.gemini`)\n- Installer `-l|--local` — Install to project-local directory (`.claude`, `.opencode`, `.gemini`)\n\n**Exit Codes**:\n- `0` — Success (all files succeeded or no files to process)\n- `1` — Partial failure (`filesProcessed > 0 && filesFailed > 0`) or file exists error\n- `2` — Total failure (`filesProcessed === 0 && filesFailed > 0`) or CLI not found\n\n### 3.2 IDE Integration Commands\n\n**Claude Code / OpenCode Skills** (`.claude/skills/are-{command}/SKILL.md` or `.opencode/commands/are-{command}.md`):\n\n```yaml\nname: /are-generate\ndescription: Generate AI-friendly documentation for entire codebase\n```\n\n**Commands Available**:\n- `/are-init` — Create configuration\n- `/are-discover` — Preview generation plan\n- `/are-generate` — Full documentation generation with background execution pattern\n- `/are-update` — Incremental update\n- `/are-specify` — Synthesize project specification\n- `/are-clean` — Remove generated artifacts\n- `/are-help` — Show command list\n\n**Background Execution Pattern** (embedded in command templates):\n```yaml\nrun_in_background: true\n# Poll with TaskOutput every 10-15s:\nTaskOutput(task_id, block: false, timeout: 1000)\n# Monitor progress via Read tool:\nRead(file_path: '.agents-reverse-engineer/progress.log', offset: <last-line>)\n# Check completion via exit code or \"Generation complete\" marker\n```\n\n**Gemini TOML Format** (`.gemini/commands/are-{command}.toml`):\n```toml\ndescription = \"Generate AI-friendly documentation\"\nprompt = \"\"\"\nExecute: npx agents-reverse-engineer@latest generate\nMonitor: .agents-reverse-engineer/progress.log\n\"\"\"\n```\n\n### 3.3 TypeScript Module Exports\n\n**Discovery**:\n```typescript\n// src/discovery/index.ts\nexport function discoverFiles(\n  root: string,\n  config: DiscoveryConfig,\n  options?: { tracer?: ITraceWriter; debug?: boolean }\n): Promise<FilterResult>\n\nexport interface FilterResult {\n  included: string[]\n  excluded: ExcludedFile[]\n}\n\nexport interface ExcludedFile {\n  path: string\n  reason: string\n  filter: string\n}\n```\n\n**Generation**:\n```typescript\n// src/generation/orchestrator.ts\nexport class GenerationOrchestrator {\n  constructor(projectRoot: string, config: Config, tracer?: ITraceWriter)\n  \n  async createPlan(discoveryResult: FilterResult): Promise<GenerationPlan>\n}\n\nexport interface GenerationPlan {\n  projectRoot: string\n  totalFiles: number\n  complexity: ComplexityMetrics\n  fileTasks: PreparedFile[]\n  directoryTasks: PreparedDirectory[]\n}\n\n// src/generation/executor.ts\nexport function buildExecutionPlan(plan: GenerationPlan): ExecutionPlan\n\nexport interface ExecutionPlan {\n  projectRoot: string\n  fileTasks: ExecutionTask[]\n  directoryTasks: ExecutionTask[]\n  rootTasks: ExecutionTask[]\n}\n\nexport interface ExecutionTask {\n  id: string\n  type: 'file' | 'directory' | 'root'\n  path: string\n  dependencies: string[]\n  metadata: Record<string, unknown>\n}\n```\n\n**AI Service**:\n```typescript\n// src/ai/service.ts\nexport class AIService {\n  constructor(backend: AIBackend, options: {\n    timeoutMs: number\n    maxRetries: number\n    model?: string\n    telemetry?: { enabled: boolean }\n  })\n  \n  async call(options: AICallOptions): Promise<AIResponse>\n  setDebug(enabled: boolean): void\n  setSubprocessLogDir(dir: string): void\n  setTracer(tracer: ITraceWriter): void\n  finalize(projectRoot: string): { totalInputTokens: number; ... }\n}\n\nexport interface AICallOptions {\n  prompt: string\n  systemPrompt: string\n  model?: string\n  timeoutMs?: number\n  maxTurns?: number\n  taskLabel?: string\n}\n\nexport interface AIResponse {\n  text: string\n  model: string\n  inputTokens: number\n  outputTokens: number\n  cacheReadTokens: number\n  cacheCreationTokens: number\n  durationMs: number\n  exitCode: number\n  raw: string\n}\n```\n\n**Update**:\n```typescript\n// src/update/orchestrator.ts\nexport class UpdateOrchestrator {\n  constructor(projectRoot: string, config: Config, options: UpdateOptions)\n  \n  async preparePlan(): Promise<UpdatePlan>\n}\n\nexport interface UpdatePlan {\n  filesToAnalyze: FileChange[]\n  filesToSkip: string[]\n  cleanup: CleanupResult\n  affectedDirs: string[]\n  baseCommit: string\n  currentCommit: string\n  isFirstRun: boolean\n}\n\nexport interface FileChange {\n  path: string\n  status: 'added' | 'modified' | 'deleted' | 'renamed'\n  oldPath?: string\n  contentHash?: string\n}\n```\n\n**Quality**:\n```typescript\n// src/quality/index.ts\nexport function checkCodeVsDoc(\n  sourceContent: string,\n  sumContent: string,\n  filePath: string\n): CodeDocInconsistency | null\n\nexport function checkCodeVsCode(\n  files: Array<{ path: string; content: string }>\n): CodeCodeInconsistency[]\n\nexport function checkPhantomPaths(\n  agentsMdPath: string,\n  content: string,\n  projectRoot: string\n): PhantomPathInconsistency[]\n\nexport interface CodeDocInconsistency {\n  type: 'code-vs-doc'\n  severity: 'error'\n  filePath: string\n  details: { missingFromDoc: string[] }\n}\n\nexport interface CodeCodeInconsistency {\n  type: 'code-vs-code'\n  severity: 'warning'\n  files: string[]\n  description: string\n  pattern: 'duplicate-export'\n  symbol: string\n}\n\nexport interface PhantomPathInconsistency {\n  type: 'phantom-path'\n  severity: 'warning'\n  agentsMdPath: string\n  referencedPath: string\n  resolvedTo: string | null\n  context: string\n}\n```\n\n**Configuration**:\n```typescript\n// src/config/loader.ts\nexport function loadConfig(\n  root: string,\n  options?: { tracer?: ITraceWriter; debug?: boolean }\n): Config | never // throws ConfigError on validation failure\n\nexport function configExists(root: string): Promise<boolean>\n\nexport function writeDefaultConfig(root: string): Promise<void>\n\nexport class ConfigError extends Error {\n  constructor(message: string, public filePath: string, public cause?: Error)\n}\n\n// src/config/schema.ts\nexport interface Config {\n  exclude: {\n    patterns: string[]\n    vendorDirs: string[]\n    binaryExtensions: string[]\n  }\n  options: {\n    followSymlinks: boolean\n    maxFileSize: number\n  }\n  output: {\n    colors: boolean\n  }\n  ai: {\n    backend: 'claude' | 'gemini' | 'opencode' | 'auto'\n    model?: string\n    timeoutMs: number\n    maxRetries: number\n    concurrency: number\n    telemetry: {\n      enabled: boolean\n      keepRuns: number\n      costThresholdUsd: number\n    }\n    pricing: Record<string, {\n      inputCostPer1kTokens: number\n      outputCostPer1kTokens: number\n      cacheReadCostPer1kTokens: number\n      cacheWriteCostPer1kTokens: number\n    }>\n  }\n}\n```\n\n**Trace System**:\n```typescript\n// src/orchestration/trace.ts\nexport interface ITraceWriter {\n  emit(payload: TraceEventPayload): void\n  finalize(): Promise<void>\n}\n\nexport function createTraceWriter(\n  projectRoot: string,\n  enabled: boolean\n): ITraceWriter // Returns NullTraceWriter if disabled\n\nexport type TraceEvent = \n  | { type: 'phase:start'; phase: string; taskCount: number; concurrency: number }\n  | { type: 'phase:end'; phase: string; durationMs: number; tasksCompleted: number; tasksFailed: number }\n  | { type: 'worker:start'; workerId: number; phase: string }\n  | { type: 'worker:end'; workerId: number; phase: string; tasksExecuted: number }\n  | { type: 'task:pickup'; workerId: number; taskIndex: number; taskLabel: string; activeTasks: number }\n  | { type: 'task:done'; workerId: number; taskIndex: number; taskLabel: string; durationMs: number; success: boolean; error?: string; activeTasks: number }\n  | { type: 'subprocess:spawn'; childPid: number; command: string; taskLabel: string }\n  | { type: 'subprocess:exit'; childPid: number; command: string; taskLabel: string; exitCode: number; signal: string | null; durationMs: number; timedOut: boolean }\n  | { type: 'retry'; attempt: number; taskLabel: string; errorCode: string }\n  | { type: 'discovery:start' | 'discovery:end' | 'filter:applied' | 'plan:created' | 'config:loaded'; ... }\n\n// All events include auto-populated fields:\n// seq: number, ts: string (ISO 8601), pid: number, elapsedMs: number\n```\n\n---\n\n## 4. Data Structures & State\n\n### 4.1 .sum File Format\n\n**Location**: Colocated with source files (`src/foo.ts` → `src/foo.ts.sum`)\n\n**Structure**:\n```yaml\n---\ngenerated_at: 2026-02-09T12:34:56.789Z\ncontent_hash: a3f5d8e9b2c4f1a8e7d6c5b4a3e2d1f0c9b8a7d6e5f4c3b2a1f0e9d8c7b6a5f4\npurpose: Single-line purpose statement (120 char max)\ncritical_todos:\n  - Security: validate user input\n  - Performance: optimize query\nrelated_files:\n  - ../types/index.ts\n  - ./helper.ts\n---\n\nMarkdown summary content with behavioral contracts:\n\nExported symbols: `extractImports()`, `formatImportMap()`\n\nRegex patterns: `/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm`\n\nMagic constants: `IMPORT_SCAN_LINE_LIMIT = 100`\n```\n\n**Frontmatter Fields**:\n- `generated_at: string` — ISO 8601 timestamp with milliseconds\n- `content_hash: string` — SHA-256 hex digest (64 chars)\n- `purpose: string` — First non-preamble line from AI response, 120 char truncation\n- `critical_todos?: string[]` — Optional array of actionable items\n- `related_files?: string[]` — Optional array of relative paths\n\n**Array Formatting Heuristic** (adaptive inline/multi-line):\n- Inline `[a, b, c]` when `length <= 3` AND all items `< 40` chars\n- Multi-line `- item` otherwise\n- Empty arrays: `key: []`\n\n### 4.2 AGENTS.md Format\n\n**Location**: One per directory (`src/AGENTS.md`, `src/cli/AGENTS.md`)\n\n**Structure**:\n```markdown\n<!-- Generated by agents-reverse-engineer -->\n\n# Directory Name\n\nPurpose statement for directory.\n\n## Contents\n\n### [file.ts](./file.ts)\nSummary from .sum file with purpose and key exports.\n\n### [subdirectory/](./subdirectory/)\nDescription of subdirectory purpose.\n\n## Architecture Section\n\nCross-file relationships, patterns, integration points.\n\n## Import Map\n\n```\nfile-a.ts:\n  ../external/module.js → ExportedType\n  ./internal.js → helperFunction\n```\n\n## Behavioral Contracts\n\nVerbatim regex patterns, format strings, constants.\n```\n\n**User Content Preservation**:\nWhen user-authored `AGENTS.md` exists (lacks `<!-- Generated by agents-reverse-engineer -->` marker):\n1. Rename to `AGENTS.local.md`\n2. Construct final output:\n   ```markdown\n   <!-- Generated by agents-reverse-engineer -->\n\n   <!-- User-defined AGENTS.md preserved as AGENTS.local.md -->\n\n   {user content from AGENTS.local.md}\n\n   ---\n\n   {LLM-generated content}\n   ```\n\n### 4.3 Configuration Schema\n\n**Location**: `.agents-reverse-engineer/config.yaml`\n\n**Full Schema**:\n```yaml\nexclude:\n  patterns:\n    - \"AGENTS.md\"\n    - \"CLAUDE.md\"\n    - \"*.sum\"\n    - \"*.lock\"\n    # ... 26 default patterns\n  vendorDirs:\n    - \"node_modules\"\n    - \".git\"\n    - \"dist\"\n    # ... 18 default directories\n  binaryExtensions:\n    - \".png\"\n    - \".jpg\"\n    - \".zip\"\n    # ... 26 default extensions\n\noptions:\n  followSymlinks: false\n  maxFileSize: 1048576  # 1MB threshold\n\noutput:\n  colors: true\n\nai:\n  backend: auto  # 'claude' | 'gemini' | 'opencode' | 'auto'\n  model: sonnet  # Backend-specific model identifier\n  timeoutMs: 300000  # 5 minutes\n  maxRetries: 3\n  concurrency: 5  # Adaptive default via getDefaultConcurrency()\n  \n  telemetry:\n    enabled: true\n    keepRuns: 50\n    costThresholdUsd: 10\n  \n  pricing:\n    claude:\n      inputCostPer1kTokens: 0.003\n      outputCostPer1kTokens: 0.015\n      cacheReadCostPer1kTokens: 0.0003\n      cacheWriteCostPer1kTokens: 0.00375\n```\n\n**Adaptive Concurrency Calculation**:\n```javascript\ncores = os.availableParallelism() || os.cpus().length\nmemCap = floor((totalMemGB * 0.5) / 0.512)  // 50% RAM, 512MB per subprocess\nconcurrency = max(2, min(cores * 5, memCap, 20))  // Clamp [2, 20]\n```\n\n### 4.4 Trace Event Schema\n\n**Location**: `.agents-reverse-engineer/traces/trace-{timestamp}.ndjson`\n\n**Base Fields** (auto-populated on all events):\n```typescript\n{\n  seq: number       // Monotonic counter\n  ts: string        // ISO 8601 timestamp\n  pid: number       // Process ID\n  elapsedMs: number // High-resolution time since process start\n}\n```\n\n**Event Payloads** (14 discriminated union types):\n```typescript\n// Worker pool events\n{ type: 'worker:start', workerId: number, phase: string }\n{ type: 'worker:end', workerId: number, phase: string, tasksExecuted: number }\n{ type: 'task:pickup', workerId: number, taskIndex: number, taskLabel: string, activeTasks: number }\n{ type: 'task:done', workerId: number, taskIndex: number, taskLabel: string, durationMs: number, success: boolean, error?: string, activeTasks: number }\n\n// Subprocess events\n{ type: 'subprocess:spawn', childPid: number, command: string, taskLabel: string }\n{ type: 'subprocess:exit', childPid: number, command: string, taskLabel: string, exitCode: number, signal: string | null, durationMs: number, timedOut: boolean }\n\n// Phase events\n{ type: 'phase:start', phase: string, taskCount: number, concurrency: number }\n{ type: 'phase:end', phase: string, durationMs: number, tasksCompleted: number, tasksFailed: number }\n\n// Other events\n{ type: 'retry', attempt: number, taskLabel: string, errorCode: string }\n{ type: 'discovery:start', filesScanned: number }\n{ type: 'discovery:end', filesIncluded: number, filesExcluded: number, durationMs: number }\n{ type: 'filter:applied', filterName: string, filesMatched: number, filesRejected: number }\n{ type: 'plan:created', planType: string, fileCount: number, taskCount: number }\n{ type: 'config:loaded', configPath: string, model: string, concurrency: number }\n```\n\n**Retention**: 500 most recent trace files via lexicographic sort on ISO 8601 filenames\n\n### 4.5 Telemetry Schema\n\n**Location**: `.agents-reverse-engineer/logs/run-{timestamp}.json`\n\n**Structure**:\n```json\n{\n  \"runId\": \"2026-02-09T12-00-00-000Z\",\n  \"startTime\": \"2026-02-09T12:00:00.000Z\",\n  \"endTime\": \"2026-02-09T12:15:30.456Z\",\n  \"entries\": [\n    {\n      \"timestamp\": \"2026-02-09T12:00:01.234Z\",\n      \"prompt\": \"Analyze file: src/cli/index.ts\",\n      \"systemPrompt\": \"You are analyzing TypeScript source...\",\n      \"response\": \"...\",\n      \"model\": \"claude-sonnet-4.5\",\n      \"inputTokens\": 1500,\n      \"outputTokens\": 800,\n      \"cacheReadTokens\": 500,\n      \"cacheCreationTokens\": 200,\n      \"latencyMs\": 3456,\n      \"exitCode\": 0,\n      \"retryCount\": 0,\n      \"filesRead\": [\n        { \"path\": \"src/cli/index.ts\", \"sizeBytes\": 4096, \"linesRead\": 120 }\n      ]\n    }\n  ],\n  \"summary\": {\n    \"totalInputTokens\": 150000,\n    \"totalOutputTokens\": 75000,\n    \"totalCacheReadTokens\": 50000,\n    \"totalCacheCreationTokens\": 25000,\n    \"totalDurationMs\": 300456,\n    \"errorCount\": 2,\n    \"totalFilesRead\": 150,\n    \"uniqueFilesRead\": 148\n  }\n}\n```\n\n**Retention**: 50 most recent run logs (configurable via `config.ai.telemetry.keepRuns`)\n\n### 4.6 Update Plan Structure\n\n```typescript\ninterface UpdatePlan {\n  filesToAnalyze: FileChange[]      // Hash mismatch or missing .sum\n  filesToSkip: string[]              // Hash match (unchanged)\n  cleanup: CleanupResult             // Orphaned .sum files\n  affectedDirs: string[]             // Parent directories (depth-sorted)\n  baseCommit: string                 // Base git commit SHA\n  currentCommit: string              // Current HEAD SHA\n  isFirstRun: boolean                // No existing .sum files\n}\n\ninterface FileChange {\n  path: string                       // Relative path from project root\n  status: 'added' | 'modified' | 'deleted' | 'renamed'\n  oldPath?: string                   // For renames only\n  contentHash?: string               // SHA-256 hex (64 chars)\n}\n\ninterface CleanupResult {\n  deletedSumFiles: string[]          // Removed .sum files\n  deletedAgentsMd: string[]          // Removed AGENTS.md (empty dirs)\n}\n```\n\n---\n\n## 5. Configuration\n\n### 5.1 Configuration File Location\n\n**Path**: `.agents-reverse-engineer/config.yaml` (project root)\n\n**Environment Overrides**:\n- `CLAUDE_CONFIG_DIR` — Override `~/.claude` path\n- `OPENCODE_CONFIG_DIR` — Override `~/.config/opencode` path\n- `GEMINI_CONFIG_DIR` — Override `~/.gemini` path\n- `ARE_DISABLE_HOOK` — Set to `1` to disable session-end auto-update\n\n### 5.2 Configuration Fields\n\n**exclude.patterns: string[]**\n- **Type**: Gitignore-style glob patterns\n- **Default**: 26 patterns excluding AI docs, lock files, dotfiles, artifacts\n- **Validation**: Array of strings, no regex validation\n- **Examples**: `\"*.sum\"`, `\"**/.env*\"`, `\"AGENTS.md\"`, `\"**/SKILL.md\"`\n\n**exclude.vendorDirs: string[]**\n- **Type**: Directory basenames to skip\n- **Default**: 18 directories including `node_modules`, `.git`, `dist`, `build`, `__pycache__`, `.next`, `venv`, `.venv`, `target`, `.cargo`, `.gradle`, `.agents-reverse-engineer`, `.agents`, `.planning`, `.claude`, `.opencode`, `.gemini`, `vendor`\n- **Validation**: Array of strings, matched via Set lookup (single-segment) or substring search (path patterns)\n\n**exclude.binaryExtensions: string[]**\n- **Type**: File extensions to skip\n- **Default**: 26 extensions including `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`, `.ico`, `.webp`, `.zip`, `.tar`, `.gz`, `.rar`, `.7z`, `.exe`, `.dll`, `.so`, `.dylib`, `.mp3`, `.mp4`, `.wav`, `.pdf`, `.woff`, `.woff2`, `.ttf`, `.eot`, `.class`, `.pyc`\n- **Validation**: Array of strings with leading dot (`.ext`)\n\n**options.followSymlinks: boolean**\n- **Type**: Boolean\n- **Default**: `false`\n- **Purpose**: Enable symlink traversal during file discovery\n- **Security**: Disabled by default to prevent circular references and unintended directory escapes\n\n**options.maxFileSize: number**\n- **Type**: Integer (bytes)\n- **Default**: `1048576` (1MB)\n- **Validation**: `Zod.number().int().min(0)`\n- **Purpose**: Binary detection threshold—files exceeding this size trigger content analysis via `isbinaryfile`\n\n**output.colors: boolean**\n- **Type**: Boolean\n- **Default**: `true`\n- **Purpose**: Enable ANSI color codes in CLI output\n- **Effect**: When `false`, `createLogger()` binds identity functions instead of picocolors\n\n**ai.backend: 'claude' | 'gemini' | 'opencode' | 'auto'**\n- **Type**: Enum\n- **Default**: `'auto'`\n- **Validation**: `Zod.enum(['claude', 'gemini', 'opencode', 'auto'])`\n- **Behavior**: `'auto'` performs parallel availability checks via `isCommandOnPath()`, returns first available CLI\n\n**ai.model: string | undefined**\n- **Type**: Optional string\n- **Default**: `'sonnet'` (Claude backend default)\n- **Purpose**: Override backend-specific model identifier\n- **Examples**: `'claude-sonnet-4.5'`, `'gemini-pro'`, `'opencode-latest'`\n\n**ai.timeoutMs: number**\n- **Type**: Integer (milliseconds)\n- **Default**: `300000` (5 minutes)\n- **Validation**: `Zod.number().int().min(1000)`\n- **Behavior**: SIGTERM sent at `timeoutMs`, SIGKILL escalation after 5s grace period\n\n**ai.maxRetries: number**\n- **Type**: Integer\n- **Default**: `3`\n- **Validation**: `Zod.number().int().min(0).max(10)`\n- **Behavior**: Exponential backoff retry only for rate limit errors, skips timeout errors\n\n**ai.concurrency: number**\n- **Type**: Integer\n- **Default**: Adaptive via `getDefaultConcurrency()` (typically 2-20)\n- **Validation**: `Zod.number().int().min(1).max(20)`\n- **Override**: CLI `--concurrency N` flag\n\n**ai.telemetry.enabled: boolean**\n- **Type**: Boolean\n- **Default**: `true`\n- **Purpose**: Write run logs to `.agents-reverse-engineer/logs/`\n\n**ai.telemetry.keepRuns: number**\n- **Type**: Integer\n- **Default**: `50`\n- **Validation**: `Zod.number().int().min(0)`\n- **Behavior**: Retention limit for historical run logs (lexicographic sort + slice)\n\n**ai.telemetry.costThresholdUsd: number**\n- **Type**: Number (USD)\n- **Default**: `10`\n- **Validation**: `Zod.number().min(0)`\n- **Purpose**: Warning threshold for cumulative costs (not yet implemented)\n\n**ai.pricing.{backend}: object**\n- **Type**: Per-backend pricing configuration\n- **Fields**:\n  - `inputCostPer1kTokens: number`\n  - `outputCostPer1kTokens: number`\n  - `cacheReadCostPer1kTokens: number`\n  - `cacheWriteCostPer1kTokens: number`\n- **Default**: Claude pricing (input: $0.003, output: $0.015, cache read: $0.0003, cache write: $0.00375)\n\n### 5.3 Configuration Validation\n\n**Schema Validation**: Zod schema enforcement in `loadConfig()`\n- On validation failure: throws `ConfigError` with formatted ZodError messages\n- On missing file: returns default config via `ConfigSchema.parse({})`\n- On YAML parse error: throws `ConfigError` with parse failure message\n\n**Quoted String Pattern** (YAML serialization):\n```javascript\n/[*{}\\[\\]?,:#&!|>'\"%@`]/  // Metacharacters requiring quotes\n```\n\n**Escape Sequences**:\n- Backslash: `\\\\` → `\\\\\\\\`\n- Double quote: `\"` → `\\\"`\n\n---\n\n## 6. Dependencies\n\n### 6.1 Runtime Dependencies\n\n**fast-glob ^3.3.3**\n- **Purpose**: File discovery with glob patterns\n- **Rationale**: Performance-optimized glob matching with ignore patterns, cross-platform consistency, `absolute: true` option eliminates path resolution overhead\n- **Used By**: `src/discovery/walker.ts` for directory traversal with `{absolute: true, onlyFiles: true, ignore: ['**/.git/**']}`\n\n**ignore ^7.0.3**\n- **Purpose**: Gitignore parsing\n- **Rationale**: Official `.gitignore` parser maintaining compatibility with git's exclusion semantics, required for gitignore filter\n- **Used By**: `src/discovery/filters/gitignore.ts`, `src/discovery/filters/custom.ts` for pattern matching\n\n**isbinaryfile ^5.0.4**\n- **Purpose**: Binary file detection\n- **Rationale**: Heuristic-based content analysis detecting non-text files without full read, fallback for files exceeding `maxFileSize` threshold\n- **Used By**: `src/discovery/filters/binary.ts` after extension and size checks\n\n**simple-git ^3.27.0**\n- **Purpose**: Git-based change detection\n- **Rationale**: Type-safe git command abstraction, diff parsing with rename detection (`git diff -M`), status parsing (`git status --porcelain`)\n- **Used By**: `src/change-detection/detector.ts` for incremental update workflow\n\n**yaml ^2.7.0**\n- **Purpose**: Configuration YAML parsing\n- **Rationale**: Spec-compliant YAML 1.2 parser with error recovery, handles commented config templates\n- **Used By**: `src/config/loader.ts` for reading `.agents-reverse-engineer/config.yaml`\n\n**zod ^3.24.1**\n- **Purpose**: Schema validation\n- **Rationale**: Type-safe runtime validation with discriminated unions, automatic TypeScript inference, detailed error messages for config validation\n- **Used By**: `src/config/schema.ts` for `ConfigSchema`, `src/ai/backends/claude.ts` for JSON response parsing\n\n**ora ^8.1.1**\n- **Purpose**: CLI spinner UI\n- **Rationale**: Non-blocking progress indication during long-running operations, cross-platform terminal state management\n- **Used By**: CLI commands for background task indication (future use—currently logging-based progress)\n\n**picocolors ^1.1.1**\n- **Purpose**: Terminal ANSI colors\n- **Rationale**: Zero-dependency, minimal overhead, conditional color support via single factory binding\n- **Used By**: `src/output/logger.ts` for colored CLI output when `config.output.colors === true`\n\n### 6.2 AI Backend Dependencies\n\n**@anthropic-ai/claude-code (peer dependency)**\n- **Purpose**: Claude Code CLI integration\n- **Rationale**: Official Anthropic CLI for Claude API access with local caching, tool use support\n- **Used By**: `src/ai/backends/claude.ts` as subprocess invocation target\n- **Version Constraint**: None specified (resolves to globally installed `claude` CLI)\n\n**Gemini CLI (external)**\n- **Purpose**: Gemini API integration\n- **Rationale**: Google's official CLI for Gemini models (stub implementation pending JSON output stabilization)\n- **Used By**: `src/ai/backends/gemini.ts` (throws `SUBPROCESS_ERROR` until implemented)\n- **Installation**: https://gemini.google.com/cli\n\n**OpenCode CLI (external)**\n- **Purpose**: OpenCode runtime integration\n- **Rationale**: Alternative AI coding assistant (stub implementation pending JSONL parsing)\n- **Used By**: `src/ai/backends/opencode.ts` (throws `SUBPROCESS_ERROR` until implemented)\n- **Installation**: https://opencode.dev\n\n### 6.3 Development Dependencies\n\n**typescript ^5.7.3**\n- **Purpose**: TypeScript compiler\n- **Rationale**: ES2022 target with NodeNext module resolution, strict type checking, declaration generation\n- **Config**: `tsconfig.json` with `src/` → `dist/` emit\n\n**tsx (implied, not in package.json)**\n- **Purpose**: Development hot reload\n- **Rationale**: TypeScript execution without build step\n- **Used By**: `npm run dev` script\n\n---\n\n## 7. Behavioral Contracts\n\n### 7.1 Runtime Behavior\n\n**Error Handling Strategy**:\n\n`AIServiceError` discriminated union with five codes:\n- `CLI_NOT_FOUND` — Backend CLI not in PATH, thrown by `resolveBackend()`, includes installation instructions\n- `TIMEOUT` — Subprocess exceeded `timeoutMs`, thrown by `runSubprocess()`, no retry\n- `PARSE_ERROR` — Backend response failed JSON parsing, thrown by `parseResponse()`, no retry\n- `SUBPROCESS_ERROR` — Non-zero exit code without timeout, thrown by `runSubprocess()`, retries if rate limit detected\n- `RATE_LIMIT` — Stderr contains rate limit patterns, thrown by `isRateLimitStderr()`, exponential backoff retry up to `maxRetries`\n\n**Retry Logic**:\n\nExponential backoff formula:\n```javascript\ndelay = min(baseDelayMs * multiplier^attempt, maxDelayMs) + jitter\nbaseDelayMs = 1000  // 1 second\nmultiplier = 2\nmaxDelayMs = 60000  // 1 minute\njitter = random(0..500)  // Milliseconds\n```\n\nRate limit detection (case-insensitive stderr substring search):\n```javascript\n['rate limit', '429', 'too many requests', 'overloaded'].some(p => \n  stderr.toLowerCase().includes(p)\n)\n```\n\nRetry predicate:\n- ✅ Retry on `RATE_LIMIT` error code\n- ❌ Skip retry on `TIMEOUT` (resource exhaustion)\n- ❌ Skip retry on `PARSE_ERROR` (malformed response)\n- ❌ Skip retry on `CLI_NOT_FOUND` (configuration error)\n\n**Concurrency Model**:\n\nIterator-based shared-task pool:\n```javascript\nasync function runPool<T>(tasks: Task<T>[], options: PoolOptions): Promise<TaskResult<T>[]> {\n  const iterator = tasks.entries()\n  const workers = Array.from({ length: concurrency }, (_, i) => \n    workerLoop(i, iterator, options)\n  )\n  const results = await Promise.allSettled(workers)\n  return sparsify(results)  // undefined for aborted indices\n}\n\nasync function workerLoop(workerId, iterator, options) {\n  for (const [index, taskFn] of iterator) {\n    if (options.aborted) break\n    try {\n      const result = await taskFn()\n      results[index] = { success: true, result }\n    } catch (error) {\n      results[index] = { success: false, error }\n      if (options.failFast) options.aborted = true\n    }\n  }\n}\n```\n\n**Lifecycle Hooks**:\n\nSession start hook (`are-check-update.js`):\n```javascript\n// Spawns detached background process:\nspawn(process.execPath, ['-e', `\n  const { execSync } = require('child_process');\n  const latest = execSync('npm view agents-reverse-engineer version', { encoding: 'utf8', timeout: 10000 }).trim();\n  const installed = readFileSync('${versionFilePath}', 'utf-8').trim();\n  const result = { update_available: latest !== installed, installed, latest, checked: Date.now() };\n  writeFileSync('${cacheFilePath}', JSON.stringify(result, null, 2));\n`], { stdio: 'ignore', detached: true, windowsHide: true }).unref()\n```\n\nSession end hook (`are-session-end.js`):\n```javascript\n// Exit early if disabled:\nif (process.env.ARE_DISABLE_HOOK === '1') process.exit(0);\nif (readFileSync('.agents-reverse-engineer.yaml', 'utf-8').includes('hook_enabled: false')) process.exit(0);\n\n// Check for uncommitted changes:\nconst changes = execSync('git status --porcelain', { encoding: 'utf-8' });\nif (!changes.trim()) process.exit(0);\n\n// Spawn detached update:\nspawn('npx', ['agents-reverse-engineer@latest', 'update', '--quiet'], { \n  stdio: 'ignore', \n  detached: true, \n  windowsHide: true \n}).unref()\n```\n\n**Resource Management**:\n\nSubprocess environment variables (injected by `AIService`):\n```javascript\n{\n  NODE_OPTIONS: '--max-old-space-size=512',  // 512MB heap limit\n  UV_THREADPOOL_SIZE: '4',                   // 4-thread libuv pool\n  CLAUDE_CODE_DISABLE_BACKGROUND_TASKS: '1'  // Disable background spawning\n}\n```\n\nProcess group killing (negative PID for tree termination):\n```javascript\ntry {\n  process.kill(-child.pid, 'SIGTERM')  // Entire process group\n} catch (err) {\n  process.kill(child.pid, 'SIGKILL')   // Fallback single-process kill\n}\n```\n\nTimeout escalation:\n```javascript\n// SIGTERM at timeoutMs:\nconst killTimer = setTimeout(() => {\n  child.kill('SIGTERM')\n  \n  // SIGKILL after 5s grace:\n  setTimeout(() => {\n    if (!child.killed) process.kill(-child.pid, 'SIGKILL')\n  }, 5000)\n}, timeoutMs)\n\n// Cleanup on early exit:\nkillTimer.unref()\n```\n\n### 7.2 Implementation Contracts\n\n**GENERATED_MARKER constant**:\n```javascript\n'<!-- Generated by agents-reverse-engineer -->'\n```\n\n**Frontmatter extraction regex**:\n```javascript\n/^---\\n([\\s\\S]*?)\\n---\\n/\n```\n\n**YAML field parsing patterns**:\n```javascript\n/generated_at:\\s*(.+)/\n/content_hash:\\s*(.+)/\n/purpose:\\s*(.+)/\n/key:\\s*\\[([^\\]]*)\\]/                    // Inline arrays: key: [a, b, c]\n/key:\\s*\\n((?:\\s+-\\s+.+\\n?)+)/m          // Multi-line arrays: key:\\n  - item\n```\n\n**Array formatting heuristic**:\n```javascript\nfunction formatYamlArray(key: string, values: string[]): string {\n  if (values.length === 0) return `${key}: []`\n  if (values.length <= 3 && values.every(v => v.length < 40)) {\n    return `${key}: [${values.map(v => JSON.stringify(v)).join(', ')}]`\n  }\n  return `${key}:\\n${values.map(v => `  - ${v}`).join('\\n')}`\n}\n```\n\n**Export extraction regex**:\n```javascript\n/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm\n```\n\n**Path extraction patterns (phantom-paths)**:\n```javascript\n[\n  /\\[(?:[^\\]]*)\\]\\((\\.[^)]+)\\)/g,                        // Markdown links: [text](./path)\n  /`((?:src\\/|\\.\\.?\\/)[^`]+\\.[a-z]{1,4})`/g,             // Backtick paths: `src/foo.ts`\n  /(?:from|in|by|via|see)\\s+`?(src\\/[\\w\\-./]+)`?/gi     // Prose paths: \"from src/foo/\"\n]\n```\n\n**Rate limit detection patterns**:\n```javascript\n['rate limit', '429', 'too many requests', 'overloaded']\n```\n\n**Preamble stripping patterns**:\n\nPattern 1 (YAML separator):\n```javascript\nconst yamlSep = content.slice(0, 500).indexOf('\\n---\\n')\nif (yamlSep !== -1) return content.slice(yamlSep + 5)\n```\n\nPattern 2 (bold uppercase start):\n```javascript\nconst match = /^[\\s\\S]{0,500}?(\\*\\*[A-Z])/.exec(content)\nif (match && match.index < 300 && !content.slice(0, match.index).includes('##')) {\n  return content.slice(match.index)\n}\n```\n\n**Skip directories set**:\n```javascript\nnew Set([\n  'node_modules', '.git', '.agents-reverse-engineer', 'vendor',\n  'dist', 'build', '__pycache__', '.next', 'venv', '.venv',\n  'target', '.cargo', '.gradle'\n])\n```\n\n**Manifest detection list**:\n```javascript\n[\n  'package.json', 'Cargo.toml', 'go.mod', 'pyproject.toml',\n  'pom.xml', 'build.gradle', 'Gemfile', 'composer.json',\n  'CMakeLists.txt', 'Makefile'\n]\n```\n\n**Import regex pattern**:\n```javascript\n/^import\\s+(type\\s+)?(?:\\{([^}]*)\\}|(\\*\\s+as\\s+\\w+)|(\\w+))\\s+from\\s+['\"]([^'\"]+)['\"]/gm\n```\nCapture groups:\n1. `type` keyword\n2. Named imports `{ Foo, Bar }`\n3. Namespace imports `* as Name`\n4. Default import identifier\n5. Module specifier string\n\n**Git commands**:\n\nChange detection:\n```bash\ngit diff --name-status -M <baseCommit>..HEAD\n```\nFormat: `<status>\\t<path>[\\t<oldPath>]`\nStatus codes: `A` (added), `M` (modified), `D` (deleted), `R<similarity>` (renamed)\n\nUncommitted changes:\n```bash\ngit status --porcelain\n```\nMerge fields: `status.modified[]`, `status.deleted[]`, `status.not_added[]`, `status.staged[]`\n\n**SHA-256 hashing**:\n```javascript\ncrypto.createHash('sha256').update(content, 'utf-8').digest('hex')\n```\nOutput: lowercase hex string (64 characters)\n\n**Detached subprocess spawn pattern**:\n```javascript\nspawn(process.execPath, ['-e', scriptString], {\n  stdio: 'ignore',\n  detached: true,\n  windowsHide: true\n}).unref()\n```\n\n**Hook disable mechanisms**:\n- Environment: `process.env.ARE_DISABLE_HOOK === '1'`\n- Config substring: `readFileSync('.agents-reverse-engineer.yaml', 'utf-8').includes('hook_enabled: false')`\n\n**Trace filename format**:\n```javascript\n`trace-${new Date().toISOString().replace(/[:.]/g, '-')}.ndjson`\n```\nExample: `trace-2026-02-09T12-00-00-000Z.ndjson`\n\n**Run log filename format**:\n```javascript\n`run-${runLog.startTime.replace(/[:.]/g, '-')}.json`\n```\n\n**Exit code extraction (subprocess)**:\n```javascript\nerror === null ? 0\n: typeof error.code === 'number' ? error.code\n: child.exitCode !== null ? child.exitCode\n: 1\n```\n\n**Filename sanitization**:\n```javascript\ntimestamp.replace(/[:.]/g, '-')  // ISO 8601 → filesystem-safe\n```\n\n**Slugification chain** (for multi-file spec splitting):\n```javascript\nfunction slugify(text: string): string {\n  return text\n    .toLowerCase()\n    .replace(/\\s+/g, '-')                // Whitespace → hyphens\n    .replace(/[^a-z0-9-]/g, '')          // Strip non-alphanumeric except hyphens\n    .replace(/-+/g, '-')                 // Collapse consecutive hyphens\n    .replace(/^-|-$/g, '')               // Trim leading/trailing hyphens\n}\n```\n\n**Binary extensions set** (82 members):\n```javascript\nnew Set([\n  '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.webp', '.svg', '.tiff', '.tif',\n  '.psd', '.raw', '.heif', '.heic', '.zip', '.tar', '.gz', '.rar', '.7z', '.bz2',\n  '.xz', '.tgz', '.exe', '.dll', '.so', '.dylib', '.bin', '.msi', '.app', '.dmg',\n  '.mp3', '.mp4', '.wav', '.avi', '.mov', '.mkv', '.flac', '.ogg', '.webm', '.m4a',\n  '.aac', '.wma', '.wmv', '.flv', '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt',\n  '.pptx', '.odt', '.ods', '.odp', '.woff', '.woff2', '.ttf', '.eot', '.otf',\n  '.class', '.pyc', '.pyo', '.o', '.obj', '.a', '.lib', '.wasm', '.db', '.sqlite',\n  '.sqlite3', '.mdb', '.ico', '.icns', '.cur', '.deb', '.rpm', '.jar', '.war', '.ear'\n])\n```\n\n**Language extension map** (22 entries):\n```javascript\n{\n  '.ts': 'typescript', '.tsx': 'tsx', '.js': 'javascript', '.jsx': 'jsx',\n  '.py': 'python', '.rb': 'ruby', '.go': 'go', '.rs': 'rust',\n  '.java': 'java', '.kt': 'kotlin', '.swift': 'swift', '.cs': 'csharp',\n  '.php': 'php', '.vue': 'vue', '.svelte': 'svelte', '.json': 'json',\n  '.yaml': 'yaml', '.yml': 'yaml', '.md': 'markdown', '.css': 'css',\n  '.scss': 'scss', '.html': 'html'\n}\n// Default: 'text'\n```\n\n**Progress log format patterns**:\n\nHeader:\n```\n=== ARE Generate (2026-02-09T12:00:00.000Z) ===\nProject: /home/user/project\nFiles: 150 discovered (120 included, 30 excluded)\n```\n\nTask progress:\n```\n[15/150] ANALYZING src/cli/index.ts 2.3s 1234 in/out tok claude-sonnet-4.5 ~5m 30s\n[15/150] DONE src/cli/index.ts 2.3s 1234/567 tok claude-sonnet-4.5 ~5m 25s\n[15/150] FAIL src/cli/index.ts 2.3s Error: Timeout\n```\n\nETA calculation:\n```javascript\nconst completionTimes: number[] = []  // Sliding window, max 10 entries\ncompletionTimes.push(durationMs)\nif (completionTimes.length > 10) completionTimes.shift()\nconst avgMs = completionTimes.reduce((a, b) => a + b, 0) / completionTimes.length\nconst etaMs = avgMs * remaining\nreturn completionTimes.length >= 2 ? formatDuration(etaMs) : ''\n```\n\n**Task ID formats**:\n```javascript\n`file:${relativePath}`           // File task: file:src/cli/index.ts\n`dir:${relativePath}`            // Directory task: dir:src/cli\n`root:${filename}`               // Root task: root:CLAUDE.md\n```\n\n**Directory depth calculation**:\n```javascript\nfunction getDirectoryDepth(dir: string): number {\n  return dir.split(path.sep).length  // '.' → 0, 'src' → 1, 'src/cli' → 2\n}\n```\n\n**Post-order sort comparator** (descending depth):\n```javascript\n(taskA, taskB) => getDirectoryDepth(dirB) - getDirectoryDepth(dirA)\n```\n\n**Quality validator severity tags**:\n```javascript\nseverity === 'error' ? '[ERROR]'\n: severity === 'warning' ? '[WARN]'\n: '[INFO]'\n```\n\n**Checkbox markdown format** (for `GENERATION-PLAN.md`):\n```markdown\n- [ ] `src/cli/init.ts`          # Uncompleted file task\n- [x] `src/cli/init.ts`          # Completed file task\n- [ ] `src/cli/AGENTS.md`        # Uncompleted directory task\n- [ ] `CLAUDE.md`                # Uncompleted root task\n```\n\n---\n\n## 8. Test Contracts\n\n### 8.1 Discovery Module Tests\n\n**File Discovery** (`src/discovery/walker.ts`):\n- Should return absolute paths via `fast-glob` with `absolute: true`\n- Should exclude `.git` directory automatically\n- Should respect `followSymlinks` option for symlink traversal\n- Should handle empty directories without errors\n- Should respect `dot: true` for hidden file inclusion\n\n**Filter Chain** (`src/discovery/filters/index.ts`):\n- Should apply filters in order: Gitignore → Vendor → Binary → Custom\n- Should short-circuit on first exclusion match\n- Should attribute exclusions with `filter` and `reason` fields\n- Should maintain concurrency bound of 30 workers\n- Should preserve input order via sparse array indexing\n\n**Gitignore Filter** (`src/discovery/filters/gitignore.ts`):\n- Should parse `.gitignore` patterns via `ignore` library\n- Should normalize paths to relative before matching\n- Should pass all files when `.gitignore` missing\n- Should handle negation patterns (`!include.txt`)\n- Should bypass filtering for paths outside root (starts with `..`)\n\n**Binary Filter** (`src/discovery/filters/binary.ts`):\n- Should check extension Set before I/O operations\n- Should use size threshold (`stat().size > maxFileSize`) as second pass\n- Should call `isbinaryfile.isBinaryFile()` as final fallback\n- Should exclude files when `stat()` fails (unreadable/missing)\n- Should support additional extensions via `additionalExtensions` param\n\n**Vendor Filter** (`src/discovery/filters/vendor.ts`):\n- Should use Set lookup for single-segment patterns (`node_modules`)\n- Should use substring search for path patterns (`apps/vendor`)\n- Should normalize path separators (`/` → `path.sep`) before matching\n\n**Custom Filter** (`src/discovery/filters/custom.ts`):\n- Should parse user patterns via `ignore` library\n- Should convert absolute paths to relative before matching\n- Should bypass filtering for paths outside root\n\n### 8.2 Generation Module Tests\n\n**Orchestrator** (`src/generation/orchestrator.ts`):\n- Should execute seven-step pipeline: read files → complexity → structure → prompts → group → concatenate → clear content\n- Should call `buildFilePrompt()` for each discovered file\n- Should group files by `path.dirname()` for directory task creation\n- Should emit `phase:start`, `plan:created`, `phase:end` trace events\n- Should clear `PreparedFile.content` fields after prompt construction\n\n**Executor** (`src/generation/executor.ts`):\n- Should sort directory tasks by depth descending (deepest first)\n- Should wait for child `.sum` files via `isDirectoryComplete()` predicate\n- Should create tasks with dependency arrays (`fileTasks` have zero dependencies)\n- Should format execution plan markdown with three sections (Files/Directories/Root)\n\n**File Prompt Builder** (`src/generation/prompts/builder.ts`):\n- Should substitute placeholders: `{{FILE_PATH}}`, `{{CONTENT}}`, `{{LANG}}`, `{{PROJECT_PLAN_SECTION}}`\n- Should select `FILE_UPDATE_SYSTEM_PROMPT` when `existingSum` present\n- Should append `contextFiles` section when populated\n- Should detect language via extension lookup returning `'text'` default\n\n**Directory Prompt Builder** (`src/generation/prompts/builder.ts`):\n- Should read `.sum` files via `readSumFile()` with error handling\n- Should collect child `AGENTS.md` via recursive traversal\n- Should extract imports from source files matching `/\\.(ts|tsx|js|jsx|py|go|rs|java|kt)$/`\n- Should detect manifests from 9-type list\n- Should include user notes from `AGENTS.local.md` or non-generated `AGENTS.md`\n- Should return `DIRECTORY_UPDATE_SYSTEM_PROMPT` when `existingAgentsMd` present\n\n**Root Prompt Builder** (`src/generation/prompts/builder.ts`):\n- Should call `collectAgentsDocs()` for recursive tree walk\n- Should parse root `package.json` extracting name/version/description/packageManager/scripts\n- Should embed all `AGENTS.md` content as `### ${relativePath}` sections\n- Should include synthesis constraint forbidding invention\n\n**Sum File Writer** (`src/generation/writers/sum.ts`):\n- Should serialize frontmatter with adaptive array formatting\n- Should compute `content_hash` via SHA-256 hex digest\n- Should truncate `purpose` to 120 chars\n- Should write to `${sourcePath}.sum` colocated path\n\n**AGENTS.md Writer** (`src/generation/writers/agents-md.ts`):\n- Should detect user ownership via `GENERATED_MARKER` absence\n- Should rename user file to `AGENTS.local.md` with idempotent logic\n- Should prepend marker, optional user block with separator, then LLM content\n- Should strip marker prefix from incoming content\n\n### 8.3 AI Service Tests\n\n**Subprocess Runner** (`src/ai/subprocess.ts`):\n- Should spawn `execFile()` with stdin piping\n- Should send SIGTERM at `timeoutMs`, SIGKILL after 5s\n- Should kill process group via `kill(-pid)` with fallback to `kill(pid)`\n- Should track active subprocesses in Map with spawn timestamps\n- Should populate `SubprocessResult` with stdout/stderr/exitCode/signal/durationMs/timedOut/childPid\n\n**Retry Logic** (`src/ai/retry.ts`):\n- Should execute exponential backoff: `min(1000 * 2^attempt, 60000) + random(0..500)`\n- Should call `isRetryable()` predicate before each retry\n- Should invoke `onRetry()` callback before delay\n- Should throw last error after exhausting retries\n\n**Rate Limit Detection**:\n- Should detect patterns: `['rate limit', '429', 'too many requests', 'overloaded']`\n- Should perform case-insensitive substring search in stderr\n- Should return `true` on first match\n\n**AIService Call Flow** (`src/ai/service.ts`):\n- Should wrap `runSubprocess()` in `withRetry()`\n- Should only retry on `RATE_LIMIT` errors, skip on `TIMEOUT`\n- Should emit `subprocess:spawn`, `subprocess:exit`, `retry` trace events\n- Should accumulate `TelemetryEntry` records with token counts\n- Should call `backend.parseResponse()` after subprocess completion\n\n**Backend Adapter Interface**:\n- `isAvailable()` should delegate to `isCommandOnPath()`\n- `buildArgs()` should return CLI argument array (prompt via stdin)\n- `parseResponse()` should normalize to `AIResponse` structure\n- `getInstallInstructions()` should return multiline help text\n\n**ClaudeBackend** (`src/ai/backends/claude.ts`):\n- Should build args: `['-p', '--output-format', 'json', '--no-session-persistence', '--permission-mode', 'bypassPermissions']` + conditionals\n- Should parse JSON via `ClaudeResponseSchema.parse()`\n- Should extract `usage.input_tokens`, `cache_read_input_tokens`, etc.\n- Should throw `PARSE_ERROR` when JSON missing (no `{` in stdout)\n\n### 8.4 Orchestration Module Tests\n\n**Worker Pool** (`src/orchestration/pool.ts`):\n- Should share single `tasks.entries()` iterator across N workers\n- Should return sparse `TaskResult<T>[]` array indexed by original position\n- Should emit `worker:start`, `worker:end`, `task:pickup`, `task:done` events\n- Should set `aborted` flag on first error when `failFast: true`\n- Should check `aborted` before task pickup, not interrupt running tasks\n\n**Progress Reporter** (`src/orchestration/progress.ts`):\n- Should calculate ETA via moving average of last 10 completion times\n- Should maintain separate sliding windows for files and directories\n- Should format ETA as `~Ns` or `~Mm Ss` when ≥2 completions\n- Should emit colored output: cyan `ANALYZING`, green `DONE`, red `FAIL`, blue `DONE` for dirs/roots\n\n**Progress Log** (`src/orchestration/progress.ts`):\n- Should strip ANSI codes via `/\\x1b\\[[0-9;]*m/g`\n- Should serialize writes via promise-chain pattern\n- Should open file handle lazily in truncate mode ('w')\n- Should close handle on `finalize()`\n\n**Plan Tracker** (`src/orchestration/plan-tracker.ts`):\n- Should serialize concurrent checkbox updates via promise-chain\n- Should match exact backtick-wrapped paths (`` `src/cli/init.ts` ``)\n- Should replace `- [ ]` with `- [x]` via string substitution\n- Should swallow write errors (non-critical operation)\n\n**Trace Writer** (`src/orchestration/trace.ts`):\n- Should auto-populate `seq`, `ts`, `pid`, `elapsedMs` base fields\n- Should serialize NDJSON writes via promise-chain\n- Should open file handle lazily via `fs.open(path, 'a')`\n- Should cleanup old traces keeping 500 most recent via lexicographic sort\n\n**Command Runner Phase 1** (`src/orchestration/runner.ts`):\n- Should pre-cache existing `.sum` files at concurrency=20\n- Should compute `contentHash` via `computeContentHashFromString()`\n- Should call `writeSumFile()` after `AIService.call()`\n- Should extract purpose from first non-preamble line, 120 char truncation\n- Should run throttled (concurrency=10) `checkCodeVsDoc()` on old vs. new `.sum`\n\n**Command Runner Phase 2** (`src/orchestration/runner.ts`):\n- Should group `directoryTasks` by `metadata.depth` into `Map<number, ExecutionTask[]>`\n- Should sort depth levels descending (deepest first)\n- Should call `buildDirectoryPrompt()` with `knownDirs` set\n- Should call `writeAgentsMd()` prepending `AGENTS.local.md` if present\n- Should run `checkPhantomPaths()` on each generated `AGENTS.md`\n\n**Command Runner Phase 3** (`src/orchestration/runner.ts`):\n- Should execute sequentially (concurrency=1) over `plan.rootTasks`\n- Should call `buildRootPrompt()` with all `AGENTS.md` injected\n- Should strip preamble via two regex patterns\n- Should flush `planTracker.flush()` after loop\n\n### 8.5 Update Module Tests\n\n**Update Orchestrator** (`src/update/orchestrator.ts`):\n- Should call `isGitRepo()`, `getCurrentCommit()` before discovery\n- Should read `.sum` frontmatter via `readSumFile()` extracting `contentHash`\n- Should compute current hash via `computeContentHash()`\n- Should classify files: hash match → `filesToSkip`, mismatch/missing → `filesToAnalyze`\n- Should sort `affectedDirs` by depth descending\n- Should detect first run when no `.sum` files exist\n\n**Orphan Cleaner** (`src/update/orphan-cleaner.ts`):\n- Should delete `.sum` for `status === 'deleted'` using `change.path`\n- Should delete `.sum` for `status === 'renamed'` using `change.oldPath`\n- Should remove `AGENTS.md` from empty directories (only hidden files, `.sum`, or `GENERATED_FILES`)\n- Should walk parent directories via `path.dirname()` until root\n- Should skip orphan cleanup in dry-run mode\n\n**Change Detection** (`src/change-detection/detector.ts`):\n- Should parse `git diff --name-status -M` with rename detection (50% similarity)\n- Should merge uncommitted via `status.modified[]`, `status.deleted[]`, `status.not_added[]`, `status.staged[]`\n- Should compute SHA-256 via `crypto.createHash('sha256').update().digest('hex')`\n- Should map status codes: `A` → `'added'`, `M` → `'modified'`, `D` → `'deleted'`, `R*` → `'renamed'`\n\n### 8.6 Quality Module Tests\n\n**Code-vs-Doc Validator** (`src/quality/inconsistency/code-vs-doc.ts`):\n- Should extract exports via `/^[ \\t]*export\\s+(?:default\\s+)?(?:function|class|const|let|var|type|interface|enum)\\s+(\\w+)/gm`\n- Should verify exports appear in `.sum` summary via substring search\n- Should return `CodeDocInconsistency` with `missingFromDoc[]` when drift detected\n- Should return `null` when all exports present\n\n**Code-vs-Code Validator** (`src/quality/inconsistency/code-vs-code.ts`):\n- Should aggregate exports into `Map<symbol, paths[]>`\n- Should filter entries where `paths.length > 1`\n- Should return `CodeCodeInconsistency[]` with `severity: 'warning'`\n\n**Phantom Path Validator** (`src/quality/phantom-paths/validator.ts`):\n- Should extract paths via three regex patterns (markdown, backtick, prose)\n- Should skip patterns: `node_modules`, `.git/`, `https?:`, `{{`, `${`, `*`, `{a,b,c}`\n- Should resolve against `agentsMdDir` then `projectRoot`\n- Should substitute `.js` → `.ts` for import convention fallback\n- Should return `PhantomPathInconsistency[]` with 120-char context excerpt\n\n**Inconsistency Reporter** (`src/quality/inconsistency/reporter.ts`):\n- Should aggregate issues into `InconsistencyReport` with metadata\n- Should compute summary counts by type and severity\n- Should format CLI output with severity tags (`[ERROR]`, `[WARN]`, `[INFO]`)\n\n### 8.7 Configuration Tests\n\n**Config Loader** (`src/config/loader.ts`):\n- Should return defaults via `ConfigSchema.parse({})` when file missing\n- Should throw `ConfigError` on Zod validation failure with formatted errors\n- Should throw `ConfigError` on YAML parse errors\n- Should emit `config:loaded` trace event with model/concurrency\n\n**Config Writer** (`src/config/loader.ts`):\n- Should quote strings matching `/[*{}\\[\\]?,:#&!|>'\"%@`]/`\n- Should escape backslashes (`\\\\` → `\\\\\\\\`) and quotes (`\"` → `\\\"`)\n- Should generate commented YAML with inline defaults\n\n**Adaptive Concurrency** (`src/config/defaults.ts`):\n- Should compute `cores * 5` baseline via `os.availableParallelism()`\n- Should cap at `floor((totalMemGB * 0.5) / 0.512)` memory limit\n- Should clamp result to `[2, 20]` interval\n- Should return `Infinity` when `totalMemGB <= 1` for edge case bypass\n\n### 8.8 Installer Tests\n\n**Path Resolution** (`src/installer/paths.ts`):\n- Should respect `CLAUDE_CONFIG_DIR` environment override\n- Should respect `OPENCODE_CONFIG_DIR` → `XDG_CONFIG_HOME/opencode` fallback chain\n- Should respect `GEMINI_CONFIG_DIR` override\n- Should return `global`/`local`/`settingsFile` paths\n\n**Operations** (`src/installer/operations.ts`):\n- Should write command templates from `getTemplatesForRuntime()`\n- Should copy hooks from `hooks/dist/` via `readBundledHook()`\n- Should register hooks in `settings.json` merging into event arrays\n- Should add ARE Bash permission patterns for Claude only\n- Should write `ARE-VERSION` file\n\n**Uninstaller** (`src/installer/uninstall.ts`):\n- Should remove command templates, hooks, `ARE-VERSION`\n- Should filter hook registrations matching current and legacy patterns\n- Should clean up empty skill directories (`are-*`)\n- Should delete legacy Gemini files (`*.md`, `are/*.toml`)\n- Should recursively delete empty parents stopping at runtime roots\n\n**Interactive Prompts** (`src/installer/prompts.ts`):\n- Should use arrow-key selection in TTY mode with raw mode cleanup\n- Should use numbered fallback in non-TTY mode\n- Should register exit handlers for `'exit'` and `'SIGINT'` events\n\n---\n\n## 9. Build Plan\n\n### Phase 1: Core Infrastructure (Foundation)\n**Dependencies**: None  \n**Enables**: All subsequent phases\n\n1. **Configuration Management**\n   - Implement `src/config/schema.ts` with Zod schemas\n   - Implement `src/config/loader.ts` with YAML parsing and validation\n   - Implement `src/config/defaults.ts` with adaptive concurrency calculation\n   - Test: Config loading, validation errors, default generation\n\n2. **Type System**\n   - Define `src/types/index.ts` with shared interfaces\n   - Define `src/ai/types.ts` for AI service abstractions\n   - Define `src/orchestration/types.ts` for execution coordination\n   - Test: TypeScript compilation, type inference\n\n3. **Output Layer**\n   - Implement `src/output/logger.ts` with picocolors integration\n   - Test: Color rendering, silent mode, output routing\n\n4. **Trace System**\n   - Implement `src/orchestration/trace.ts` with NDJSON serialization\n   - Implement promise-chain write serialization\n   - Test: Event emission order, file rotation, cleanup\n\n### Phase 2: Discovery Pipeline (File Scanning)\n**Dependencies**: Phase 1 (config, types, output)  \n**Enables**: Phase 3 (generation), Phase 5 (updates)\n\n1. **Walker Implementation**\n   - Implement `src/discovery/walker.ts` with fast-glob integration\n   - Test: Absolute path output, dotfile handling, symlink control\n\n2. **Filter Chain**\n   - Implement `src/discovery/filters/index.ts` orchestrator\n   - Implement `src/discovery/filters/gitignore.ts`\n   - Implement `src/discovery/filters/vendor.ts`\n   - Implement `src/discovery/filters/binary.ts`\n   - Implement `src/discovery/filters/custom.ts`\n   - Test: Filter order, short-circuit evaluation, attribution\n\n3. **Discovery Facade**\n   - Implement `src/discovery/run.ts` with filter chain assembly\n   - Test: End-to-end discovery with various config combinations\n\n### Phase 3: AI Service Layer (Subprocess Management)\n**Dependencies**: Phase 1 (config, types), Phase 2 (for integration testing)  \n**Enables**: Phase 4 (generation orchestration)\n\n1. **Subprocess Runner**\n   - Implement `src/ai/subprocess.ts` with execFile integration\n   - Implement resource limits (heap, threads, task blocking)\n   - Implement process group killing\n   - Implement timeout enforcement (SIGTERM → SIGKILL)\n   - Test: Timeout scenarios, signal handling, active process tracking\n\n2. **Retry Logic**\n   - Implement `src/ai/retry.ts` with exponential backoff\n   - Test: Retry predicate, backoff calculation, max retries\n\n3. **Backend Adapters**\n   - Implement `src/ai/backends/claude.ts` with Zod response parsing\n   - Implement `src/ai/backends/gemini.ts` stub\n   - Implement `src/ai/backends/opencode.ts` stub\n   - Implement `src/ai/backends/index.ts` with PATH detection\n   - Test: Command argument construction, JSON parsing, availability checks\n\n4. **Backend Registry**\n   - Implement `src/ai/registry.ts` with auto-detection\n   - Test: Registry population, backend resolution, fallback order\n\n5. **Telemetry System**\n   - Implement `src/ai/telemetry/logger.ts` with in-memory accumulation\n   - Implement `src/ai/telemetry/run-log.ts` with JSON serialization\n   - Implement `src/ai/telemetry/cleanup.ts` with retention enforcement\n   - Test: Summary computation, file sanitization, rotation\n\n6. **AI Service Facade**\n   - Implement `src/ai/service.ts` orchestrating retry + subprocess + telemetry\n   - Test: Call flow, error propagation, trace emission\n\n### Phase 4: Generation Pipeline (Documentation Creation)\n**Dependencies**: Phase 2 (discovery), Phase 3 (AI service)  \n**Enables**: Phase 6 (CLI commands)\n\n1. **Import Analysis**\n   - Implement `src/imports/extractor.ts` with regex-based parsing\n   - Implement `src/imports/types.ts` with internal/external partitioning\n   - Test: Import extraction, line limit optimization, bare specifier filtering\n\n2. **Prompt Engineering**\n   - Implement `src/generation/prompts/templates.ts` with constraint definitions\n   - Implement `src/generation/prompts/builder.ts` with placeholder substitution\n   - Implement `src/generation/prompts/types.ts`\n   - Test: File/directory/root prompt construction, context injection\n\n3. **File Writers**\n   - Implement `src/generation/writers/sum.ts` with YAML frontmatter serialization\n   - Implement `src/generation/writers/agents-md.ts` with user content preservation\n   - Test: Adaptive array formatting, marker detection, rename idempotency\n\n4. **Complexity Analysis**\n   - Implement `src/generation/complexity.ts` with depth calculation\n   - Test: Metric computation, directory enumeration\n\n5. **Document Collectors**\n   - Implement `src/generation/collector.ts` with recursive AGENTS.md traversal\n   - Test: Skip directory filtering, sort order, error handling\n\n6. **Orchestrator**\n   - Implement `src/generation/orchestrator.ts` with seven-step pipeline\n   - Test: Plan creation, memory clearing, trace emission\n\n7. **Executor**\n   - Implement `src/generation/executor.ts` with dependency graph construction\n   - Test: Post-order sort, completion predicate, markdown formatting\n\n### Phase 5: Incremental Updates (Change Detection)\n**Dependencies**: Phase 2 (discovery), Phase 4 (writers)  \n**Enables**: Phase 6 (CLI update command)\n\n1. **Change Detection**\n   - Implement `src/change-detection/detector.ts` with git integration\n   - Implement SHA-256 hashing\n   - Test: Diff parsing, rename detection, uncommitted merge\n\n2. **Orphan Cleanup**\n   - Implement `src/update/orphan-cleaner.ts` with .sum deletion\n   - Implement empty directory detection\n   - Test: Delete targeting, AGENTS.md removal, dry-run mode\n\n3. **Update Orchestrator**\n   - Implement `src/update/orchestrator.ts` with hash comparison\n   - Implement affected directory computation\n   - Test: Plan preparation, first-run detection, depth sorting\n\n### Phase 6: Orchestration Layer (Execution Coordination)\n**Dependencies**: Phase 4 (generation), Phase 5 (updates)  \n**Enables**: Phase 7 (CLI)\n\n1. **Worker Pool**\n   - Implement `src/orchestration/pool.ts` with shared-iterator pattern\n   - Test: Task distribution, fail-fast abort, result indexing\n\n2. **Progress Reporting**\n   - Implement `src/orchestration/progress.ts` with ETA calculation\n   - Implement ANSI stripping for log file\n   - Test: Moving average, color rendering, promise-chain serialization\n\n3. **Plan Tracking**\n   - Implement `src/orchestration/plan-tracker.ts` with checkbox updates\n   - Test: Markdown substitution, promise-chain serialization\n\n4. **Command Runner**\n   - Implement `src/orchestration/runner.ts` with three-phase execution\n   - Test: Phase orchestration, quality validation integration, summary building\n\n### Phase 7: Quality Validation (Consistency Checks)\n**Dependencies**: Phase 4 (generation for .sum reading)  \n**Enables**: Phase 6 (runner integration)\n\n1. **Code-vs-Doc Validator**\n   - Implement `src/quality/inconsistency/code-vs-doc.ts` with export extraction\n   - Test: Regex matching, substring verification, drift detection\n\n2. **Code-vs-Code Validator**\n   - Implement `src/quality/inconsistency/code-vs-code.ts` with duplicate aggregation\n   - Test: Symbol deduplication, multi-file matching\n\n3. **Phantom Path Validator**\n   - Implement `src/quality/phantom-paths/validator.ts` with three regex patterns\n   - Test: Path extraction, resolution fallbacks, context excerpts\n\n4. **Inconsistency Reporter**\n   - Implement `src/quality/inconsistency/reporter.ts` with aggregation\n   - Test: Summary computation, CLI formatting, severity tags\n\n5. **Density Validator (Stub)**\n   - Implement `src/quality/density/validator.ts` disabled stub\n   - Document restoration path in comments\n\n### Phase 8: Specification Synthesis (AI-Driven Specs)\n**Dependencies**: Phase 3 (AI service), Phase 4 (collector)  \n**Enables**: Phase 9 (CLI specify command)\n\n1. **Spec Prompts**\n   - Implement `src/specify/prompts.ts` with nine-section structure\n   - Test: Section enforcement, behavioral contract preservation\n\n2. **Spec Writer**\n   - Implement `src/specify/writer.ts` with heading-based splitting\n   - Test: Single-file output, multi-file split, slugification, overwrite protection\n\n### Phase 9: CLI Layer (User Interface)\n**Dependencies**: Phase 6 (orchestration), Phase 7 (quality), Phase 8 (specify)  \n**Enables**: End-user interaction\n\n1. **Command Implementations**\n   - Implement `src/cli/init.ts` with config writer\n   - Implement `src/cli/discover.ts` with plan preview\n   - Implement `src/cli/generate.ts` with three-phase orchestration\n   - Implement `src/cli/update.ts` with incremental workflow\n   - Implement `src/cli/clean.ts` with artifact deletion\n   - Implement `src/cli/specify.ts` with auto-generation fallback\n   - Test: Each command's end-to-end flow, error handling, exit codes\n\n2. **Argument Parser**\n   - Implement `src/cli/index.ts` with dual routing (installer vs. command)\n   - Test: Flag parsing, short flag expansion, positional arguments\n\n3. **Version Utility**\n   - Implement `src/version.ts` with package.json reading\n   - Test: Version extraction, fallback to 'unknown'\n\n### Phase 10: IDE Integration (AI Assistant Setup)\n**Dependencies**: Phase 9 (CLI for installation target)  \n**Enables**: Session lifecycle hooks\n\n1. **Environment Detection**\n   - Implement `src/integration/detect.ts` with filesystem marker scanning\n   - Test: Multi-runtime detection, environment type classification\n\n2. **Template Generation**\n   - Implement `src/integration/templates.ts` with placeholder substitution\n   - Test: Command file construction, platform-specific formatting (YAML/TOML)\n\n3. **File Generation**\n   - Implement `src/integration/generate.ts` with template writing\n   - Test: Directory creation, hook copying, dry-run mode\n\n4. **Interactive Prompts**\n   - Implement `src/installer/prompts.ts` with TTY detection\n   - Test: Arrow-key selection, numbered fallback, raw mode cleanup\n\n5. **Path Resolution**\n   - Implement `src/installer/paths.ts` with environment overrides\n   - Test: Runtime-specific paths, existence checks\n\n6. **Installation Operations**\n   - Implement `src/installer/operations.ts` with hook registration\n   - Test: Command writing, settings.json merging, permission registration\n\n7. **Uninstallation**\n   - Implement `src/installer/uninstall.ts` with cleanup\n   - Test: File removal, hook deregistration, empty directory deletion\n\n8. **Banner Display**\n   - Implement `src/installer/banner.ts` with ASCII art\n   - Test: Help text formatting, next steps display\n\n9. **Installer Entry Point**\n   - Implement `src/installer/index.ts` with argument parsing\n   - Test: Runtime selection, location determination, result display\n\n### Phase 11: Session Lifecycle Hooks (Auto-Update)\n**Dependencies**: Phase 10 (installer for deployment)  \n**Enables**: Automatic documentation synchronization\n\n1. **Claude/Gemini Hooks**\n   - Implement `hooks/are-check-update.js` with npm version check\n   - Implement `hooks/are-session-end.js` with git status detection\n   - Test: Detached spawn, version cache, disable mechanisms\n\n2. **OpenCode Plugins**\n   - Implement `hooks/opencode-are-check-update.js` with factory pattern\n   - Implement `hooks/opencode-are-session-end.js` with event handlers\n   - Test: Plugin exports, session lifecycle integration\n\n3. **Hook Build Script**\n   - Implement `scripts/build-hooks.js` with file copying\n   - Test: Distribution directory creation, .js file filtering\n\n### Phase 12: Build & Distribution (Package Preparation)\n**Dependencies**: All phases (complete codebase)  \n**Enables**: npm publication\n\n1. **TypeScript Configuration**\n   - Configure `tsconfig.json` with ES2022 target, NodeNext resolution\n   - Test: Compilation, source maps, declaration generation\n\n2. **Package Metadata**\n   - Configure `package.json` with dual binaries, dependencies, scripts\n   - Test: Binary resolution, module type, npm tarball contents\n\n3. **CI/CD Pipeline**\n   - Configure `.github/workflows/publish.yml` with provenance attestation\n   - Test: Workflow execution, npm publish with Sigstore signature\n\n4. **Documentation**\n   - Write `README.md` with CLI reference and workflow examples\n   - Write `LICENSE` with MIT terms\n   - Write `LANGUAGES-MANIFEST.md` with ecosystem coverage table\n   - Test: Link validation, example accuracy\n\n### Phase 13: Testing & Quality Assurance (Validation)\n**Dependencies**: Phases 1-12 (all implementation)  \n**Enables**: Production readiness\n\n1. **Unit Tests**\n   - Write tests for each module per contracts in Section 8\n   - Achieve >80% code coverage\n   - Test: All behavioral contracts, error paths, edge cases\n\n2. **Integration Tests**\n   - Test end-to-end generate workflow with fixture project\n   - Test incremental update workflow with git repository\n   - Test installer with mock filesystem\n   - Test quality validators with synthetic codebases\n\n3. **Performance Tests**\n   - Benchmark worker pool with varying concurrency\n   - Benchmark discovery with large codebases (>10K files)\n   - Benchmark SHA-256 hashing with large files\n\n4. **Compatibility Tests**\n   - Test on Node.js 18, 20, 22\n   - Test on Windows, macOS, Linux\n   - Test with all AI backends (Claude Code, Gemini stub, OpenCode stub)\n\n**Milestone**: Production-ready package with comprehensive test coverage",
      "model": "claude-sonnet-4-5-20250929",
      "inputTokens": 3,
      "outputTokens": 23137,
      "cacheReadTokens": 0,
      "cacheCreationTokens": 78142,
      "latencyMs": 446988,
      "exitCode": 0,
      "retryCount": 0,
      "thinking": "not supported",
      "filesRead": []
    }
  ],
  "summary": {
    "totalCalls": 1,
    "totalInputTokens": 3,
    "totalOutputTokens": 23137,
    "totalCacheReadTokens": 0,
    "totalCacheCreationTokens": 78142,
    "totalDurationMs": 446988,
    "errorCount": 0,
    "totalFilesRead": 0,
    "uniqueFilesRead": 0
  }
}