---
phase: 06-ai-service-foundation
plan: 03
type: execute
wave: 3
depends_on: ["06-01", "06-02"]
files_modified:
  - src/ai/telemetry/logger.ts
  - src/ai/telemetry/run-log.ts
  - src/ai/telemetry/cleanup.ts
  - src/ai/service.ts
  - src/ai/index.ts
  - src/config/schema.ts
autonomous: true

must_haves:
  truths:
    - "Each AI call produces a TelemetryEntry in memory with prompt, response, tokens, latency, and exit code"
    - "When a run finishes, all entries are written to a single JSON file in .agents-reverse-engineer/logs/"
    - "Old telemetry log files are automatically cleaned up, keeping only the N most recent"
    - "The AIService orchestrates backend selection, subprocess spawning, retry, and telemetry in a single call() method"
    - "The config schema includes an ai section with backend, model, timeoutMs, maxRetries, and telemetry.keepRuns"
    - "The src/ai/index.ts barrel export provides the public API for the AI service layer"
  artifacts:
    - path: "src/ai/telemetry/logger.ts"
      provides: "TelemetryLogger class that accumulates per-call entries"
      exports: ["TelemetryLogger"]
    - path: "src/ai/telemetry/run-log.ts"
      provides: "RunLogWriter that writes the completed run log to disk"
      exports: ["writeRunLog"]
    - path: "src/ai/telemetry/cleanup.ts"
      provides: "Log cleanup utility that removes old run files"
      exports: ["cleanupOldLogs"]
    - path: "src/ai/service.ts"
      provides: "AIService class orchestrating call + retry + telemetry"
      exports: ["AIService"]
    - path: "src/ai/index.ts"
      provides: "Public API barrel exports"
      exports: ["AIService", "AIResponse", "AICallOptions", "AIBackend", "AIServiceError", "createBackendRegistry", "resolveBackend"]
    - path: "src/config/schema.ts"
      provides: "Extended config schema with ai section"
      contains: "AISchema"
  key_links:
    - from: "src/ai/service.ts"
      to: "src/ai/subprocess.ts"
      via: "calls runSubprocess to spawn CLI"
      pattern: "runSubprocess"
    - from: "src/ai/service.ts"
      to: "src/ai/retry.ts"
      via: "wraps call in withRetry"
      pattern: "withRetry"
    - from: "src/ai/service.ts"
      to: "src/ai/telemetry/logger.ts"
      via: "records each call result as TelemetryEntry"
      pattern: "TelemetryLogger"
    - from: "src/ai/service.ts"
      to: "src/ai/registry.ts"
      via: "uses resolved backend for CLI invocation"
      pattern: "AIBackend"
    - from: "src/config/schema.ts"
      to: "zod"
      via: "AISchema Zod definition"
      pattern: "AISchema"
---

<objective>
Build the telemetry subsystem, the AIService orchestrator, config schema extension, and the public API barrel export.

Purpose: The AIService is the main entry point for making AI calls. It ties together the subprocess wrapper, retry logic, backend selection, and telemetry logging into a clean `call()` method. The telemetry subsystem ensures every call is logged for debugging. The config extension allows users to configure AI backend, model, timeout, retries, and telemetry retention.

Output: The complete AI service layer ready to be wired into commands in Phase 7.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ai-service-foundation/06-RESEARCH.md
@.planning/phases/06-ai-service-foundation/06-CONTEXT.md
@.planning/phases/06-ai-service-foundation/06-01-SUMMARY.md
@.planning/phases/06-ai-service-foundation/06-02-SUMMARY.md
@src/ai/types.ts
@src/ai/subprocess.ts
@src/ai/retry.ts
@src/ai/registry.ts
@src/ai/backends/claude.ts
@src/config/schema.ts
@src/config/defaults.ts
@src/config/loader.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build telemetry subsystem</name>
  <files>src/ai/telemetry/logger.ts, src/ai/telemetry/run-log.ts, src/ai/telemetry/cleanup.ts</files>
  <action>
Create the three telemetry files that handle per-call logging, run-level file writing, and cleanup.

**src/ai/telemetry/logger.ts -- TelemetryLogger class:**
- Constructor takes `runId: string` (generated from start time)
- `startTime: string` set to `new Date().toISOString()` in constructor
- `private entries: TelemetryEntry[]` accumulates entries in memory
- `addEntry(entry: TelemetryEntry): void` -- push entry to array
- `getEntries(): readonly TelemetryEntry[]` -- return entries
- `getSummary(): RunLog['summary']` -- compute totals from entries (totalCalls, totalInputTokens, totalOutputTokens, totalCostUsd, totalDurationMs, errorCount)
- `toRunLog(): RunLog` -- assemble the complete RunLog object with runId, startTime, endTime (current time), entries, and computed summary

**src/ai/telemetry/run-log.ts -- writeRunLog function:**
- `writeRunLog(projectRoot: string, runLog: RunLog): Promise<string>` -- returns the file path written
- Create `.agents-reverse-engineer/logs/` directory if it does not exist (use `mkdir` with `{ recursive: true }`)
- Filename convention: `run-YYYY-MM-DDTHH-MM-SS-mmmZ.json` (replace `:` and `.` with `-` in the ISO timestamp from `runLog.startTime`)
- Write pretty-printed JSON (`JSON.stringify(runLog, null, 2)`)
- Return the absolute file path

**src/ai/telemetry/cleanup.ts -- cleanupOldLogs function:**
- `cleanupOldLogs(projectRoot: string, keepCount: number): Promise<number>` -- returns count of deleted files
- Read the logs directory, filter for files matching `run-*.json`
- Sort lexicographically (ISO timestamps sort correctly), reverse (newest first)
- Delete all files beyond `keepCount`
- If directory doesn't exist, return 0 (not an error)

All functions use `node:fs/promises` and `node:path`. Follow existing project patterns for error handling.
  </action>
  <verify>Run `npx tsc --noEmit`. Verify TelemetryLogger correctly accumulates entries and computes summary totals.</verify>
  <done>TelemetryLogger accumulates entries in memory, computes summary totals, and produces a complete RunLog. writeRunLog writes pretty-printed JSON to the logs directory. cleanupOldLogs removes old files while keeping the N most recent.</done>
</task>

<task type="auto">
  <name>Task 2: Build AIService orchestrator and extend config schema</name>
  <files>src/ai/service.ts, src/config/schema.ts</files>
  <action>
Create the AIService class and extend the config schema with AI settings.

**src/ai/service.ts -- AIService class:**

Constructor takes: `backend: AIBackend`, `options: { timeoutMs: number; maxRetries: number; telemetry: { keepRuns: number } }`

Internal state:
- `private logger: TelemetryLogger` -- created in constructor with ISO timestamp runId
- `private callCount: number = 0`

Methods:

1. `async call(options: AICallOptions): Promise<AIResponse>` -- the main entry point:
   - Build CLI args via `this.backend.buildArgs(options)`
   - Determine timeout: `options.timeoutMs ?? this.options.timeoutMs`
   - Wrap the subprocess call in `withRetry`:
     - Inner function: call `runSubprocess(this.backend.cliCommand, args, { timeoutMs, input: options.prompt })`
     - If result.timedOut: throw `new AIServiceError('Subprocess timed out', 'TIMEOUT')`
     - If result.exitCode !== 0: check if retryable (rate limit patterns in stderr: "rate limit", "429", "too many requests", "overloaded"). If retryable, throw `AIServiceError` with code `'RATE_LIMIT'`. If not retryable, throw with `'SUBPROCESS_ERROR'`.
     - If exit code 0: parse response via `this.backend.parseResponse(result.stdout, result.durationMs, result.exitCode)` -- wrap in try/catch, throw `AIServiceError` with `'PARSE_ERROR'` on failure
     - Return parsed AIResponse
   - Retry options: use `DEFAULT_RETRY_OPTIONS` merged with `{ maxRetries: this.options.maxRetries, isRetryable, onRetry }`
   - `isRetryable`: check if error is AIServiceError with code `'RATE_LIMIT'` or `'TIMEOUT'`
   - `onRetry`: no-op by default (verbosity is handled by the caller in Phase 7)
   - After the call (success or final failure): record a TelemetryEntry via `this.logger.addEntry()`
   - For successful calls: entry has response text, tokens, cost, etc.
   - For failed calls: entry has error message, zero tokens, actual latency

2. `async finalize(projectRoot: string): Promise<{ logPath: string; summary: RunLog['summary'] }>`:
   - Build the RunLog via `this.logger.toRunLog()`
   - Write to disk via `writeRunLog(projectRoot, runLog)`
   - Cleanup old logs via `cleanupOldLogs(projectRoot, this.options.telemetry.keepRuns)`
   - Return `{ logPath, summary }`

3. `getSummary(): RunLog['summary']` -- get current summary without finalizing (for progress display)

**src/config/schema.ts -- extend ConfigSchema:**

Add an `AISchema` before the main `ConfigSchema`:
```typescript
const AISchema = z.object({
  backend: z.enum(['claude', 'gemini', 'opencode', 'auto']).default('auto'),
  model: z.string().default('sonnet'),
  timeoutMs: z.number().positive().default(120_000),
  maxRetries: z.number().min(0).default(3),
  telemetry: z.object({
    keepRuns: z.number().min(0).default(10),
  }).default({}),
}).default({});
```

Add `ai: AISchema` to the ConfigSchema object. Export `AIConfig` type. This is a non-breaking change -- the `.default({})` ensures existing configs without an `ai` section still parse correctly.
  </action>
  <verify>Run `npx tsc --noEmit`. Verify the AIService call() method handles success, timeout, rate limit retry, parse error, and permanent failure paths. Verify ConfigSchema still parses `{}` correctly (backward compatible).</verify>
  <done>AIService.call() orchestrates subprocess spawning with retry and telemetry logging. AIService.finalize() writes the run log to disk and cleans up old files. Config schema includes ai section with all settings and backward-compatible defaults.</done>
</task>

<task type="auto">
  <name>Task 3: Create barrel export and verify full compilation</name>
  <files>src/ai/index.ts</files>
  <action>
Create `src/ai/index.ts` as the public API barrel export for the AI service layer.

Export the following (re-export from internal modules):

From `./types.js`:
- `AIBackend`, `AIResponse`, `AICallOptions`, `SubprocessResult`, `RetryOptions`, `TelemetryEntry`, `RunLog`, `AIServiceError`

From `./service.js`:
- `AIService`

From `./registry.js`:
- `BackendRegistry`, `createBackendRegistry`, `resolveBackend`, `detectBackend`, `getInstallInstructions`

From `./retry.js`:
- `withRetry`, `DEFAULT_RETRY_OPTIONS`

From `./subprocess.js`:
- `runSubprocess`

From `./backends/claude.js`:
- `isCommandOnPath` (utility for other consumers)

This barrel export is the ONLY import point for the AI service layer. No other module should reach into `src/ai/backends/` or `src/ai/telemetry/` directly.

After creating the file, run `npx tsc --noEmit` to verify the ENTIRE `src/ai/` module compiles cleanly. Fix any compilation errors.
  </action>
  <verify>Run `npx tsc --noEmit` -- must pass with zero errors. Run `npx tsc` to build the full project and verify no regressions in existing modules.</verify>
  <done>The `src/ai/index.ts` barrel export provides the public API. The full project compiles with zero errors. No regressions in existing modules.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors across the entire project
2. `npx tsc` builds successfully (full compilation)
3. All telemetry files exist under `src/ai/telemetry/`
4. `src/ai/service.ts` exists with call() and finalize() methods
5. `src/ai/index.ts` barrel export covers all public types and functions
6. `src/config/schema.ts` includes the ai section and still parses `{}` correctly
7. No new runtime dependencies in package.json
8. Existing modules (cli, config, discovery, generation, etc.) still compile without changes
</verification>

<success_criteria>
- TelemetryLogger accumulates entries and computes summary
- writeRunLog writes pretty-printed JSON to .agents-reverse-engineer/logs/
- cleanupOldLogs removes old files keeping N most recent
- AIService.call() handles: success, timeout, rate limit retry, parse error, permanent failure
- AIService.finalize() writes run log and cleans up old files
- Config schema extended with ai section (backward compatible)
- Full project compiles with `npx tsc` -- zero errors, zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-service-foundation/06-03-SUMMARY.md`
</output>
