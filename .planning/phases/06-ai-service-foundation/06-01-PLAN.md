---
phase: 06-ai-service-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ai/types.ts
  - src/ai/subprocess.ts
  - src/ai/retry.ts
autonomous: true

must_haves:
  truths:
    - "A subprocess can be spawned with a command, args, timeout, and optional stdin input"
    - "When a subprocess exceeds its timeout, it is killed and the result indicates timedOut: true"
    - "When a transient failure occurs, the retry utility retries with exponential backoff"
    - "When a permanent failure occurs, the retry utility throws immediately without retrying"
    - "All AI service types (AIResponse, AICallOptions, AIBackend, SubprocessResult, etc.) are defined and exported"
  artifacts:
    - path: "src/ai/types.ts"
      provides: "AIBackend interface, AIResponse, AICallOptions, SubprocessResult, TelemetryEntry, RunLog types"
      exports: ["AIBackend", "AIResponse", "AICallOptions", "SubprocessResult", "RetryOptions", "TelemetryEntry", "RunLog"]
    - path: "src/ai/subprocess.ts"
      provides: "Low-level subprocess spawn with timeout, kill, zombie prevention"
      exports: ["runSubprocess"]
    - path: "src/ai/retry.ts"
      provides: "Retry with exponential backoff utility"
      exports: ["withRetry"]
  key_links:
    - from: "src/ai/subprocess.ts"
      to: "node:child_process"
      via: "execFile with timeout and killSignal options"
      pattern: "execFile.*timeout"
    - from: "src/ai/retry.ts"
      to: "src/ai/types.ts"
      via: "RetryOptions type import"
      pattern: "import.*RetryOptions.*from.*types"
---

<objective>
Create the foundational types, subprocess wrapper, and retry utility for the AI service layer.

Purpose: These are the building blocks that every other AI service module depends on. The types define the contract for backends, responses, and telemetry. The subprocess wrapper centralizes all process spawning with timeout enforcement and zombie prevention. The retry utility provides exponential backoff for transient failures.

Output: Three files in `src/ai/` that compile cleanly and export the core primitives.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ai-service-foundation/06-RESEARCH.md
@.planning/phases/06-ai-service-foundation/06-CONTEXT.md
@src/config/schema.ts
@src/types/index.ts
@tsconfig.json
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define AI service types</name>
  <files>src/ai/types.ts</files>
  <action>
Create `src/ai/types.ts` with all shared types for the AI service layer. Follow the project's existing conventions (JSDoc comments, ESM imports, Zod for validation where needed).

Define these types:

1. **SubprocessResult** -- returned by the subprocess wrapper:
   - `stdout: string`, `stderr: string`, `exitCode: number`, `signal: string | null`, `durationMs: number`, `timedOut: boolean`

2. **AICallOptions** -- input options for an AI call:
   - `prompt: string`, `systemPrompt?: string`, `model?: string`, `timeoutMs?: number`, `maxTurns?: number`

3. **AIResponse** -- normalized response from any AI CLI:
   - `text: string`, `model: string`, `inputTokens: number`, `outputTokens: number`, `cacheReadTokens: number`, `cacheCreationTokens: number`, `costUsd: number`, `durationMs: number`, `exitCode: number`, `raw: unknown`

4. **AIBackend** interface -- contract for backend adapters:
   - `readonly name: string`, `readonly cliCommand: string`
   - `isAvailable(): Promise<boolean>`
   - `buildArgs(options: AICallOptions): string[]`
   - `parseResponse(stdout: string, durationMs: number, exitCode: number): AIResponse`
   - `getInstallInstructions(): string`

5. **RetryOptions** -- configuration for retry behavior:
   - `maxRetries: number`, `baseDelayMs: number`, `maxDelayMs: number`, `multiplier: number`
   - `isRetryable: (error: unknown) => boolean`
   - `onRetry?: (attempt: number, error: unknown) => void`

6. **TelemetryEntry** -- per-call log entry:
   - `timestamp: string`, `prompt: string`, `systemPrompt?: string`, `response: string`, `model: string`
   - `inputTokens: number`, `outputTokens: number`, `cacheReadTokens: number`, `cacheCreationTokens: number`
   - `costUsd: number`, `latencyMs: number`, `exitCode: number`, `error?: string`, `retryCount: number`

7. **RunLog** -- per-run log file structure:
   - `runId: string`, `startTime: string`, `endTime: string`, `entries: TelemetryEntry[]`
   - `summary: { totalCalls, totalInputTokens, totalOutputTokens, totalCostUsd, totalDurationMs, errorCount }`

8. **AIServiceError** class extending Error with `code` field for typed error handling:
   - codes: `'CLI_NOT_FOUND'`, `'TIMEOUT'`, `'PARSE_ERROR'`, `'SUBPROCESS_ERROR'`, `'RATE_LIMIT'`

Every type must have JSDoc comments. Export everything as named exports.
  </action>
  <verify>Run `npx tsc --noEmit` and confirm no type errors in `src/ai/types.ts`.</verify>
  <done>All AI service types are defined and exported. Other modules can import and use them without any type errors.</done>
</task>

<task type="auto">
  <name>Task 2: Build subprocess wrapper with timeout and cleanup</name>
  <files>src/ai/subprocess.ts</files>
  <action>
Create `src/ai/subprocess.ts` that exports a single `runSubprocess` function. This is the ONLY place in the codebase that spawns AI CLI processes.

Implementation details:
- Import `execFile` from `node:child_process`
- Import `SubprocessResult` from `./types.js`
- Function signature: `runSubprocess(command: string, args: string[], options: { timeoutMs: number; input?: string }): Promise<SubprocessResult>`
- Use `execFile` (NOT `exec`, NOT `spawn`) with these options:
  - `timeout: options.timeoutMs`
  - `killSignal: 'SIGTERM'` (graceful kill on timeout)
  - `maxBuffer: 10 * 1024 * 1024` (10MB to handle large AI responses)
  - `encoding: 'utf-8'`
- Write prompt to stdin if `options.input` is provided, then call `child.stdin.end()`
- In the callback: compute `durationMs`, detect `timedOut` via `error?.killed === true`
- Handle exit code extraction: `error?.code` if number, else `child.exitCode`, else 1
- Always resolve (never reject) -- errors are captured in the SubprocessResult fields (exitCode, timedOut, stderr). This lets callers decide how to handle failures.

Follow pitfalls from RESEARCH.md:
- Always call `.end()` on stdin after writing (Pitfall 1)
- Set maxBuffer explicitly (Pitfall 2)
- Use SIGTERM as killSignal (Pitfall 3)

Add JSDoc with usage example.
  </action>
  <verify>Run `npx tsc --noEmit` and confirm no type errors. Verify the function signature matches SubprocessResult type.</verify>
  <done>The `runSubprocess` function compiles, always resolves with a SubprocessResult, enforces timeouts, writes to stdin, and handles all edge cases documented in research.</done>
</task>

<task type="auto">
  <name>Task 3: Build retry utility with exponential backoff</name>
  <files>src/ai/retry.ts</files>
  <action>
Create `src/ai/retry.ts` that exports a `withRetry` generic function.

Implementation details:
- Import `RetryOptions` from `./types.js`
- Function signature: `withRetry<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T>`
- Loop from `attempt = 0` to `options.maxRetries` (inclusive, so maxRetries=3 means 4 total attempts: 1 initial + 3 retries)
- On each failure:
  - If `attempt === options.maxRetries` or `!options.isRetryable(error)`: throw immediately
  - Otherwise: compute delay as `Math.min(options.baseDelayMs * Math.pow(options.multiplier, attempt), options.maxDelayMs)`
  - Add jitter: `delay + Math.random() * 500` (prevents thundering herd)
  - Call `options.onRetry?.(attempt + 1, error)` before waiting
  - Wait with `await new Promise(resolve => setTimeout(resolve, delay))`

Export a `DEFAULT_RETRY_OPTIONS` constant (without `isRetryable` and `onRetry` since those are caller-specific):
- `maxRetries: 3`
- `baseDelayMs: 1000`
- `maxDelayMs: 8000`
- `multiplier: 2`

Add JSDoc with usage example showing how to wrap an AI call with retry.
  </action>
  <verify>Run `npx tsc --noEmit` and confirm no type errors. Verify the function handles all retry/throw paths correctly by code review.</verify>
  <done>The `withRetry` function compiles, retries on transient failures with exponential backoff + jitter, and throws immediately on permanent failures or after max retries.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. All three files exist under `src/ai/`
3. All types and functions are exported as named exports
4. No new dependencies added to package.json (all built-in Node.js modules)
5. Code follows project conventions: JSDoc comments, ESM imports with `.js` extensions, TypeScript strict mode
</verification>

<success_criteria>
- `src/ai/types.ts` exports AIBackend, AIResponse, AICallOptions, SubprocessResult, RetryOptions, TelemetryEntry, RunLog, AIServiceError
- `src/ai/subprocess.ts` exports runSubprocess with timeout enforcement and stdin piping
- `src/ai/retry.ts` exports withRetry with exponential backoff + jitter and DEFAULT_RETRY_OPTIONS
- All files compile with `npx tsc --noEmit`
- No new runtime dependencies
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-service-foundation/06-01-SUMMARY.md`
</output>
